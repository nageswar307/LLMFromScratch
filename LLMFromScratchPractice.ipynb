{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KiGFmErf1ti-teqYuSmYBDZ4Ajw_LFsU",
      "authorship_tag": "ABX9TyOtWUIHE+T0RFppSr8N/LNk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nageswar307/LLMFromScratch/blob/main/LLMFromScratchPractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY2eI3-N1L3i",
        "outputId": "b2fc10ed-96ca-48ff-a0ba-164c358c1f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. get raw input text for training\n",
        "2. tokenization\n",
        "3. prepare input and target sequence\n",
        "4. creating token embeddings\n"
      ],
      "metadata": {
        "id": "-VoJKuYZ2hJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. get raw input  text for training"
      ],
      "metadata": {
        "id": "sziO2whd_Cxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/the-verdict.txt\", \"r\",encoding='utf-8') as f:\n",
        "  raw_text = f.read()\n",
        "  print(raw_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HPVXVqD1SSm",
        "outputId": "e334c100-10bb-47ca-897b-123cfa770781"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
            "\n",
            "\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it's going to send the value of my picture 'way up; but I don't think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing's lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn's \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\n",
            "\n",
            "Well!--even through th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Tokenization"
      ],
      "metadata": {
        "id": "dk8cimKQ21Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n"
      ],
      "metadata": {
        "id": "aP0qpIbV1Okp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "JPgCf4h61rfM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = tokenizer.encode(raw_text)\n",
        "len(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkkA4Ggv117h",
        "outputId": "67499f41-0aa5-4168-c327-9e56dc53ce5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5145"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(token_ids[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "mcUKKU7N2Lwy",
        "outputId": "53298834-05d9-4889-ceb2-44c4777cd873"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\\n\\n\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMBrk_762YvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. prepare input and target data"
      ],
      "metadata": {
        "id": "DrBwLOP326OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch"
      ],
      "metadata": {
        "id": "aRYpWVJ23ADe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "0Gotnfn93DQg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "    self.stride = stride\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunks = token_ids[i:i+max_length]\n",
        "      target_chunks = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunks))\n",
        "      self.target_ids.append(torch.tensor(target_chunks))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.target_ids[idx]\n"
      ],
      "metadata": {
        "id": "WHzo4Bl83LAi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n"
      ],
      "metadata": {
        "id": "UoCBWut24hWW"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GPTDatasetV1(raw_text,tokenizer,10,5)\n",
        "print(dataset[ 276])  #observe how getitem method is\n",
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqStGuXp4wBP",
        "outputId": "889f3094-9795-455b-cfcc-3a3dd2adfbb3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([ 4808, 13698, 10322,  6532,    62,  8263,    12,  9649,   550,  9258]), tensor([13698, 10322,  6532,    62,  8263,    12,  9649,   550,  9258,   284]))\n",
            "1027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.input_ids[0], dataset.target_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg-freHJ4wx5",
        "outputId": "3068928f-4448-4926-d4db-f18e88a05d84"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   40,   367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138]),\n",
              " tensor([  367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,   257]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.input_ids[1], dataset.target_ids[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hnsBeBy42PG",
        "outputId": "21e8f292-dab9-4ab1-f0c6-2f3b8b4068d6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3619,   402,   271, 10899,  2138,   257,  7026, 15632,   438,  2016]),\n",
              " tensor([  402,   271, 10899,  2138,   257,  7026, 15632,   438,  2016,   257]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ux8sn3w95Okg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader_v1(txt,max_length,stride,batch_size,shuffle=True,drop_last=True):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt,tokenizer,max_length=max_length,stride=stride)\n",
        "  data_loader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last)\n",
        "  return data_loader"
      ],
      "metadata": {
        "id": "63jC4gFy8nc5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_data_loader_v1(raw_text,max_length=4,stride=1,batch_size=1,shuffle=False,drop_last=False)\n",
        "data_iter = iter(dataloader)\n",
        "next(data_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77aL5GP_9Urv",
        "outputId": "b0b7f045-82cf-4ae8-ff00-3493d2d64e15"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(data_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7POH6sn9u_M",
        "outputId": "9a0004fc-3673-41e5-a2c9-a3556c0feb65"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(data_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNevC4Vz92Gc",
        "outputId": "e324ae33-63c5-4614-83e7-77709630b634"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[2885, 1464, 1807, 3619]]), tensor([[1464, 1807, 3619,  402]])]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_data_loader_v1(raw_text,max_length=4,stride=4,batch_size=8,shuffle=False,drop_last=False)\n",
        "data_iter = iter(dataloader)\n",
        "next(data_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7taVS4f938s",
        "outputId": "bc3355c0-a69d-4b5a-820a-3ae44671bcfa"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[   40,   367,  2885,  1464],\n",
              "         [ 1807,  3619,   402,   271],\n",
              "         [10899,  2138,   257,  7026],\n",
              "         [15632,   438,  2016,   257],\n",
              "         [  922,  5891,  1576,   438],\n",
              "         [  568,   340,   373,   645],\n",
              "         [ 1049,  5975,   284,   502],\n",
              "         [  284,  3285,   326,    11]]),\n",
              " tensor([[  367,  2885,  1464,  1807],\n",
              "         [ 3619,   402,   271, 10899],\n",
              "         [ 2138,   257,  7026, 15632],\n",
              "         [  438,  2016,   257,   922],\n",
              "         [ 5891,  1576,   438,   568],\n",
              "         [  340,   373,   645,  1049],\n",
              "         [ 5975,   284,   502,   284],\n",
              "         [ 3285,   326,    11,   287]])]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(data_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_n1JWBw-YNo",
        "outputId": "55ee8418-d7f8-48ab-a933-16e2768355c8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[  287,   262,  6001,   286],\n",
              "         [  465, 13476,    11,   339],\n",
              "         [  550,  5710,   465, 12036],\n",
              "         [   11,  6405,   257,  5527],\n",
              "         [27075,    11,   290,  4920],\n",
              "         [ 2241,   287,   257,  4489],\n",
              "         [   64,   319,   262, 34686],\n",
              "         [41976,    13,   357, 10915]]),\n",
              " tensor([[  262,  6001,   286,   465],\n",
              "         [13476,    11,   339,   550],\n",
              "         [ 5710,   465, 12036,    11],\n",
              "         [ 6405,   257,  5527, 27075],\n",
              "         [   11,   290,  4920,  2241],\n",
              "         [  287,   257,  4489,    64],\n",
              "         [  319,   262, 34686, 41976],\n",
              "         [   13,   357, 10915,   314]])]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omVnfBF9-tY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. creating token embeddings"
      ],
      "metadata": {
        "id": "-NHZnk5h-5RC"
      }
    }
  ]
}