{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IW08jEsMQ0jb2ZeouLOLjT1hnavA1BYt",
      "authorship_tag": "ABX9TyMupybNNwUL3JVw5grGRASR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nageswar307/LLMFromScratch/blob/main/LLMFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Working with text and building our own tokenizer**"
      ],
      "metadata": {
        "id": "PlxtX9fFL2Dy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CyAka6MUr7U_"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text=f.read()\n",
        "print(len(raw_text))\n",
        "print(raw_text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBMssUnWsB4u",
        "outputId": "e35c69fc-37b4-4ae9-b373-29a52c4c7bd4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. This, is a test.\"\n",
        "result = re.split(r\"(\\s)\", text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBIwHqpIujph",
        "outputId": "d093f15d-2c50-4dc4-edd4-8d5032db882a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split('([.,]|\\s)',text)\n",
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxlRb-wcveZ4",
        "outputId": "8c3cde4e-fd7f-4d7e-d7a8-04342f635ce8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "result  = re.split('([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjwEFSsavk39",
        "outputId": "59c25b6d-0ee8-403b-fee3-2dd9de428d19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item for item in preprocessed if item.strip()]\n",
        "len(preprocessed)\n",
        "print(preprocessed[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-u0bMzZxVTf",
        "outputId": "aa770da1-5dac-492f-fdf8-ea8b9d1aeaa6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(list(set(preprocessed)))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFO6IxOSxzQR",
        "outputId": "d7ec35ba-f168-4c51-adb6-2195fc0613f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token: idx for idx,token in enumerate(all_words)}\n",
        "for i,j in enumerate(vocab.items()):\n",
        "  print(j)\n",
        "  if i==20:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApofKyDmyQ7B",
        "outputId": "e99e2b8b-2291-488e-9044-04eee69ec685"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab #A\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()} #B\n",
        "  def encode(self, text): #C\n",
        "    preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "  def decode(self, ids): #D\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
        "    return text"
      ],
      "metadata": {
        "id": "7mOt0YhYyV6v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "tokenizer.int_to_str[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NQINrTXx0xcy",
        "outputId": "f8ba5732-d93c-4054-fb02-3d7f6d5cdbcd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tea'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\"It's the last he painted, you know,\" Mrs. Gisburn said with pardonable \"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAKnz7V801xY",
        "outputId": "2ed48e05-3880-4c97-9e88-56f9d90bff62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 58, 2, 872, 1013, 615, 541, 763, 5, 1155, 608, 5, 1, 69, 7, 39, 873, 1136, 773]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kcU6zQ7T04eR",
        "outputId": "9fca994c-2575-4ccf-9394-5f631bf83688"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"\"\"From Wikipedia, the free encyclopedia\n",
        "This article is about natural and human-made phenomena and structures of the world. For other uses of \"Wonders of the World\", see Wonders of the World (disambiguation).\n",
        "\n",
        "The Seven Wonders of the Ancient World (from left to right, top to bottom): Great Pyramid of Giza, Hanging Gardens of Babylon, Temple of Artemis at Ephesus, Statue of Zeus at Olympia, Mausoleum at Halicarnassus (also known as the Mausoleum of Mausolus), Colossus of Rhodes, and the Lighthouse of Alexandria as depicted by 16th-century Dutch artist Maarten van Heemskerck.\n",
        "\n",
        "Map of places listed in various Wonders of the World lists\n",
        "Various lists of the Wonders of the World have been compiled from antiquity to the present day, in order to catalogue the world's most spectacular natural features and human-built structures.\n",
        "\n",
        "The Seven Wonders of the Ancient World is the oldest known list of this type, documenting the most iconic and remarkable human-made creations of classical antiquity; it was based on guidebooks popular among Hellenic sightseers and as such only includes works located around the Mediterranean rim and in the ancient Near East. The number seven was chosen because the Greeks believed it represented perfection and plenty, and because it reflected the number of planets known in ancient times (five) plus the Sun and Moon.[1]\n",
        "\n",
        "Seven Wonders of the Ancient World\n",
        "Main article: Seven Wonders of the Ancient World\n",
        "\n",
        "The Great Pyramid of Giza, the only wonder of the ancient world still in existence\n",
        "The Greek historian Herodotus (484 – c. 425 BC) and the scholar Callimachus of Cyrene (c. 305–240 BC), at the Museum of Alexandria, made early lists of seven wonders. These lists have not survived, however, except as references in other writings.\n",
        "\n",
        "The classic Seven Wonders were:\n",
        "\n",
        "Great Pyramid of Giza, in Giza, Egypt, the earliest of the wonders to be completed, as well as the only one that still exists in the present day.\n",
        "Colossus of Rhodes, in the harbor of the city of Rhodes, on the Greek island of the same name.\n",
        "Hanging Gardens of Babylon, in Babylon, near present-day Hillah, Babylon Governorate, Iraq; or Nineveh, Mosul, Nineveh Governorate, Iraq.\n",
        "Lighthouse of Alexandria, in Alexandria, Egypt.\n",
        "Mausoleum at Halicarnassus, in Halicarnassus, a city of the Achaemenid Empire in present-day Turkey.\n",
        "Statue of Zeus at Olympia, in Olympia, Greece.\n",
        "Temple of Artemis at Ephesus, in the city of Ephesus, near present-day Selçuk, Turkey.\n",
        "Lists from other eras\n",
        "In the 19th and early 20th centuries, some writers emulated the classical list by creating their own lists with names such as \"Wonders of the Middle Ages\", \"Seven Wonders of the Middle Ages\", \"Seven Wonders of the Medieval Mind\", and \"Architectural Wonders of the Middle Ages\".[2] It is unlikely that any of these lists actually originated in the Middle Ages since the concept of a \"Middle Age\" did not become popular until at least the 16th century and the word \"medieval\" was not invented until the Enlightenment era. Brewer's Dictionary of Phrase and Fable refers to them as \"later list[s]\",[3] suggesting the lists were created after the Middle Ages.\n",
        "\n",
        "Many of the structures on these lists were built much earlier than the Middle Ages but were well known throughout the world.[4][5] Typically representative of such lists are:[3][4][6][7]\n",
        "\n",
        "Catacombs of Kom El Shoqafa, a 2nd-century funerary complex in Alexandria, Egypt.\n",
        "Colosseum, a 1st-century amphitheatre in the centre of the city of Rome, Italy.\n",
        "Great Wall of China, a series of defensive fortifications built across the historical northern borders of China, with some segments dating to as early as the 7th century BC.\n",
        "Hagia Sophia, a 6th-century cathedral and mosque in Istanbul, Turkey.\n",
        "Leaning Tower of Pisa, a 12th-century bell tower in Pisa, Italy.\n",
        "Porcelain Tower of Nanjing, a 15th-century pagoda on the south bank of the external Qinhuai River in Nanjing, China.\n",
        "Stonehenge, a Neolithic henge monument in Wiltshire, England dated to the 3rd millennium BC.\n",
        "Other structures sometimes included on such lists include:\n",
        "\n",
        "Cairo Citadel, a 13th-century Islamic fortification in Cairo, Egypt.[8]\n",
        "Cluny Abbey, a 10th-century Benedictine monastery in Cluny, Saône-et-Loire, France.[9]\n",
        "Ely Cathedral, a (currently Anglican) cathedral originally built in the 11th century in Ely, Cambridgeshire, England.[10]\n",
        "\n",
        "Recent lists\n",
        "Following in the tradition of the classical list, modern people and organisations have made their own lists of wonderful things, both ancient and modern, natural and artificial. Some of the most notable lists are presented below.\n",
        "\n",
        "American Society of Civil Engineers\n",
        "\n",
        "CN Tower in Toronto, Canada\n",
        "In 1994, the American Society of Civil Engineers compiled a list of Seven Wonders of the Modern World, paying tribute to the \"greatest civil engineering achievements of the 20th century\".[11][12]\n",
        "\n",
        "American Society of Civil Engineers Wonders\n",
        "Wonder\tDate started\tDate finished\tLocation\tSignificance\n",
        "Channel Tunnel\tDecember 1, 1987\tMay 6, 1994\tStrait of Dover, in the English Channel between the United Kingdom and France\tLongest undersea portion of any tunnel in the world\n",
        "CN Tower\tFebruary 6, 1973\tJune 26, 1976\tToronto, Ontario, Canada\tTallest freestanding structure in the world from 1976 to 2007\n",
        "Empire State Building\tMarch 17, 1930\tApril 11, 1931\tNew York City, New York, United States\tTallest structure in the world from 1931 to 1954; tallest freestanding structure in the world from 1931 to 1967; tallest building in the world from 1931 to 1970; first building with 100+ stories\n",
        "Golden Gate Bridge\tJanuary 5, 1933\tMay 27, 1937\tGolden Gate Strait, north of San Francisco, California, United States\tLongest main span of any suspension bridge in the world from 1937 to 1964\n",
        "Itaipu Dam\tJanuary 1970\tMay 5, 1984\tParaná River, on the border between Brazil and Paraguay\tLargest operating hydroelectric facility in the world in terms of annual energy generation[13]\n",
        "Netherlands North Sea Protection Works (Delta and Zuiderzee Works)\t1920\tMay 10, 1997\tZeeland, South Holland, North Holland, Friesland and Flevoland, Netherlands\tLargest hydraulic engineering project undertaken by the Netherlands during the 20th century\n",
        "Panama Canal\tJanuary 1, 1880\tJanuary 7, 1914\tIsthmus of Panama\tAllows passage of oceangoing vessels between the Atlantic and Pacific oceans; one of the largest and most difficult engineering projects ever undertaken\n",
        "USA Today's New Seven Wonders\n",
        "\n",
        "Old City of Jerusalem\n",
        "In November 2006, the American national newspaper USA Today and the American television show Good Morning America revealed a list of the \"New Seven Wonders\", both natural and human-made, as chosen by six judges.[14] The Grand Canyon was added as an eighth wonder on November 24, 2006, in response to viewer feedback.[15]\n",
        "\n",
        "USA Today's New Seven Wonders\n",
        "Wonder\tLocation\n",
        "Potala Palace\tLhasa, Tibet\n",
        "Old City of Jerusalem\tIsrael[n 1]\n",
        "Polar ice caps\tEarth's polar regions (Arctic and Antarctic)\n",
        "Papahānaumokuākea Marine National Monument\tHawaii, United States\n",
        "The Internet\tWorldwide\n",
        "Mayan ruins\tYucatán Peninsula, México\n",
        "Great Migration of Serengeti and Masai Mara\tTanzania and Kenya\n",
        "Grand Canyon (viewer-chosen eighth wonder)\tArizona, United States\n",
        "Seven Natural Wonders of the World\n",
        "\n",
        "Victoria Falls\n",
        "Similar to the other lists of wonders, there is no consensus on a list of seven natural wonders of the world, and there has been debate over how large such a list should be. One of many existing versions of this list was compiled by CNN in 1997:[16]\n",
        "\n",
        "Aurora, in the Earth's high-latitude regions (around the Arctic and Antarctic)\n",
        "Grand Canyon, in Arizona, United States\n",
        "Great Barrier Reef, off the coast of Queensland, Australia\n",
        "Harbor of Rio de Janeiro, Brazil\n",
        "Mount Everest, on the border of Nepal and China\n",
        "Parícutin volcano, located in the state of Michoacán, Mexico\n",
        "Victoria Falls, on the border of Zambia and Zimbabwe\n",
        "New 7 Wonders of the World\n",
        "\n",
        "El Castillo at Chichen Itza\n",
        "In 2001, an initiative was started by the Swiss corporation New7Wonders Foundation to choose the New 7 Wonders of the World from a selection of 200 existing monuments through online votes.[17] The Great Pyramid of Giza—part of the Giza Pyramids, the only remaining wonder of the traditional Seven Wonders of the Ancient World, was not one of the winners announced in 2007 but was added as an honorary candidate.[18][19]\n",
        "\n",
        "Wonder\tDate of construction\tPresent-day location\n",
        "Great Wall of China\tSince 7th century BC[20]\tChina\n",
        "Petra\tc. 100 BC\tMa'an, Jordan\n",
        "Christ the Redeemer\topened to the public October 12, 1931\tRio de Janeiro, Brazil\n",
        "Machu Picchu\tc. AD 1450\tUrubamba Province, Peru\n",
        "Chichen Itza\tc. AD 600\tYucatán, Mexico\n",
        "Colosseum\tcompleted AD 80\tRome, Italy\n",
        "Taj Mahal\tcompleted c. AD 1648\tAgra, India\n",
        "Giza Pyramids (honorary candidates)\tcompleted c. 2560 BC\tGiza, Egypt\n",
        "\n",
        "New 7 Wonders of Nature\n",
        "\n",
        "Jeju Island\n",
        "A similar contemporary effort to create a list of seven natural (as opposed to human-made) wonders chosen through a global poll, called the New 7 Wonders of Nature, was organized from 2007 to 2011 by the same group as the New 7 Wonders of the World campaign.\n",
        "\n",
        "Iguazu Falls, on the border of the Argentine province of Misiones and the Brazilian state of Paraná\n",
        "Hạ Long Bay, in Quảng Ninh province, Vietnam\n",
        "Jeju Island, in the Jeju Province of South Korea\n",
        "Puerto Princesa Underground River, in Palawan, Philippines\n",
        "Table Mountain, overlooking the city of Cape Town, South Africa\n",
        "Komodo Island, one of the 17,508 islands that comprise the Republic of Indonesia\n",
        "Amazon rainforest, located in Brazil, Peru, Colombia, Venezuela, Ecuador, Bolivia, Guyana, Suriname, and French Guiana\n",
        "New 7 Wonders Cities\n",
        "\n",
        "Calle Crisologo, Vigan City\n",
        "New 7 Wonders Cities, a third list organized by New7Wonders and determined by another global vote, includes entire cities:\n",
        "\n",
        "Durban, South Africa\n",
        "Vigan, Philippines\n",
        "Havana, Cuba\n",
        "Kuala Lumpur, Malaysia\n",
        "Beirut, Lebanon\n",
        "Doha, Qatar\n",
        "La Paz, Bolivia\n",
        "Seven Wonders of the Underwater World\n",
        "\n",
        "The Great Barrier Reef\n",
        "The list of \"Seven Wonders of the Underwater World\" was drawn up by CEDAM International, an American-based non-profit group for divers that is dedicated to ocean preservation and research. In 1989, CEDAM brought together a panel of marine scientists, including Eugenie Clark, to choose underwater areas which they considered worthy of protection. The results were announced at The National Aquarium in Washington, D.C., by actor Lloyd Bridges, star of TV's Sea Hunt:[21]\n",
        "\n",
        "Palau\n",
        "Belize Barrier Reef, Belize\n",
        "Great Barrier Reef, Australia\n",
        "Deep-sea hydrothermal vents (worldwide)\n",
        "Galápagos Islands, Ecuador\n",
        "Lake Baikal, Russia\n",
        "Northern Red Sea, bordered by Saudi Arabia and Yemen on the eastern shore, and Egypt, Sudan, Eritrea, and Djibouti on the western shore\n",
        "Seven Wonders of the Industrial World\n",
        "\n",
        "Bell Rock Lighthouse\n",
        "British author Deborah Cadbury wrote Seven Wonders of the Industrial World, a book telling the stories of seven great feats of engineering of the 19th and early 20th centuries.[22] In 2003, the BBC aired a seven-part docudrama exploring the same feats, with Cadbury as a producer.[23]\n",
        "\n",
        "Wonder\tDescription\tCompleted\n",
        "SS Great Eastern\tBritish oceangoing passenger steamship\t1858\n",
        "Bell Rock Lighthouse\tin the North Sea off the coast of Angus, Scotland\t1810\n",
        "Brooklyn Bridge\tin New York City, New York, United States\t1883\n",
        "London sewerage system\tserving London, England\t1870\n",
        "First transcontinental railroad\t1,912-mile (3,077 km) continuous railroad line connecting existing rail networks in Iowa, Nebraska, Wyoming, Utah, Nevada, and California in the United States\t1869\n",
        "Panama Canal\t51-mile (82 km) artificial waterway crossing the Isthmus of Panama and connecting the Atlantic and Pacific oceans\t1914\n",
        "Hoover Dam\ton the Colorado River, spanning the border between Nevada and Arizona in the United States\t1936\n",
        "Seven Wonders of the Solar System\n",
        "\n",
        "Enceladus\n",
        "In a 1999 article, Astronomy magazine listed the \"Seven Wonders of the Solar System\". This article was later made into a video.[24]\n",
        "\n",
        "Enceladus, a moon of Saturn\n",
        "The Great Red Spot of Jupiter, a massive and persistent anticyclonic storm in the planet's southern hemisphere\n",
        "The asteroid belt, a region of innumerable small solid bodies located between the orbits of Mars and Jupiter\n",
        "The surface of the Sun\n",
        "The oceans of Earth\n",
        "The Rings of Saturn\n",
        "Olympus Mons, an enormous shield volcano on Mars and the tallest planetary mountain in the Solar System\n",
        "Other lists of wonders of the world\n",
        "Many authors and organisations have composed lists of the wonders of the world that have been published in book or magazine form.\n",
        "\n",
        "Seven Wonders of the World is a 1956 film in which Lowell Thomas searches the world for natural and artificial wonders and invites the audience to try to update the ancient Wonders of the World list.\"\"\""
      ],
      "metadata": {
        "id": "4chByG_C2oKP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst_txt = re.split(r\"([,.?_!\\\"()\\']|--|\\s)\",txt)\n",
        "lst_txt = [item for item in lst_txt if item.strip()]\n",
        "len(lst_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aObPXflA43Pw",
        "outputId": "9f62196b-3eac-4f93-a895-c4d43c56172f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2371"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(list(set(lst_txt)))\n",
        "vocab_size = len(vocab)\n",
        "vocab = {token: idx for idx,token in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "bDWCDjVn5AMd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {v:k for k,v in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    preprocessed_text = re.split(r\"([,.?_!\\\"()\\']|--|\\s)\",text)\n",
        "    preprocessed_text = [item.strip() for item in preprocessed_text if item.strip()] # [\"1\",\"am\",\"man\",....]\n",
        "    print(\"preprocessed_text --\",preprocessed_text)\n",
        "    token_ids = [self.str_to_int[token] for token in preprocessed_text]\n",
        "    return token_ids\n",
        "\n",
        "  def decode(self, token_ids): #[100,234,908,567,10000.....]\n",
        "    decoded_text = \" \".join([self.int_to_str[id] for id in token_ids])\n",
        "    decoded_text = re.sub(r'\\s+([,.?!\"()\\'])',r'\\1',decoded_text)\n",
        "    return decoded_text\n"
      ],
      "metadata": {
        "id": "dVRArFlY6jnI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tknzr = tokenizerV1(vocab)\n",
        "print(tknzr.str_to_int)\n",
        "print(tknzr.int_to_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh-na-3C6EdY",
        "outputId": "29a537c5-e564-406a-f8df-9c0c863c46d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\"': 0, \"'\": 1, '(': 2, ')': 3, ',': 4, '.': 5, '077': 6, '1': 7, '10': 8, '100': 9, '100+': 10, '10th-century': 11, '11': 12, '11th': 13, '12': 14, '12th-century': 15, '13th-century': 16, '1450': 17, '15th-century': 18, '1648': 19, '16th': 20, '16th-century': 21, '17': 22, '1810': 23, '1858': 24, '1869': 25, '1870': 26, '1880': 27, '1883': 28, '1914': 29, '1920': 30, '1930': 31, '1931': 32, '1933': 33, '1936': 34, '1937': 35, '1954;': 36, '1956': 37, '1964': 38, '1967;': 39, '1970': 40, '1970;': 41, '1973': 42, '1976': 43, '1984': 44, '1987': 45, '1989': 46, '1994': 47, '1997': 48, '1997:[16]': 49, '1999': 50, '19th': 51, '1]': 52, '1st-century': 53, '200': 54, '2001': 55, '2003': 56, '2006': 57, '2007': 58, '2011': 59, '20th': 60, '24': 61, '2560': 62, '26': 63, '27': 64, '2nd-century': 65, '3': 66, '305–240': 67, '3rd': 68, '425': 69, '484': 70, '5': 71, '508': 72, '51-mile': 73, '6': 74, '600': 75, '6th-century': 76, '7': 77, '7th': 78, '80': 79, '82': 80, '912-mile': 81, ':': 82, 'A': 83, 'AD': 84, 'Abbey': 85, 'Achaemenid': 86, 'Africa': 87, 'Age': 88, 'Ages': 89, 'Agra': 90, 'Alexandria': 91, 'Allows': 92, 'Amazon': 93, 'America': 94, 'American': 95, 'American-based': 96, 'Ancient': 97, 'Anglican': 98, 'Angus': 99, 'Antarctic': 100, 'April': 101, 'Aquarium': 102, 'Arabia': 103, 'Architectural': 104, 'Arctic': 105, 'Argentine': 106, 'Arizona': 107, 'Artemis': 108, 'Astronomy': 109, 'Atlantic': 110, 'Aurora': 111, 'Australia': 112, 'BBC': 113, 'BC': 114, 'BC[20]': 115, 'Babylon': 116, 'Baikal': 117, 'Barrier': 118, 'Bay': 119, 'Beirut': 120, 'Belize': 121, 'Bell': 122, 'Benedictine': 123, 'Bolivia': 124, 'Brazil': 125, 'Brazilian': 126, 'Brewer': 127, 'Bridge': 128, 'Bridges': 129, 'British': 130, 'Brooklyn': 131, 'Building': 132, 'C': 133, 'CEDAM': 134, 'CN': 135, 'CNN': 136, 'Cadbury': 137, 'Cairo': 138, 'California': 139, 'Calle': 140, 'Callimachus': 141, 'Cambridgeshire': 142, 'Canada': 143, 'Canal': 144, 'Canyon': 145, 'Cape': 146, 'Castillo': 147, 'Catacombs': 148, 'Cathedral': 149, 'Channel': 150, 'Chichen': 151, 'China': 152, 'Christ': 153, 'Citadel': 154, 'Cities': 155, 'City': 156, 'Civil': 157, 'Clark': 158, 'Cluny': 159, 'Colombia': 160, 'Colorado': 161, 'Colosseum': 162, 'Colossus': 163, 'Completed': 164, 'Crisologo': 165, 'Cuba': 166, 'Cyrene': 167, 'D': 168, 'Dam': 169, 'Date': 170, 'Deborah': 171, 'December': 172, 'Deep-sea': 173, 'Delta': 174, 'Description': 175, 'Dictionary': 176, 'Djibouti': 177, 'Doha': 178, 'Dover': 179, 'Durban': 180, 'Dutch': 181, 'Earth': 182, 'East': 183, 'Eastern': 184, 'Ecuador': 185, 'Egypt': 186, 'El': 187, 'Ely': 188, 'Empire': 189, 'Enceladus': 190, 'Engineers': 191, 'England': 192, 'English': 193, 'Enlightenment': 194, 'Ephesus': 195, 'Eritrea': 196, 'Eugenie': 197, 'Everest': 198, 'Fable': 199, 'Falls': 200, 'February': 201, 'First': 202, 'Flevoland': 203, 'Following': 204, 'For': 205, 'Foundation': 206, 'France': 207, 'Francisco': 208, 'French': 209, 'Friesland': 210, 'From': 211, 'Galápagos': 212, 'Gardens': 213, 'Gate': 214, 'Giza': 215, 'Giza—part': 216, 'Golden': 217, 'Good': 218, 'Governorate': 219, 'Grand': 220, 'Great': 221, 'Greece': 222, 'Greek': 223, 'Greeks': 224, 'Guiana': 225, 'Guyana': 226, 'Hagia': 227, 'Halicarnassus': 228, 'Hanging': 229, 'Harbor': 230, 'Havana': 231, 'Hawaii': 232, 'Heemskerck': 233, 'Hellenic': 234, 'Herodotus': 235, 'Hillah': 236, 'Holland': 237, 'Hoover': 238, 'Hunt:[21]': 239, 'Hạ': 240, 'Iguazu': 241, 'In': 242, 'India': 243, 'Indonesia': 244, 'Industrial': 245, 'International': 246, 'Internet': 247, 'Iowa': 248, 'Iraq': 249, 'Iraq;': 250, 'Islamic': 251, 'Island': 252, 'Islands': 253, 'Israel[n': 254, 'Istanbul': 255, 'Isthmus': 256, 'It': 257, 'Itaipu': 258, 'Italy': 259, 'Itza': 260, 'Janeiro': 261, 'January': 262, 'Jeju': 263, 'Jerusalem': 264, 'Jordan': 265, 'June': 266, 'Jupiter': 267, 'Kenya': 268, 'Kingdom': 269, 'Kom': 270, 'Komodo': 271, 'Korea': 272, 'Kuala': 273, 'La': 274, 'Lake': 275, 'Largest': 276, 'Leaning': 277, 'Lebanon': 278, 'Lhasa': 279, 'Lighthouse': 280, 'Lists': 281, 'Lloyd': 282, 'Location': 283, 'London': 284, 'Long': 285, 'Longest': 286, 'Lowell': 287, 'Lumpur': 288, 'Ma': 289, 'Maarten': 290, 'Machu': 291, 'Mahal': 292, 'Main': 293, 'Malaysia': 294, 'Many': 295, 'Map': 296, 'Mara': 297, 'March': 298, 'Marine': 299, 'Mars': 300, 'Masai': 301, 'Mausoleum': 302, 'Mausolus': 303, 'May': 304, 'Mayan': 305, 'Medieval': 306, 'Mediterranean': 307, 'Mexico': 308, 'Michoacán': 309, 'Middle': 310, 'Migration': 311, 'Mind': 312, 'Misiones': 313, 'Modern': 314, 'Mons': 315, 'Monument': 316, 'Moon': 317, 'Morning': 318, 'Mosul': 319, 'Mount': 320, 'Mountain': 321, 'Museum': 322, 'México': 323, 'Nanjing': 324, 'National': 325, 'Natural': 326, 'Nature': 327, 'Near': 328, 'Nebraska': 329, 'Neolithic': 330, 'Nepal': 331, 'Netherlands': 332, 'Nevada': 333, 'New': 334, 'New7Wonders': 335, 'Nineveh': 336, 'Ninh': 337, 'North': 338, 'Northern': 339, 'November': 340, 'October': 341, 'Old': 342, 'Olympia': 343, 'Olympus': 344, 'One': 345, 'Ontario': 346, 'Other': 347, 'Pacific': 348, 'Palace': 349, 'Palau': 350, 'Palawan': 351, 'Panama': 352, 'Papahānaumokuākea': 353, 'Paraguay': 354, 'Paraná': 355, 'Parícutin': 356, 'Paz': 357, 'Peninsula': 358, 'Peru': 359, 'Petra': 360, 'Philippines': 361, 'Phrase': 362, 'Picchu': 363, 'Pisa': 364, 'Polar': 365, 'Porcelain': 366, 'Potala': 367, 'Present-day': 368, 'Princesa': 369, 'Protection': 370, 'Province': 371, 'Puerto': 372, 'Pyramid': 373, 'Pyramids': 374, 'Qatar': 375, 'Qinhuai': 376, 'Queensland': 377, 'Quảng': 378, 'Recent': 379, 'Red': 380, 'Redeemer': 381, 'Reef': 382, 'Republic': 383, 'Rhodes': 384, 'Rings': 385, 'Rio': 386, 'River': 387, 'Rock': 388, 'Rome': 389, 'Russia': 390, 'SS': 391, 'San': 392, 'Saturn': 393, 'Saudi': 394, 'Saône-et-Loire': 395, 'Scotland': 396, 'Sea': 397, 'Selçuk': 398, 'Serengeti': 399, 'Seven': 400, 'Shoqafa': 401, 'Significance': 402, 'Similar': 403, 'Since': 404, 'Society': 405, 'Solar': 406, 'Some': 407, 'Sophia': 408, 'South': 409, 'Spot': 410, 'State': 411, 'States': 412, 'Statue': 413, 'Stonehenge': 414, 'Strait': 415, 'Sudan': 416, 'Sun': 417, 'Suriname': 418, 'Swiss': 419, 'System': 420, 'TV': 421, 'Table': 422, 'Taj': 423, 'Tallest': 424, 'Tanzania': 425, 'Temple': 426, 'The': 427, 'These': 428, 'This': 429, 'Thomas': 430, 'Tibet': 431, 'Today': 432, 'Toronto': 433, 'Tower': 434, 'Town': 435, 'Tunnel': 436, 'Turkey': 437, 'Typically': 438, 'USA': 439, 'Underground': 440, 'Underwater': 441, 'United': 442, 'Urubamba': 443, 'Utah': 444, 'Various': 445, 'Venezuela': 446, 'Victoria': 447, 'Vietnam': 448, 'Vigan': 449, 'Wall': 450, 'Washington': 451, 'Wikipedia': 452, 'Wiltshire': 453, 'Wonder': 454, 'Wonders': 455, 'Works': 456, 'World': 457, 'Worldwide': 458, 'Wyoming': 459, 'Yemen': 460, 'York': 461, 'Yucatán': 462, 'Zambia': 463, 'Zeeland': 464, 'Zeus': 465, 'Zimbabwe': 466, 'Zuiderzee': 467, '[10]': 468, '[11][12]': 469, '[14]': 470, '[15]': 471, '[17]': 472, '[18][19]': 473, '[1]': 474, '[22]': 475, '[23]': 476, '[24]': 477, '[2]': 478, '[3]': 479, '[4][5]': 480, '[8]': 481, '[9]': 482, 'a': 483, 'about': 484, 'achievements': 485, 'across': 486, 'actor': 487, 'actually': 488, 'added': 489, 'after': 490, 'aired': 491, 'also': 492, 'among': 493, 'amphitheatre': 494, 'an': 495, 'ancient': 496, 'and': 497, 'announced': 498, 'annual': 499, 'another': 500, 'anticyclonic': 501, 'antiquity': 502, 'antiquity;': 503, 'any': 504, 'are': 505, 'are:[3][4][6][7]': 506, 'areas': 507, 'around': 508, 'article': 509, 'article:': 510, 'artificial': 511, 'artist': 512, 'as': 513, 'asteroid': 514, 'at': 515, 'audience': 516, 'author': 517, 'authors': 518, 'bank': 519, 'based': 520, 'be': 521, 'because': 522, 'become': 523, 'been': 524, 'believed': 525, 'bell': 526, 'below': 527, 'belt': 528, 'between': 529, 'bodies': 530, 'book': 531, 'border': 532, 'bordered': 533, 'borders': 534, 'both': 535, 'bottom': 536, 'bridge': 537, 'brought': 538, 'building': 539, 'built': 540, 'but': 541, 'by': 542, 'c': 543, 'called': 544, 'campaign': 545, 'candidate': 546, 'candidates': 547, 'caps': 548, 'catalogue': 549, 'cathedral': 550, 'centre': 551, 'centuries': 552, 'century': 553, 'choose': 554, 'chosen': 555, 'cities:': 556, 'city': 557, 'civil': 558, 'classic': 559, 'classical': 560, 'coast': 561, 'compiled': 562, 'completed': 563, 'complex': 564, 'composed': 565, 'comprise': 566, 'concept': 567, 'connecting': 568, 'consensus': 569, 'considered': 570, 'construction': 571, 'contemporary': 572, 'continuous': 573, 'corporation': 574, 'create': 575, 'created': 576, 'creating': 577, 'creations': 578, 'crossing': 579, 'currently': 580, 'dated': 581, 'dating': 582, 'day': 583, 'de': 584, 'debate': 585, 'dedicated': 586, 'defensive': 587, 'depicted': 588, 'determined': 589, 'did': 590, 'difficult': 591, 'disambiguation': 592, 'divers': 593, 'docudrama': 594, 'documenting': 595, 'drawn': 596, 'during': 597, 'earlier': 598, 'earliest': 599, 'early': 600, 'eastern': 601, 'effort': 602, 'eighth': 603, 'emulated': 604, 'encyclopedia': 605, 'energy': 606, 'engineering': 607, 'enormous': 608, 'entire': 609, 'era': 610, 'eras': 611, 'ever': 612, 'except': 613, 'existence': 614, 'existing': 615, 'exists': 616, 'exploring': 617, 'external': 618, 'facility': 619, 'feats': 620, 'features': 621, 'feedback': 622, 'film': 623, 'finished': 624, 'first': 625, 'five': 626, 'for': 627, 'form': 628, 'fortification': 629, 'fortifications': 630, 'free': 631, 'freestanding': 632, 'from': 633, 'funerary': 634, 'generation[13]': 635, 'global': 636, 'great': 637, 'greatest': 638, 'group': 639, 'guidebooks': 640, 'harbor': 641, 'has': 642, 'have': 643, 'hemisphere': 644, 'henge': 645, 'high-latitude': 646, 'historian': 647, 'historical': 648, 'honorary': 649, 'how': 650, 'however': 651, 'human-built': 652, 'human-made': 653, 'hydraulic': 654, 'hydroelectric': 655, 'hydrothermal': 656, 'ice': 657, 'iconic': 658, 'in': 659, 'include:': 660, 'included': 661, 'includes': 662, 'including': 663, 'initiative': 664, 'innumerable': 665, 'into': 666, 'invented': 667, 'invites': 668, 'is': 669, 'island': 670, 'islands': 671, 'it': 672, 'judges': 673, 'km': 674, 'known': 675, 'large': 676, 'largest': 677, 'later': 678, 'least': 679, 'left': 680, 'line': 681, 'list': 682, 'list[s]': 683, 'listed': 684, 'lists': 685, 'located': 686, 'location': 687, 'made': 688, 'magazine': 689, 'main': 690, 'many': 691, 'marine': 692, 'massive': 693, 'medieval': 694, 'millennium': 695, 'modern': 696, 'monastery': 697, 'monument': 698, 'monuments': 699, 'moon': 700, 'mosque': 701, 'most': 702, 'mountain': 703, 'much': 704, 'name': 705, 'names': 706, 'national': 707, 'natural': 708, 'near': 709, 'networks': 710, 'newspaper': 711, 'no': 712, 'non-profit': 713, 'north': 714, 'northern': 715, 'not': 716, 'notable': 717, 'number': 718, 'ocean': 719, 'oceangoing': 720, 'oceans': 721, 'oceans;': 722, 'of': 723, 'off': 724, 'oldest': 725, 'on': 726, 'one': 727, 'online': 728, 'only': 729, 'opened': 730, 'operating': 731, 'opposed': 732, 'or': 733, 'orbits': 734, 'order': 735, 'organisations': 736, 'organized': 737, 'originally': 738, 'originated': 739, 'other': 740, 'over': 741, 'overlooking': 742, 'own': 743, 'pagoda': 744, 'panel': 745, 'passage': 746, 'passenger': 747, 'paying': 748, 'people': 749, 'perfection': 750, 'persistent': 751, 'phenomena': 752, 'places': 753, 'planet': 754, 'planetary': 755, 'planets': 756, 'plenty': 757, 'plus': 758, 'polar': 759, 'poll': 760, 'popular': 761, 'portion': 762, 'present': 763, 'present-day': 764, 'presented': 765, 'preservation': 766, 'producer': 767, 'project': 768, 'projects': 769, 'protection': 770, 'province': 771, 'public': 772, 'published': 773, 'rail': 774, 'railroad': 775, 'rainforest': 776, 'references': 777, 'refers': 778, 'reflected': 779, 'region': 780, 'regions': 781, 'remaining': 782, 'remarkable': 783, 'representative': 784, 'represented': 785, 'research': 786, 'response': 787, 'results': 788, 'revealed': 789, 'right': 790, 'rim': 791, 'ruins': 792, 's': 793, 'same': 794, 'scholar': 795, 'scientists': 796, 'searches': 797, 'see': 798, 'segments': 799, 'selection': 800, 'series': 801, 'serving': 802, 'seven': 803, 'seven-part': 804, 'sewerage': 805, 'shield': 806, 'shore': 807, 'should': 808, 'show': 809, 'sightseers': 810, 'similar': 811, 'since': 812, 'six': 813, 'small': 814, 'solid': 815, 'some': 816, 'sometimes': 817, 'south': 818, 'southern': 819, 'span': 820, 'spanning': 821, 'spectacular': 822, 'star': 823, 'started': 824, 'state': 825, 'steamship': 826, 'still': 827, 'stories': 828, 'storm': 829, 'structure': 830, 'structures': 831, 'such': 832, 'suggesting': 833, 'surface': 834, 'survived': 835, 'suspension': 836, 'system': 837, 'tallest': 838, 'television': 839, 'telling': 840, 'terms': 841, 'than': 842, 'that': 843, 'the': 844, 'their': 845, 'them': 846, 'there': 847, 'these': 848, 'they': 849, 'things': 850, 'third': 851, 'this': 852, 'through': 853, 'throughout': 854, 'times': 855, 'to': 856, 'together': 857, 'top': 858, 'tower': 859, 'tradition': 860, 'traditional': 861, 'transcontinental': 862, 'tribute': 863, 'try': 864, 'tunnel': 865, 'type': 866, 'undersea': 867, 'undertaken': 868, 'underwater': 869, 'unlikely': 870, 'until': 871, 'up': 872, 'update': 873, 'uses': 874, 'van': 875, 'various': 876, 'vents': 877, 'versions': 878, 'vessels': 879, 'video': 880, 'viewer': 881, 'viewer-chosen': 882, 'volcano': 883, 'vote': 884, 'votes': 885, 'was': 886, 'waterway': 887, 'well': 888, 'were': 889, 'were:': 890, 'western': 891, 'which': 892, 'winners': 893, 'with': 894, 'wonder': 895, 'wonderful': 896, 'wonders': 897, 'word': 898, 'works': 899, 'world': 900, 'worldwide': 901, 'worthy': 902, 'writers': 903, 'writings': 904, 'wrote': 905, '–': 906}\n",
            "{0: '\"', 1: \"'\", 2: '(', 3: ')', 4: ',', 5: '.', 6: '077', 7: '1', 8: '10', 9: '100', 10: '100+', 11: '10th-century', 12: '11', 13: '11th', 14: '12', 15: '12th-century', 16: '13th-century', 17: '1450', 18: '15th-century', 19: '1648', 20: '16th', 21: '16th-century', 22: '17', 23: '1810', 24: '1858', 25: '1869', 26: '1870', 27: '1880', 28: '1883', 29: '1914', 30: '1920', 31: '1930', 32: '1931', 33: '1933', 34: '1936', 35: '1937', 36: '1954;', 37: '1956', 38: '1964', 39: '1967;', 40: '1970', 41: '1970;', 42: '1973', 43: '1976', 44: '1984', 45: '1987', 46: '1989', 47: '1994', 48: '1997', 49: '1997:[16]', 50: '1999', 51: '19th', 52: '1]', 53: '1st-century', 54: '200', 55: '2001', 56: '2003', 57: '2006', 58: '2007', 59: '2011', 60: '20th', 61: '24', 62: '2560', 63: '26', 64: '27', 65: '2nd-century', 66: '3', 67: '305–240', 68: '3rd', 69: '425', 70: '484', 71: '5', 72: '508', 73: '51-mile', 74: '6', 75: '600', 76: '6th-century', 77: '7', 78: '7th', 79: '80', 80: '82', 81: '912-mile', 82: ':', 83: 'A', 84: 'AD', 85: 'Abbey', 86: 'Achaemenid', 87: 'Africa', 88: 'Age', 89: 'Ages', 90: 'Agra', 91: 'Alexandria', 92: 'Allows', 93: 'Amazon', 94: 'America', 95: 'American', 96: 'American-based', 97: 'Ancient', 98: 'Anglican', 99: 'Angus', 100: 'Antarctic', 101: 'April', 102: 'Aquarium', 103: 'Arabia', 104: 'Architectural', 105: 'Arctic', 106: 'Argentine', 107: 'Arizona', 108: 'Artemis', 109: 'Astronomy', 110: 'Atlantic', 111: 'Aurora', 112: 'Australia', 113: 'BBC', 114: 'BC', 115: 'BC[20]', 116: 'Babylon', 117: 'Baikal', 118: 'Barrier', 119: 'Bay', 120: 'Beirut', 121: 'Belize', 122: 'Bell', 123: 'Benedictine', 124: 'Bolivia', 125: 'Brazil', 126: 'Brazilian', 127: 'Brewer', 128: 'Bridge', 129: 'Bridges', 130: 'British', 131: 'Brooklyn', 132: 'Building', 133: 'C', 134: 'CEDAM', 135: 'CN', 136: 'CNN', 137: 'Cadbury', 138: 'Cairo', 139: 'California', 140: 'Calle', 141: 'Callimachus', 142: 'Cambridgeshire', 143: 'Canada', 144: 'Canal', 145: 'Canyon', 146: 'Cape', 147: 'Castillo', 148: 'Catacombs', 149: 'Cathedral', 150: 'Channel', 151: 'Chichen', 152: 'China', 153: 'Christ', 154: 'Citadel', 155: 'Cities', 156: 'City', 157: 'Civil', 158: 'Clark', 159: 'Cluny', 160: 'Colombia', 161: 'Colorado', 162: 'Colosseum', 163: 'Colossus', 164: 'Completed', 165: 'Crisologo', 166: 'Cuba', 167: 'Cyrene', 168: 'D', 169: 'Dam', 170: 'Date', 171: 'Deborah', 172: 'December', 173: 'Deep-sea', 174: 'Delta', 175: 'Description', 176: 'Dictionary', 177: 'Djibouti', 178: 'Doha', 179: 'Dover', 180: 'Durban', 181: 'Dutch', 182: 'Earth', 183: 'East', 184: 'Eastern', 185: 'Ecuador', 186: 'Egypt', 187: 'El', 188: 'Ely', 189: 'Empire', 190: 'Enceladus', 191: 'Engineers', 192: 'England', 193: 'English', 194: 'Enlightenment', 195: 'Ephesus', 196: 'Eritrea', 197: 'Eugenie', 198: 'Everest', 199: 'Fable', 200: 'Falls', 201: 'February', 202: 'First', 203: 'Flevoland', 204: 'Following', 205: 'For', 206: 'Foundation', 207: 'France', 208: 'Francisco', 209: 'French', 210: 'Friesland', 211: 'From', 212: 'Galápagos', 213: 'Gardens', 214: 'Gate', 215: 'Giza', 216: 'Giza—part', 217: 'Golden', 218: 'Good', 219: 'Governorate', 220: 'Grand', 221: 'Great', 222: 'Greece', 223: 'Greek', 224: 'Greeks', 225: 'Guiana', 226: 'Guyana', 227: 'Hagia', 228: 'Halicarnassus', 229: 'Hanging', 230: 'Harbor', 231: 'Havana', 232: 'Hawaii', 233: 'Heemskerck', 234: 'Hellenic', 235: 'Herodotus', 236: 'Hillah', 237: 'Holland', 238: 'Hoover', 239: 'Hunt:[21]', 240: 'Hạ', 241: 'Iguazu', 242: 'In', 243: 'India', 244: 'Indonesia', 245: 'Industrial', 246: 'International', 247: 'Internet', 248: 'Iowa', 249: 'Iraq', 250: 'Iraq;', 251: 'Islamic', 252: 'Island', 253: 'Islands', 254: 'Israel[n', 255: 'Istanbul', 256: 'Isthmus', 257: 'It', 258: 'Itaipu', 259: 'Italy', 260: 'Itza', 261: 'Janeiro', 262: 'January', 263: 'Jeju', 264: 'Jerusalem', 265: 'Jordan', 266: 'June', 267: 'Jupiter', 268: 'Kenya', 269: 'Kingdom', 270: 'Kom', 271: 'Komodo', 272: 'Korea', 273: 'Kuala', 274: 'La', 275: 'Lake', 276: 'Largest', 277: 'Leaning', 278: 'Lebanon', 279: 'Lhasa', 280: 'Lighthouse', 281: 'Lists', 282: 'Lloyd', 283: 'Location', 284: 'London', 285: 'Long', 286: 'Longest', 287: 'Lowell', 288: 'Lumpur', 289: 'Ma', 290: 'Maarten', 291: 'Machu', 292: 'Mahal', 293: 'Main', 294: 'Malaysia', 295: 'Many', 296: 'Map', 297: 'Mara', 298: 'March', 299: 'Marine', 300: 'Mars', 301: 'Masai', 302: 'Mausoleum', 303: 'Mausolus', 304: 'May', 305: 'Mayan', 306: 'Medieval', 307: 'Mediterranean', 308: 'Mexico', 309: 'Michoacán', 310: 'Middle', 311: 'Migration', 312: 'Mind', 313: 'Misiones', 314: 'Modern', 315: 'Mons', 316: 'Monument', 317: 'Moon', 318: 'Morning', 319: 'Mosul', 320: 'Mount', 321: 'Mountain', 322: 'Museum', 323: 'México', 324: 'Nanjing', 325: 'National', 326: 'Natural', 327: 'Nature', 328: 'Near', 329: 'Nebraska', 330: 'Neolithic', 331: 'Nepal', 332: 'Netherlands', 333: 'Nevada', 334: 'New', 335: 'New7Wonders', 336: 'Nineveh', 337: 'Ninh', 338: 'North', 339: 'Northern', 340: 'November', 341: 'October', 342: 'Old', 343: 'Olympia', 344: 'Olympus', 345: 'One', 346: 'Ontario', 347: 'Other', 348: 'Pacific', 349: 'Palace', 350: 'Palau', 351: 'Palawan', 352: 'Panama', 353: 'Papahānaumokuākea', 354: 'Paraguay', 355: 'Paraná', 356: 'Parícutin', 357: 'Paz', 358: 'Peninsula', 359: 'Peru', 360: 'Petra', 361: 'Philippines', 362: 'Phrase', 363: 'Picchu', 364: 'Pisa', 365: 'Polar', 366: 'Porcelain', 367: 'Potala', 368: 'Present-day', 369: 'Princesa', 370: 'Protection', 371: 'Province', 372: 'Puerto', 373: 'Pyramid', 374: 'Pyramids', 375: 'Qatar', 376: 'Qinhuai', 377: 'Queensland', 378: 'Quảng', 379: 'Recent', 380: 'Red', 381: 'Redeemer', 382: 'Reef', 383: 'Republic', 384: 'Rhodes', 385: 'Rings', 386: 'Rio', 387: 'River', 388: 'Rock', 389: 'Rome', 390: 'Russia', 391: 'SS', 392: 'San', 393: 'Saturn', 394: 'Saudi', 395: 'Saône-et-Loire', 396: 'Scotland', 397: 'Sea', 398: 'Selçuk', 399: 'Serengeti', 400: 'Seven', 401: 'Shoqafa', 402: 'Significance', 403: 'Similar', 404: 'Since', 405: 'Society', 406: 'Solar', 407: 'Some', 408: 'Sophia', 409: 'South', 410: 'Spot', 411: 'State', 412: 'States', 413: 'Statue', 414: 'Stonehenge', 415: 'Strait', 416: 'Sudan', 417: 'Sun', 418: 'Suriname', 419: 'Swiss', 420: 'System', 421: 'TV', 422: 'Table', 423: 'Taj', 424: 'Tallest', 425: 'Tanzania', 426: 'Temple', 427: 'The', 428: 'These', 429: 'This', 430: 'Thomas', 431: 'Tibet', 432: 'Today', 433: 'Toronto', 434: 'Tower', 435: 'Town', 436: 'Tunnel', 437: 'Turkey', 438: 'Typically', 439: 'USA', 440: 'Underground', 441: 'Underwater', 442: 'United', 443: 'Urubamba', 444: 'Utah', 445: 'Various', 446: 'Venezuela', 447: 'Victoria', 448: 'Vietnam', 449: 'Vigan', 450: 'Wall', 451: 'Washington', 452: 'Wikipedia', 453: 'Wiltshire', 454: 'Wonder', 455: 'Wonders', 456: 'Works', 457: 'World', 458: 'Worldwide', 459: 'Wyoming', 460: 'Yemen', 461: 'York', 462: 'Yucatán', 463: 'Zambia', 464: 'Zeeland', 465: 'Zeus', 466: 'Zimbabwe', 467: 'Zuiderzee', 468: '[10]', 469: '[11][12]', 470: '[14]', 471: '[15]', 472: '[17]', 473: '[18][19]', 474: '[1]', 475: '[22]', 476: '[23]', 477: '[24]', 478: '[2]', 479: '[3]', 480: '[4][5]', 481: '[8]', 482: '[9]', 483: 'a', 484: 'about', 485: 'achievements', 486: 'across', 487: 'actor', 488: 'actually', 489: 'added', 490: 'after', 491: 'aired', 492: 'also', 493: 'among', 494: 'amphitheatre', 495: 'an', 496: 'ancient', 497: 'and', 498: 'announced', 499: 'annual', 500: 'another', 501: 'anticyclonic', 502: 'antiquity', 503: 'antiquity;', 504: 'any', 505: 'are', 506: 'are:[3][4][6][7]', 507: 'areas', 508: 'around', 509: 'article', 510: 'article:', 511: 'artificial', 512: 'artist', 513: 'as', 514: 'asteroid', 515: 'at', 516: 'audience', 517: 'author', 518: 'authors', 519: 'bank', 520: 'based', 521: 'be', 522: 'because', 523: 'become', 524: 'been', 525: 'believed', 526: 'bell', 527: 'below', 528: 'belt', 529: 'between', 530: 'bodies', 531: 'book', 532: 'border', 533: 'bordered', 534: 'borders', 535: 'both', 536: 'bottom', 537: 'bridge', 538: 'brought', 539: 'building', 540: 'built', 541: 'but', 542: 'by', 543: 'c', 544: 'called', 545: 'campaign', 546: 'candidate', 547: 'candidates', 548: 'caps', 549: 'catalogue', 550: 'cathedral', 551: 'centre', 552: 'centuries', 553: 'century', 554: 'choose', 555: 'chosen', 556: 'cities:', 557: 'city', 558: 'civil', 559: 'classic', 560: 'classical', 561: 'coast', 562: 'compiled', 563: 'completed', 564: 'complex', 565: 'composed', 566: 'comprise', 567: 'concept', 568: 'connecting', 569: 'consensus', 570: 'considered', 571: 'construction', 572: 'contemporary', 573: 'continuous', 574: 'corporation', 575: 'create', 576: 'created', 577: 'creating', 578: 'creations', 579: 'crossing', 580: 'currently', 581: 'dated', 582: 'dating', 583: 'day', 584: 'de', 585: 'debate', 586: 'dedicated', 587: 'defensive', 588: 'depicted', 589: 'determined', 590: 'did', 591: 'difficult', 592: 'disambiguation', 593: 'divers', 594: 'docudrama', 595: 'documenting', 596: 'drawn', 597: 'during', 598: 'earlier', 599: 'earliest', 600: 'early', 601: 'eastern', 602: 'effort', 603: 'eighth', 604: 'emulated', 605: 'encyclopedia', 606: 'energy', 607: 'engineering', 608: 'enormous', 609: 'entire', 610: 'era', 611: 'eras', 612: 'ever', 613: 'except', 614: 'existence', 615: 'existing', 616: 'exists', 617: 'exploring', 618: 'external', 619: 'facility', 620: 'feats', 621: 'features', 622: 'feedback', 623: 'film', 624: 'finished', 625: 'first', 626: 'five', 627: 'for', 628: 'form', 629: 'fortification', 630: 'fortifications', 631: 'free', 632: 'freestanding', 633: 'from', 634: 'funerary', 635: 'generation[13]', 636: 'global', 637: 'great', 638: 'greatest', 639: 'group', 640: 'guidebooks', 641: 'harbor', 642: 'has', 643: 'have', 644: 'hemisphere', 645: 'henge', 646: 'high-latitude', 647: 'historian', 648: 'historical', 649: 'honorary', 650: 'how', 651: 'however', 652: 'human-built', 653: 'human-made', 654: 'hydraulic', 655: 'hydroelectric', 656: 'hydrothermal', 657: 'ice', 658: 'iconic', 659: 'in', 660: 'include:', 661: 'included', 662: 'includes', 663: 'including', 664: 'initiative', 665: 'innumerable', 666: 'into', 667: 'invented', 668: 'invites', 669: 'is', 670: 'island', 671: 'islands', 672: 'it', 673: 'judges', 674: 'km', 675: 'known', 676: 'large', 677: 'largest', 678: 'later', 679: 'least', 680: 'left', 681: 'line', 682: 'list', 683: 'list[s]', 684: 'listed', 685: 'lists', 686: 'located', 687: 'location', 688: 'made', 689: 'magazine', 690: 'main', 691: 'many', 692: 'marine', 693: 'massive', 694: 'medieval', 695: 'millennium', 696: 'modern', 697: 'monastery', 698: 'monument', 699: 'monuments', 700: 'moon', 701: 'mosque', 702: 'most', 703: 'mountain', 704: 'much', 705: 'name', 706: 'names', 707: 'national', 708: 'natural', 709: 'near', 710: 'networks', 711: 'newspaper', 712: 'no', 713: 'non-profit', 714: 'north', 715: 'northern', 716: 'not', 717: 'notable', 718: 'number', 719: 'ocean', 720: 'oceangoing', 721: 'oceans', 722: 'oceans;', 723: 'of', 724: 'off', 725: 'oldest', 726: 'on', 727: 'one', 728: 'online', 729: 'only', 730: 'opened', 731: 'operating', 732: 'opposed', 733: 'or', 734: 'orbits', 735: 'order', 736: 'organisations', 737: 'organized', 738: 'originally', 739: 'originated', 740: 'other', 741: 'over', 742: 'overlooking', 743: 'own', 744: 'pagoda', 745: 'panel', 746: 'passage', 747: 'passenger', 748: 'paying', 749: 'people', 750: 'perfection', 751: 'persistent', 752: 'phenomena', 753: 'places', 754: 'planet', 755: 'planetary', 756: 'planets', 757: 'plenty', 758: 'plus', 759: 'polar', 760: 'poll', 761: 'popular', 762: 'portion', 763: 'present', 764: 'present-day', 765: 'presented', 766: 'preservation', 767: 'producer', 768: 'project', 769: 'projects', 770: 'protection', 771: 'province', 772: 'public', 773: 'published', 774: 'rail', 775: 'railroad', 776: 'rainforest', 777: 'references', 778: 'refers', 779: 'reflected', 780: 'region', 781: 'regions', 782: 'remaining', 783: 'remarkable', 784: 'representative', 785: 'represented', 786: 'research', 787: 'response', 788: 'results', 789: 'revealed', 790: 'right', 791: 'rim', 792: 'ruins', 793: 's', 794: 'same', 795: 'scholar', 796: 'scientists', 797: 'searches', 798: 'see', 799: 'segments', 800: 'selection', 801: 'series', 802: 'serving', 803: 'seven', 804: 'seven-part', 805: 'sewerage', 806: 'shield', 807: 'shore', 808: 'should', 809: 'show', 810: 'sightseers', 811: 'similar', 812: 'since', 813: 'six', 814: 'small', 815: 'solid', 816: 'some', 817: 'sometimes', 818: 'south', 819: 'southern', 820: 'span', 821: 'spanning', 822: 'spectacular', 823: 'star', 824: 'started', 825: 'state', 826: 'steamship', 827: 'still', 828: 'stories', 829: 'storm', 830: 'structure', 831: 'structures', 832: 'such', 833: 'suggesting', 834: 'surface', 835: 'survived', 836: 'suspension', 837: 'system', 838: 'tallest', 839: 'television', 840: 'telling', 841: 'terms', 842: 'than', 843: 'that', 844: 'the', 845: 'their', 846: 'them', 847: 'there', 848: 'these', 849: 'they', 850: 'things', 851: 'third', 852: 'this', 853: 'through', 854: 'throughout', 855: 'times', 856: 'to', 857: 'together', 858: 'top', 859: 'tower', 860: 'tradition', 861: 'traditional', 862: 'transcontinental', 863: 'tribute', 864: 'try', 865: 'tunnel', 866: 'type', 867: 'undersea', 868: 'undertaken', 869: 'underwater', 870: 'unlikely', 871: 'until', 872: 'up', 873: 'update', 874: 'uses', 875: 'van', 876: 'various', 877: 'vents', 878: 'versions', 879: 'vessels', 880: 'video', 881: 'viewer', 882: 'viewer-chosen', 883: 'volcano', 884: 'vote', 885: 'votes', 886: 'was', 887: 'waterway', 888: 'well', 889: 'were', 890: 'were:', 891: 'western', 892: 'which', 893: 'winners', 894: 'with', 895: 'wonder', 896: 'wonderful', 897: 'wonders', 898: 'word', 899: 'works', 900: 'world', 901: 'worldwide', 902: 'worthy', 903: 'writers', 904: 'writings', 905: 'wrote', 906: '–'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_txt = \"right scientists results............\"\n",
        "tknzr.encode(test_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGEtO74H93hZ",
        "outputId": "d7fa039f-c67d-4bed-edd9-d2b6ce55ba72"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessed_text -- ['right', 'scientists', 'results', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[790, 796, 788, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = [790, 796, 788, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
        "tknzr.decode(test_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L_RXHLUV-JZ_",
        "outputId": "d1e981a3-98ee-46f0-a5d0-d44e1e4ddd56"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'right scientists results............'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOrRhZqZAaaT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jE5ceqxLAbSH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**BPE - Byte Pair Encoding**"
      ],
      "metadata": {
        "id": "FeJyUboCLnsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "Q1qJX0I4AbI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce74ec8-292c-431e-e18e-ac46fa75477f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "J1SLUCZ5Aevj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([3506, 5519, 2482])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JRAkGKanAtGi",
        "outputId": "2877971a-a47a-4be4-807f-232ff2fd4858"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'right scientists results'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GgM9aqpfA5vh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terra\"\n",
        "tkn_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(tkn_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoGEJ58rBQAo",
        "outputId": "e148f854-5899-4191-d9c8-7cc7e14b0e86"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 1059, 430]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tkn_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IboNoqgGBiTw",
        "outputId": "3a6ef3d0-6dad-405c-898b-e7fa8c402ed5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, do you like tea? <|endoftext|> In the sunlit terra'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gibberish_txt = \"awkyummy simplysuperb neetlykept\"\n",
        "tkn_ids = tokenizer.encode(gibberish_txt)\n",
        "print(tkn_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP-OiQjKBphB",
        "outputId": "4954a838-49d6-4587-a6de-d07e9a6bd195"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[707, 2584, 13513, 2391, 16668, 65, 497, 316, 306, 45089]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer.decode(tkn_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_HgvlU0VB6Lo",
        "outputId": "86c91e9f-5501-4aa1-bf25-64bf32e8e9de"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'awkyummy simplysuperb neetlykept'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"qwghnyklmnaorcbddbcj\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWBUG156CCrw",
        "outputId": "5d55a4bf-f1f3-4fa1-989b-4b45b86a703f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[80, 86, 456, 3281, 41582, 76, 2616, 273, 21101, 1860, 15630, 73]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([80, 86, 456, 3281, 41582, 76, 2616, 273, 21101, 1860, 15630, 73])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6hQXSOuKCJPi",
        "outputId": "f9ea2471-4430-4f7c-bc99-3b8349157311"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'qwghnyklmnaorcbddbcj'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [707, 2584, 13513, 2391, 16668, 65, 497, 316, 306, 45089]:\n",
        "  print(tokenizer.decode([i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZv1qvyNCNXS",
        "outputId": "fc78741d-db3e-4625-fc26-60dad1405670"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aw\n",
            "ky\n",
            "ummy\n",
            " simply\n",
            "super\n",
            "b\n",
            " ne\n",
            "et\n",
            "ly\n",
            "kept\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"Akwirwier\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4GcVsciDOiQ",
        "outputId": "052acd2e-1d50-4511-e77a-82fd9d5cd29e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[33901, 86, 343, 86, 959]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_E2e54WKoYQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EADvb9KfKoJK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.6 Data sampling with a sliding window**\n",
        "it's the process of creating input seq's and target words"
      ],
      "metadata": {
        "id": "LTdYKuvjKp4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "cQxJmaxjKu3A",
        "outputId": "164eb6cf-1387-4802-97fe-a1e3f847be7b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\\n\\n\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it\\'s going to send the value of my picture \\'way up; but I don\\'t think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing\\'s lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn\\'s \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\\n\\nWell!--even through the prism of Hermia\\'s tears I felt able to face the fact with equanimity. Poor Jack Gisburn! The women had made him--it was fitting that they should mourn him. Among his own sex fewer regrets were heard, and in his own trade hardly a murmur. Professional jealousy? Perhaps. If it were, the honour of the craft was vindicated by little Claude Nutley, who, in all good faith, brought out in the Burlington a very handsome \"obituary\" on Jack--one of those showy articles stocked with random technicalities that I have heard (I won\\'t say by whom) compared to Gisburn\\'s painting. And so--his resolve being apparently irrevocable--the discussion gradually died out, and, as Mrs. Thwing had predicted, the price of \"Gisburns\" went up.\\n\\nIt was not till three years later that, in the course of a few weeks\\' idling on the Riviera, it suddenly occurred to me to wonder why Gisburn had given up his painting. On reflection, it really was a tempting problem. To accuse his wife would have been too easy--his fair sitters had been denied the solace of saying that Mrs. Gisburn had \"dragged him down.\" For Mrs. Gisburn--as such--had not existed till nearly a year after Jack\\'s resolve had been taken. It might be that he had married her--since he liked his ease--because he didn\\'t want to go on painting; but it would have been hard to prove that he had given up his painting because he had married her.\\n\\nOf course, if she had not dragged him down, she had equally, as Miss Croft contended, failed to \"lift him up\"--she had not led him back to the easel. To put the brush into his hand again--what a vocation for a wife! But Mrs. Gisburn appeared to have disdained it--and I felt it might be interesting to find out why.\\n\\nThe desultory life of the Riviera lends itself to such purely academic speculations; and having, on my way to Monte Carlo, caught a glimpse of Jack\\'s balustraded terraces between the pines, I had myself borne thither the next day.\\n\\nI found the couple at tea beneath their palm-trees; and Mrs. Gisburn\\'s welcome was so genial that, in the ensuing weeks, I claimed it frequently. It was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. It was just because she was _not_ interesting--if I may be pardoned the bull--that I found her so. For Jack, all his life, had been surrounded by interesting women: they had fostered his art, it had been reared in the hot-house of their adulation. And it was therefore instructive to note what effect the \"deadening atmosphere of mediocrity\" (I quote Miss Croft) was having on him.\\n\\nI have mentioned that Mrs. Gisburn was rich; and it was immediately perceptible that her husband was extracting from this circumstance a delicate but substantial satisfaction. It is, as a rule, the people who scorn money who get most out of it; and Jack\\'s elegant disdain of his wife\\'s big balance enabled him, with an appearance of perfect good-breeding, to transmute it into objects of art and luxury. To the latter, I must add, he remained relatively indifferent; but he was buying Renaissance bronzes and eighteenth-century pictures with a discrimination that bespoke the amplest resources.\\n\\n\"Money\\'s only excuse is to put beauty into circulation,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gisburn, beaming on him, added for my enlightenment: \"Jack is so morbidly sensitive to every form of beauty.\"\\n\\nPoor Jack! It had always been his fate to have women say such things of him: the fact should be set down in extenuation. What struck me now was that, for the first time, he resented the tone. I had seen him, so often, basking under similar tributes--was it the conjugal note that robbed them of their savour? No--for, oddly enough, it became apparent that he was fond of Mrs. Gisburn--fond enough not to see her absurdity. It was his own absurdity he seemed to be wincing under--his own attitude as an object for garlands and incense.\\n\\n\"My dear, since I\\'ve chucked painting people don\\'t say that stuff about me--they say it about Victor Grindle,\" was his only protest, as he rose from the table and strolled out onto the sunlit terrace.\\n\\nI glanced after him, struck by his last word. Victor Grindle was, in fact, becoming the man of the moment--as Jack himself, one might put it, had been the man of the hour. The younger artist was said to have formed himself at my friend\\'s feet, and I wondered if a tinge of jealousy underlay the latter\\'s mysterious abdication. But no--for it was not till after that event that the _rose Dubarry_ drawing-rooms had begun to display their \"Grindles.\"\\n\\nI turned to Mrs. Gisburn, who had lingered to give a lump of sugar to her spaniel in the dining-room.\\n\\n\"Why _has_ he chucked painting?\" I asked abruptly.\\n\\nShe raised her eyebrows with a hint of good-humoured surprise.\\n\\n\"Oh, he doesn\\'t _have_ to now, you know; and I want him to enjoy himself,\" she said quite simply.\\n\\nI looked about the spacious white-panelled room, with its _famille-verte_ vases repeating the tones of the pale damask curtains, and its eighteenth-century pastels in delicate faded frames.\\n\\n\"Has he chucked his pictures too? I haven\\'t seen a single one in the house.\"\\n\\nA slight shade of constraint crossed Mrs. Gisburn\\'s open countenance. \"It\\'s his ridiculous modesty, you know. He says they\\'re not fit to have about; he\\'s sent them all away except one--my portrait--and that I have to keep upstairs.\"\\n\\nHis ridiculous modesty--Jack\\'s modesty about his pictures? My curiosity was growing like the bean-stalk. I said persuasively to my hostess: \"I must really see your portrait, you know.\"\\n\\nShe glanced out almost timorously at the terrace where her husband, lounging in a hooded chair, had lit a cigar and drawn the Russian deerhound\\'s head between his knees.\\n\\n\"Well, come while he\\'s not looking,\" she said, with a laugh that tried to hide her nervousness; and I followed her between the marble Emperors of the hall, and up the wide stairs with terra-cotta nymphs poised among flowers at each landing.\\n\\nIn the dimmest corner of her boudoir, amid a profusion of delicate and distinguished objects, hung one of the familiar oval canvases, in the inevitable garlanded frame. The mere outline of the frame called up all Gisburn\\'s past!\\n\\nMrs. Gisburn drew back the window-curtains, moved aside a _jardiniere_ full of pink azaleas, pushed an arm-chair away, and said: \"If you stand here you can just manage to see it. I had it over the mantel-piece, but he wouldn\\'t let it stay.\"\\n\\nYes--I could just manage to see it--the first portrait of Jack\\'s I had ever had to strain my eyes over! Usually they had the place of honour--say the central panel in a pale yellow or _rose Dubarry_ drawing-room, or a monumental easel placed so that it took the light through curtains of old Venetian point. The more modest place became the picture better; yet, as my eyes grew accustomed to the half-light, all the characteristic qualities came out--all the hesitations disguised as audacities, the tricks of prestidigitation by which, with such consummate skill, he managed to divert attention from the real business of the picture to some pretty irrelevance of detail. Mrs. Gisburn, presenting a neutral surface to work on--forming, as it were, so inevitably the background of her own picture--had lent herself in an unusual degree to the display of this false virtuosity. The picture was one of Jack\\'s \"strongest,\" as his admirers would have put it--it represented, on his part, a swelling of muscles, a congesting of veins, a balancing, straddling and straining, that reminded one of the circus-clown\\'s ironic efforts to lift a feather. It met, in short, at every point the demand of lovely woman to be painted \"strongly\" because she was tired of being painted \"sweetly\"--and yet not to lose an atom of the sweetness.\\n\\n\"It\\'s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride. \"The last but one,\" she corrected herself--\"but the other doesn\\'t count, because he destroyed it.\"\\n\\n\"Destroyed it?\" I was about to follow up this clue when I heard a footstep and saw Jack himself on the threshold.\\n\\nAs he stood there, his hands in the pockets of his velveteen coat, the thin brown waves of hair pushed back from his white forehead, his lean sunburnt cheeks furrowed by a smile that lifted the tips of a self-confident moustache, I felt to what a degree he had the same quality as his pictures--the quality of looking cleverer than he was.\\n\\nHis wife glanced at him deprecatingly, but his eyes travelled past her to the portrait.\\n\\n\"Mr. Rickham wanted to see it,\" she began, as if excusing herself. He shrugged his shoulders, still smiling.\\n\\n\"Oh, Rickham found me out long ago,\" he said lightly; then, passing his arm through mine: \"Come and see the rest of the house.\"\\n\\nHe showed it to me with a kind of naive suburban pride: the bath-rooms, the speaking-tubes, the dress-closets, the trouser-presses--all the complex simplifications of the millionaire\\'s domestic economy. And whenever my wonder paid the expected tribute he said, throwing out his chest a little: \"Yes, I really don\\'t see how people manage to live without that.\"\\n\\nWell--it was just the end one might have foreseen for him. Only he was, through it all and in spite of it all--as he had been through, and in spite of, his pictures--so handsome, so charming, so disarming, that one longed to cry out: \"Be dissatisfied with your leisure!\" as once one had longed to say: \"Be dissatisfied with your work!\"\\n\\nBut, with the cry on my lips, my diagnosis suffered an unexpected check.\\n\\n\"This is my own lair,\" he said, leading me into a dark plain room at the end of the florid vista. It was square and brown and leathery: no \"effects\"; no bric-a-brac, none of the air of posing for reproduction in a picture weekly--above all, no least sign of ever having been used as a studio.\\n\\nThe fact brought home to me the absolute finality of Jack\\'s break with his old life.\\n\\n\"Don\\'t you ever dabble with paint any more?\" I asked, still looking about for a trace of such activity.\\n\\n\"Never,\" he said briefly.\\n\\n\"Or water-colour--or etching?\"\\n\\nHis confident eyes grew dim, and his cheeks paled a little under their handsome sunburn.\\n\\n\"Never think of it, my dear fellow--any more than if I\\'d never touched a brush.\"\\n\\nAnd his tone told me in a flash that he never thought of anything else.\\n\\nI moved away, instinctively embarrassed by my unexpected discovery; and as I turned, my eye fell on a small picture above the mantel-piece--the only object breaking the plain oak panelling of the room.\\n\\n\"Oh, by Jove!\" I said.\\n\\nIt was a sketch of a donkey--an old tired donkey, standing in the rain under a wall.\\n\\n\"By Jove--a Stroud!\" I cried.\\n\\nHe was silent; but I felt him close behind me, breathing a little quickly.\\n\\n\"What a wonder! Made with a dozen lines--but on everlasting foundations. You lucky chap, where did you get it?\"\\n\\nHe answered slowly: \"Mrs. Stroud gave it to me.\"\\n\\n\"Ah--I didn\\'t know you even knew the Strouds. He was such an inflexible hermit.\"\\n\\n\"I didn\\'t--till after. . . . She sent for me to paint him when he was dead.\"\\n\\n\"When he was dead? You?\"\\n\\nI must have let a little too much amazement escape through my surprise, for he answered with a deprecating laugh: \"Yes--she\\'s an awful simpleton, you know, Mrs. Stroud. Her only idea was to have him done by a fashionable painter--ah, poor Stroud! She thought it the surest way of proclaiming his greatness--of forcing it on a purblind public. And at the moment I was _the_ fashionable painter.\"\\n\\n\"Ah, poor Stroud--as you say. Was _that_ his history?\"\\n\\n\"That was his history. She believed in him, gloried in him--or thought she did. But she couldn\\'t bear not to have all the drawing-rooms with her. She couldn\\'t bear the fact that, on varnishing days, one could always get near enough to see his pictures. Poor woman! She\\'s just a fragment groping for other fragments. Stroud is the only whole I ever knew.\"\\n\\n\"You ever knew? But you just said--\"\\n\\nGisburn had a curious smile in his eyes.\\n\\n\"Oh, I knew him, and he knew me--only it happened after he was dead.\"\\n\\nI dropped my voice instinctively. \"When she sent for you?\"\\n\\n\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\\n\\nHe laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I couldn\\'t look at that thing--couldn\\'t face it. But I forced myself to put it here; and now it\\'s cured me--cured me. That\\'s the reason why I don\\'t dabble any more, my dear Rickham; or rather Stroud himself is the reason.\"\\n\\nFor the first time my idle curiosity about my companion turned into a serious desire to understand him better.\\n\\n\"I wish you\\'d tell me how it happened,\" I said.\\n\\nHe stood looking up at the sketch, and twirling between his fingers a cigarette he had forgotten to light. Suddenly he turned toward me.\\n\\n\"I\\'d rather like to tell you--because I\\'ve always suspected you of loathing my work.\"\\n\\nI made a deprecating gesture, which he negatived with a good-humoured shrug.\\n\\n\"Oh, I didn\\'t care a straw when I believed in myself--and now it\\'s an added tie between us!\"\\n\\nHe laughed slightly, without bitterness, and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"\\n\\nHe placed them at my elbow and continued to wander up and down the room, stopping now and then beneath the picture.\\n\\n\"How it happened? I can tell you in five minutes--and it didn\\'t take much longer to happen. . . . I can remember now how surprised and pleased I was when I got Mrs. Stroud\\'s note. Of course, deep down, I had always _felt_ there was no one like him--only I had gone with the stream, echoed the usual platitudes about him, till I half got to think he was a failure, one of the kind that are left behind. By Jove, and he _was_ left behind--because he had come to stay! The rest of us had to let ourselves be swept along or go under, but he was high above the current--on everlasting foundations, as you say.\\n\\n\"Well, I went off to the house in my most egregious mood--rather moved, Lord forgive me, at the pathos of poor Stroud\\'s career of failure being crowned by the glory of my painting him! Of course I meant to do the picture for nothing--I told Mrs. Stroud so when she began to stammer something about her poverty. I remember getting off a prodigious phrase about the honour being _mine_--oh, I was princely, my dear Rickham! I was posing to myself like one of my own sitters.\\n\\n\"Then I was taken up and left alone with him. I had sent all my traps in advance, and I had only to set up the easel and get to work. He had been dead only twenty-four hours, and he died suddenly, of heart disease, so that there had been no preliminary work of destruction--his face was clear and untouched. I had met him once or twice, years before, and thought him insignificant and dingy. Now I saw that he was superb.\\n\\n\"I was glad at first, with a merely aesthetic satisfaction: glad to have my hand on such a \\'subject.\\' Then his strange life-likeness began to affect me queerly--as I blocked the head in I felt as if he were watching me do it. The sensation was followed by the thought: if he _were_ watching me, what would he say to my way of working? My strokes began to go a little wild--I felt nervous and uncertain.\\n\\n\"Once, when I looked up, I seemed to see a smile behind his close grayish beard--as if he had the secret, and were amusing himself by holding it back from me. That exasperated me still more. The secret? Why, I had a secret worth twenty of his! I dashed at the canvas furiously, and tried some of my bravura tricks. But they failed me, they crumbled. I saw that he wasn\\'t watching the showy bits--I couldn\\'t distract his attention; he just kept his eyes on the hard passages between. Those were the ones I had always shirked, or covered up with some lying paint. And how he saw through my lies!\\n\\n\"I looked up again, and caught sight of that sketch of the donkey hanging on the wall near his bed. His wife told me afterward it was the last thing he had done--just a note taken with a shaking hand, when he was down in Devonshire recovering from a previous heart attack. Just a note! But it tells his whole history. There are years of patient scornful persistence in every line. A man who had swum with the current could never have learned that mighty up-stream stroke. . . .\\n\\n\"I turned back to my work, and went on groping and muddling; then I looked at the donkey again. I saw that, when Stroud laid in the first stroke, he knew just what the end would be. He had possessed his subject, absorbed it, recreated it. When had I done that with any of my things? They hadn\\'t been born of me--I had just adopted them. . . .\\n\\n\"Hang it, Rickham, with that face watching me I couldn\\'t do another stroke. The plain truth was, I didn\\'t know where to put it--_I had never known_. Only, with my sitters and my public, a showy splash of colour covered up the fact--I just threw paint into their faces. . . . Well, paint was the one medium those dead eyes could see through--see straight to the tottering foundations underneath. Don\\'t you know how, in talking a foreign language, even fluently, one says half the time not what one wants to but what one can? Well--that was the way I painted; and as he lay there and watched me, the thing they called my \\'technique\\' collapsed like a house of cards. He didn\\'t sneer, you understand, poor Stroud--he just lay there quietly watching, and on his lips, through the gray beard, I seemed to hear the question: \\'Are you sure you know where you\\'re coming out?\\'\\n\\n\"If I could have painted that face, with that question on it, I should have done a great thing. The next greatest thing was to see that I couldn\\'t--and that grace was given me. But, oh, at that minute, Rickham, was there anything on earth I wouldn\\'t have given to have Stroud alive before me, and to hear him say: \\'It\\'s not too late--I\\'ll show you how\\'?\\n\\n\"It _was_ too late--it would have been, even if he\\'d been alive. I packed up my traps, and went down and told Mrs. Stroud. Of course I didn\\'t tell her _that_--it would have been Greek to her. I simply said I couldn\\'t paint him, that I was too moved. She rather liked the idea--she\\'s so romantic! It was that that made her give me the donkey. But she was terribly upset at not getting the portrait--she did so want him \\'done\\' by some one showy! At first I was afraid she wouldn\\'t let me off--and at my wits\\' end I suggested Grindle. Yes, it was I who started Grindle: I told Mrs. Stroud he was the \\'coming\\' man, and she told somebody else, and so it got to be true. . . . And he painted Stroud without wincing; and she hung the picture among her husband\\'s things. . . .\"\\n\\nHe flung himself down in the arm-chair near mine, laid back his head, and clasping his arms beneath it, looked up at the picture above the chimney-piece.\\n\\n\"I like to fancy that Stroud himself would have given it to me, if he\\'d been able to say what he thought that day.\"\\n\\nAnd, in answer to a question I put half-mechanically--\"Begin again?\" he flashed out. \"When the one thing that brings me anywhere near him is that I knew enough to leave off?\"\\n\\nHe stood up and laid his hand on my shoulder with a laugh. \"Only the irony of it is that I _am_ still painting--since Grindle\\'s doing it for me! The Strouds stand alone, and happen once--but there\\'s no exterminating our kind of art.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_txt = tokenizer.encode(raw_text)\n",
        "enc_txt[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHSJvQs4LFnR",
        "outputId": "d735b4f3-70d1-4ce6-f78d-62eb5180b7f9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nAhiIcMsLHm9",
        "outputId": "676c0b28-1920-4b2b-ed94-2f7a108bd292"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_txt[50:]\n",
        "context_size = 4\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size]\n",
        "print(enc_sample[:10])\n",
        "print(x,y)\n",
        "print(tokenizer.decode(enc_sample[:10]))\n",
        "print(tokenizer.decode(x))\n",
        "print(tokenizer.decode(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN8p9Tz4Ldbq",
        "outputId": "07ace423-96f5-41bb-d215-a844939b1083"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686]\n",
            "[290, 4920, 2241, 287] [4920, 2241, 287]\n",
            " and established himself in a villa on the Riv\n",
            " and established himself in\n",
            " established himself in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i:i+1]\n",
        "  print(tokenizer.decode(context),\"====>\" ,tokenizer.decode(desired))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHYal5JOMvDl",
        "outputId": "3b4cab9c-4dcd-4fa7-86d8-4d422081e946"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ====>  established\n",
            " and established ====>  himself\n",
            " and established himself ====>  in\n",
            " and established himself in ====>  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAtryWZxSbc1",
        "outputId": "5520714a-a201-469d-bc9d-116f6abb01c2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "Lev7fbrhW2-L"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,text,tokenizer, max_length,stride):\n",
        "    self.text = text\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "    self.stride = stride\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = self.tokenizer.encode(self.text)\n",
        "    for i in range(0,len(token_ids)-self.max_length,self.stride):\n",
        "      input_chunks = token_ids[i:i+self.max_length]\n",
        "      target_chunks = token_ids[i+1:i+self.max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunks))\n",
        "      self.target_ids.append(torch.tensor(target_chunks))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BS2yxKRgXA64"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "In Python, when working with classes, using self.input_ids.append(...) instead of just input_ids.append(...) is necessary to modify the instance variable input_ids of the class rather than a local variable. Let's break this down to understand the difference.\n",
        "\n",
        "Why Use self.input_ids.append(...)?\n",
        "Instance Variables vs. Local Variables:\n",
        "\n",
        "When you define self.input_ids in the __init__ method, it creates an instance variable that belongs to the instance of the class (self). This means self.input_ids is accessible throughout the entire instance of the class, and its state will be preserved across method calls.\n",
        "On the other hand, if you were to just use input_ids.append(...), you would be referring to a local variable named input_ids within the scope of the __init__ method. However, there is no such local variable named input_ids; only self.input_ids exists as an instance variable.\n",
        "Scope of Variables:\n",
        "\n",
        "self.input_ids is an instance variable that can be accessed from any method within the class.\n",
        "input_ids (without self) would be a local variable within the __init__ method, and using it would result in an UnboundLocalError because input_ids has not been defined locally. The only input_ids defined in your class is self.input_ids.\n",
        "Modifying Instance State:\n",
        "\n",
        "By using self.input_ids.append(...), you are appending to the list that is an attribute of the instance (self). This ensures that any other method within the class that accesses self.input_ids will see the changes made.\n",
        "If you use input_ids.append(...), even if input_ids were defined locally, it would only modify a local copy, and changes would not be reflected in the instance variable.\n",
        "An Example to Illustrate\n",
        "Consider the following simplified example to illustrate the difference:\"\"\""
      ],
      "metadata": {
        "id": "uKvUvo7eH-xY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "ZB5W41IDIH1Q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GPTDatasetV1(text,tokenizer,10,5)"
      ],
      "metadata": {
        "id": "p85YS1AgIKuo"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataset.input_ids)):\n",
        "  print(dataset.input_ids[i])\n",
        "  print(dataset.target_ids[i])\n",
        "  if i == 0:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qoQ1IZUIT4N",
        "outputId": "517a9ba7-3691-4ffc-9c43-467cef7c2c30"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  198,   818, 11361,    11,   618,  1762,   351,  6097,    11,  1262])\n",
            "tensor([  818, 11361,    11,   618,  1762,   351,  6097,    11,  1262,  2116])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bY5qZ0aiJkXu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**PyTorch Practice**"
      ],
      "metadata": {
        "id": "-KnTHBl2NPhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "WjxCPaB8NbuA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor0d = torch.tensor(100)\n",
        "tensor1d = torch.tensor([1,2,3,4,5])\n",
        "tensor2d = torch.tensor([[1,2,3],[4,5,6]])\n",
        "tensor3d = torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
        "print(tensor0d)\n",
        "print(tensor1d)\n",
        "print(tensor2d)\n",
        "print(tensor3d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRR2eFU1Nd00",
        "outputId": "b6ce0ddd-14a3-4cab-dd68-56bb8b039af4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(100)\n",
            "tensor([1, 2, 3, 4, 5])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6]],\n",
            "\n",
            "        [[ 7,  8,  9],\n",
            "         [10, 11, 12]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(tensor3d.dtype)\n",
        "floatvec = torch.tensor([1.0,2.0,3.0])\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ELwiAL4Npa9",
        "outputId": "efd2d353-36f3-494e-a1b0-09ed365b7921"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we create tensors from Python floats, **PyTorch creates tensors with a 32-bit\n",
        "precision by default**, as seen in above cell.\n",
        "1. This choice is primarily due to the balance between precision and\n",
        "computational efficiency. A 32-bit floating point number offers **sufficient\n",
        "precision for most deep learning tasks, while consuming less memory** and\n",
        "computational resources than a 64-bit floating point number.\n",
        "2. Moreover, **GPU\n",
        "architectures are optimized for 32-bit computations, and using this data type\n",
        "can significantly speed up model training and inference.**\n",
        "3. Moreover, it is **possible to readily change the precision using a tensor's .to\n",
        "method.**\n",
        "The following code demonstrates this by changing a 64-bit integer\n",
        "tensor into a 32-bit float tensor:"
      ],
      "metadata": {
        "id": "riTQR2VgOx8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor0d.to(torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXcDPuB1ON0M",
        "outputId": "0019a86e-648e-48c5-d3c5-0a60c5e61484"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(100.)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Common PyTorch tensor operations**\n",
        "\n",
        " .shape, .size, .reshape(to_size) --> alternate is .view(to_size), .T, matmul(or @)\n"
      ],
      "metadata": {
        "id": "u2LnDWKRQRvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.shape, tensor2d.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtW7QbmgPpyN",
        "outputId": "cff307f0-a940-4167-fbb1-6ba5fb29fba1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jilJNAq2Pvfw",
        "outputId": "cae2a6c0-3fdd-4b95-daca-71bb83666f2e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.reshape(3,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW1Tzt4oRDF7",
        "outputId": "21a5d03e-3ecd-4d5a-ec5e-4265fc291361"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d,tensor3d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbQjJyxmRNbo",
        "outputId": "5e660f9a-4d6b-4d1f-9050-668fcfa3b066"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 1,  2,  3],\n",
              "          [ 4,  5,  6]],\n",
              " \n",
              "         [[ 7,  8,  9],\n",
              "          [10, 11, 12]]]),\n",
              " torch.Size([2, 2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d.view(2,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_AyUkSURG1H",
        "outputId": "56207733-1f17-451e-a7a3-ed3df90b5375"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5,  6],\n",
              "        [ 7,  8,  9, 10, 11, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d.view(6,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GORRG12aR5a3",
        "outputId": "e1cfd910-6913-4541-bcd5-79682a611652"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2],\n",
              "        [ 3,  4],\n",
              "        [ 5,  6],\n",
              "        [ 7,  8],\n",
              "        [ 9, 10],\n",
              "        [11, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d.view(3,2,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDz3YeB4R8oG",
        "outputId": "cb2d5a99-8def-49de-b4cc-b0bc85679459"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2],\n",
              "         [ 3,  4]],\n",
              "\n",
              "        [[ 5,  6],\n",
              "         [ 7,  8]],\n",
              "\n",
              "        [[ 9, 10],\n",
              "         [11, 12]]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzg0fZOuSMMQ",
        "outputId": "341004d8-de50-499a-c0ee-fe8c38149c77"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXwFufO-SPuG",
        "outputId": "4445bcdd-9543-4414-ff5f-1e22fb5f19e2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_cNla9nSWuJ",
        "outputId": "ad8c8ffe-b3d4-45ee-96b5-b6aace149552"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3],\n",
              "         [ 4,  5,  6]],\n",
              "\n",
              "        [[ 7,  8,  9],\n",
              "         [10, 11, 12]]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d.mT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G8nIzMQSZvN",
        "outputId": "6d1ed58a-b88c-47a8-b137-ce091b5455b0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  4],\n",
              "         [ 2,  5],\n",
              "         [ 3,  6]],\n",
              "\n",
              "        [[ 7, 10],\n",
              "         [ 8, 11],\n",
              "         [ 9, 12]]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d.shape , tensor3d.mT.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XY_PDAgSb4c",
        "outputId": "2ed850ee-267b-46fc-9283-3389fd695097"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 2, 3]), torch.Size([2, 3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.matmul(tensor2d.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xfnJqSnSyId",
        "outputId": "ba3f552d-99c9-4c5b-f99c-c85822343c9f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d @ tensor2d.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNpli15LS_lO",
        "outputId": "2149ef4b-7040-4094-ce1e-385b4fe19804"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. load input text\n",
        "2. tokenize the inptut text\n",
        "3. create input and target tensors using dataset and dataloader modules of PyTorch\n",
        "4. creating embeddings for thos input and target tensors"
      ],
      "metadata": {
        "id": "hsVJ_Z_y_5lH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. load input text"
      ],
      "metadata": {
        "id": "pb1wa6DKAQoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()"
      ],
      "metadata": {
        "id": "sUnQzT1l_9Yo"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tiktoken\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "6usjvnZBAAfQ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "bHbJ4Sv0AFcF"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. tokenize the inptut text\n"
      ],
      "metadata": {
        "id": "4WJ6HKl-AM2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "__7XSrWBAVID"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qWhsL93jAcsk"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 .create input and target tensors using dataset and dataloader modules of PyTorch"
      ],
      "metadata": {
        "id": "lVfLv0uZAgFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "PlbI9Uy_AjAY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,text,max_length,stride):\n",
        "    self.text = text\n",
        "    self.max_length = max_length\n",
        "    self.stride = stride\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(text)\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunks = token_ids[i:i+max_length]\n",
        "      target_chunks = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunks))\n",
        "      self.target_ids.append(torch.tensor(target_chunks))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "nUexuAuRAspW"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataloader_v1(txt,max_length,stride,batch_size,shuffle=True,drop_last=True):\n",
        "  dataset = GPTDatasetV1(txt,max_length,stride)\n",
        "  dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "MUY92yfRCuhI"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = dataloader_v1(raw_text,max_length=10,stride=5,batch_size=8)"
      ],
      "metadata": {
        "id": "SXroWJfADONx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_iter = iter(dataloader)"
      ],
      "metadata": {
        "id": "fYWg5fHtDa81"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_iyozqsD1K-"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. creating embeddings for those input and target tensors"
      ],
      "metadata": {
        "id": "vqpfqjF-ETnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it is important to note\n",
        "that we initialize these embedding weights with random values as a\n",
        "preliminary step. This initialization serves as the starting point for the LLM's\n",
        "learning process. We will optimize the embedding weights as part of the\n",
        "LLM training"
      ],
      "metadata": {
        "id": "nNthiIZVFs5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2,3,5,1])"
      ],
      "metadata": {
        "id": "zEVTr0_mF4cT"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the sake of simplicity and illustration purposes, suppose we have a small\n",
        "vocabulary of only 6 words (instead of the 50,257 words in the BPE\n",
        "tokenizer vocabulary), and we want to create embeddings of size 3 (in GPT3,\n",
        "the embedding size is 12,288 dimensions):\n",
        "vocab_size = 6\n",
        "output_dim = 3"
      ],
      "metadata": {
        "id": "PsU11iOiGGNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3"
      ],
      "metadata": {
        "id": "4Uabv8iFGOxR"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n",
        "embedding_layer.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874JipUpGiHj",
        "outputId": "963d1d50-8000-4cf2-be05-3267928dcddb"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.9269,  1.4873, -0.4974],\n",
              "        [ 0.4396, -0.7581,  1.0783],\n",
              "        [ 0.8008,  1.6806,  0.3559],\n",
              "        [-0.6866,  0.6105,  1.3347],\n",
              "        [-0.2316,  0.0418, -0.2516],\n",
              "        [ 0.8599, -0.3097, -0.3957]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the weight matrix of the embedding layer contains small,\n",
        "random values. These values are optimized during LLM training as part of\n",
        "the LLM optimization itself\n",
        "Moreover,\n",
        "we can see that the weight matrix has six rows and three columns. There is\n",
        "one row for each of the six possible tokens in the vocabulary. And there is\n",
        "one column for each of the three embedding dimensions."
      ],
      "metadata": {
        "id": "d2NYEw-YHFQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer(torch.tensor(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxwz5NnkHRlK",
        "outputId": "e7741f58-e7bc-4efe-88dc-0886581a74e2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6866,  0.6105,  1.3347], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we compare the embedding vector for token ID 3 to the previous\n",
        "embedding matrix, we see that it is identical to the 4th row (Python starts\n",
        "with a zero index, so it's the row corresponding to index 3). In other words,\n",
        "the embedding layer is essentially a look-up operation that retrieves rows\n",
        "from the embedding layer's weight matrix via a token ID."
      ],
      "metadata": {
        "id": "lchFkZpJIvgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256 #in actual gpt it's 12288\n",
        "torch.manual_seed(42)\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n",
        "token_embedding = token_embedding_layer(torch.tensor(0))\n",
        "token_embedding.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN3VoCI8P8wM",
        "outputId": "42562073-adcc-45e0-c31d-5ad2af4b9717"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.size>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "positional encoding layer"
      ],
      "metadata": {
        "id": "plbMsrKaRZ9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we assume context_length same as max_length\n",
        "max_length = 4\n",
        "context_length = max_length\n",
        "torch.manual_seed(42)\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length,output_dim)\n",
        "pos_embedding = pos_embedding_layer(torch.arange(max_length))\n",
        "pos_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLjMRMsBRdCC",
        "outputId": "14afd217-35f7-42fc-99f1-322fa7b9b8d9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.5655,  0.5058,  0.2225],\n",
              "        [-0.6855,  0.5636, -1.5072,  ...,  0.4232, -0.3389,  0.5180],\n",
              "        [-1.3638,  0.1930, -0.6103,  ..., -1.6034, -0.4298,  0.5762],\n",
              "        [ 0.3444, -3.1016, -1.4587,  ...,  1.1085,  0.5544,  1.5818]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2175jVAFSF-0",
        "outputId": "f69a4faa-f8f9-473e-e222-a75754fe31b6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embedding_layer(torch.arange(max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woevNFVgSI2Q",
        "outputId": "df46ddca-1c5d-4dd3-9e5b-a7b6e0d9eaf0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.5655,  0.5058,  0.2225],\n",
              "        [-0.6855,  0.5636, -1.5072,  ...,  0.4232, -0.3389,  0.5180],\n",
              "        [-1.3638,  0.1930, -0.6103,  ..., -1.6034, -0.4298,  0.5762],\n",
              "        [ 0.3444, -3.1016, -1.4587,  ...,  1.1085,  0.5544,  1.5818]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pG4LoGSPt6T"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_BDxjplRzaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = dataloader_v1(raw_text,max_length=10,stride=5,batch_size=8)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n",
        "for input_batch, target_batch in dataloader:\n",
        "    # Convert input_batch to a tensor if it's a list of tensors\n",
        "    input_batch = torch.stack(input_batch) if isinstance(input_batch, list) else input_batch\n",
        "\n",
        "    print(\"Batch of Input Indices:\\n\", input_batch)\n",
        "\n",
        "    # Generate embeddings for the input batch\n",
        "    embeddings = embedding_layer(input_batch)\n",
        "    print(\"Batch of Embeddings:\\n\", embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NUJowbYzRzRC",
        "outputId": "ea21bea5-bb37-408c-e401-f46f4b2829bb"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         ...,\n",
            "         [-0.6723, -1.4593,  0.9186,  ..., -1.2261, -0.7068,  0.0707],\n",
            "         [ 2.1120,  1.0673, -1.0083,  ...,  0.2292,  1.3644, -0.4726],\n",
            "         [-1.8818, -0.1470,  1.4267,  ...,  1.2142, -0.4687,  1.1407]],\n",
            "\n",
            "        [[ 0.3529,  0.7288,  0.2554,  ...,  1.3014, -0.3387, -1.1856],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.9184,  0.0880,  0.8104,  ..., -0.6285, -0.0428, -0.4515],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-1.1602,  0.3133, -1.2542,  ...,  1.0247,  0.0166, -0.2712],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0133, -0.0784, -0.4398,  ...,  1.2505, -2.7738,  0.2461],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [-0.5175, -0.5807, -0.7034,  ..., -1.5931, -0.5740,  1.3111],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[ 0.2423,  0.7831, -0.4994,  ...,  0.1702,  0.6767,  0.9578],\n",
            "         [ 0.3074, -0.5444, -0.2572,  ...,  0.3732,  1.0061,  0.0126],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         ...,\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        [[-0.3128, -0.2570,  0.3336,  ..., -0.4578, -1.1063, -0.7198],\n",
            "         [ 1.9291, -1.0747,  0.6107,  ...,  0.0267,  0.6023, -1.5198],\n",
            "         [-0.5503, -0.1869,  0.7398,  ...,  0.9604, -0.6598, -1.1398],\n",
            "         ...,\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.0811,  0.9551, -0.4938,  ..., -1.3557,  0.7913, -0.2509]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  392,   314,  2936,   340,  1244,   307,  3499,   284,  1064,   503],\n",
            "        [ 3114,   510,   379,   262,  4286,  2029,   262, 18205,  1681,    12],\n",
            "        [  351,   257,  8839,   326,  7284, 35924,   262, 12306,   395,  4133],\n",
            "        [  355,   257,  8034,    13,   198,   198,   464,  1109,  3181,  1363],\n",
            "        [ 3016,   257,   614,   706,  3619,   338, 10568,   550,   587,  2077],\n",
            "        [  475,   465,  2951, 21650,  1613,   607,   284,   262, 18560,    13],\n",
            "        [  922,    12, 49705,    11,   284, 21595,  1133,   340,   656,  5563],\n",
            "        [41976,    13,   357, 10915,   314,  2138,  1807,   340,   561,   423]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 1.0818e+00, -1.6573e-02, -1.1103e-01,  ..., -8.4401e-01,\n",
            "          -8.8796e-01,  6.6953e-01],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         [-1.2386e+00,  1.5231e+00,  5.8632e-01,  ..., -7.0340e-01,\n",
            "           9.2396e-01,  1.0341e+00],\n",
            "         ...,\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [ 2.8344e-01, -7.3962e-02,  4.4766e-01,  ...,  1.6150e+00,\n",
            "          -6.6766e-01, -6.3209e-02],\n",
            "         [-1.5821e+00,  8.3312e-01, -1.0998e+00,  ...,  3.1671e-01,\n",
            "           5.1927e-01, -7.5376e-01]],\n",
            "\n",
            "        [[-1.1473e+00, -5.2751e-02,  6.0993e-01,  ...,  8.1023e-01,\n",
            "          -1.1959e-01, -3.9522e-01],\n",
            "         [ 2.8984e-01,  1.4311e+00, -6.8838e-01,  ...,  1.4353e+00,\n",
            "          -7.3147e-01, -4.6282e-01],\n",
            "         [-1.1569e+00,  1.2174e-01, -6.1396e-01,  ...,  2.0293e-01,\n",
            "          -1.3125e-01,  1.4171e-01],\n",
            "         ...,\n",
            "         [-3.4233e-01,  2.2876e+00,  7.5158e-01,  ...,  2.2959e-01,\n",
            "           1.1618e+00,  2.9552e-01],\n",
            "         [-9.1553e-01,  1.6921e+00, -7.5688e-01,  ..., -1.7730e+00,\n",
            "           1.1954e+00, -5.5804e-01],\n",
            "         [-2.3836e-02,  7.2067e-01, -1.5676e+00,  ...,  2.5924e-01,\n",
            "           2.4894e+00,  2.3067e-01]],\n",
            "\n",
            "        [[-3.2174e-01, -1.2322e+00, -2.6197e-01,  ..., -2.2384e+00,\n",
            "          -1.3085e+00,  1.6677e+00],\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         [ 1.1570e+00,  1.4354e+00, -3.2015e-01,  ..., -7.9002e-01,\n",
            "           1.8126e+00,  1.7084e-01],\n",
            "         ...,\n",
            "         [ 8.6535e-01, -2.4655e-01,  1.2569e+00,  ..., -1.2296e-01,\n",
            "           1.5848e-01, -9.9100e-01],\n",
            "         [ 1.4818e-01,  8.6556e-01, -1.0927e+00,  ...,  2.1345e-02,\n",
            "           1.0604e+00,  1.5769e+00],\n",
            "         [-6.2497e-01, -2.5596e+00, -1.7830e-01,  ..., -5.9186e-01,\n",
            "           3.1262e-02,  6.6749e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.8399e-01, -2.2967e+00,  9.1001e-01,  ..., -6.1041e-01,\n",
            "          -6.8508e-01, -1.6910e-01],\n",
            "         [ 7.1757e-01, -8.3968e-01,  1.2131e-01,  ...,  6.3562e-01,\n",
            "          -1.0264e+00, -1.4093e+00],\n",
            "         [ 1.4609e+00, -1.6441e+00,  6.3180e-01,  ...,  1.6115e+00,\n",
            "          -1.9263e+00, -7.9017e-01],\n",
            "         ...,\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-5.5027e-01, -1.8688e-01,  7.3975e-01,  ...,  9.6038e-01,\n",
            "          -6.5985e-01, -1.1398e+00],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00]],\n",
            "\n",
            "        [[-7.4230e-01,  9.6989e-01, -1.5757e+00,  ...,  2.8940e+00,\n",
            "           1.2396e+00,  1.5012e+00],\n",
            "         [-2.3836e-02,  7.2067e-01, -1.5676e+00,  ...,  2.5924e-01,\n",
            "           2.4894e+00,  2.3067e-01],\n",
            "         [-9.8705e-01,  9.6847e-01,  4.9927e-01,  ..., -1.9774e-01,\n",
            "          -1.7103e-03,  8.0114e-01],\n",
            "         ...,\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01],\n",
            "         [ 2.7327e-01, -4.5454e-01,  3.1237e-01,  ..., -4.6669e-01,\n",
            "          -4.9667e-01,  2.9760e-01],\n",
            "         [-4.3836e-01,  2.1500e-03,  2.6583e-01,  ..., -2.0031e+00,\n",
            "          -2.1666e+00,  1.1588e+00]],\n",
            "\n",
            "        [[ 6.5061e-01,  1.0083e+00, -7.4791e-01,  ...,  4.1768e-01,\n",
            "           8.1318e-01, -6.9956e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 2.0657e-01,  1.9892e+00,  6.7228e-01,  ..., -1.2186e+00,\n",
            "           1.0255e+00,  1.1395e+00],\n",
            "         ...,\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01],\n",
            "         [-2.2530e+00,  7.8581e-01, -1.5418e+00,  ...,  3.4132e-01,\n",
            "          -3.5590e-01,  4.9379e-01],\n",
            "         [ 7.8450e-01,  1.3598e+00, -1.1044e+00,  ...,  2.9561e-02,\n",
            "          -3.5540e-02, -3.0833e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  783,   703,  6655,   290, 10607,   314,   373,   618,   314,  1392],\n",
            "        [  607, 10927,  1108,    26,   290,   314,  3940,   607,  1022,   262],\n",
            "        [  373,   645,   530,   588,   683,   438,  8807,   314,   550,  3750],\n",
            "        [ 2993,    30,   887,   345,   655,   531,   438,     1,   198,   198],\n",
            "        [  407,   284,   766,   607, 41793,    13,   632,   373,   465,   898],\n",
            "        [ 1576,   284,   766,   465,  5986,    13, 23676,  2415,     0,  1375],\n",
            "        [    8,  3688,   284,   402,   271, 10899,   338, 12036,    13,   843],\n",
            "        [  766,   326,   314,  3521,   470,   438,   392,   326, 11542,   373]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.0421, -1.0840, -1.4136,  ..., -0.2519,  0.4297, -1.3407],\n",
            "         [ 0.3074, -0.5444, -0.2572,  ...,  0.3732,  1.0061,  0.0126],\n",
            "         [-0.2924,  0.0649, -0.4354,  ..., -0.3808,  1.1124,  0.5609],\n",
            "         ...,\n",
            "         [ 0.5868,  1.3891, -1.6561,  ...,  0.7081,  1.3799, -0.5942],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 0.7058, -0.1971, -0.0638,  ...,  1.1204,  1.0437, -0.2445]],\n",
            "\n",
            "        [[-1.9156, -1.6805, -0.0275,  ..., -1.4683, -0.0037, -0.2294],\n",
            "         [ 0.1817, -1.1142,  1.1229,  ..., -0.9094,  1.4540, -1.3926],\n",
            "         [ 0.8572,  0.6474,  0.1851,  ..., -0.1091,  1.1644, -0.4356],\n",
            "         ...,\n",
            "         [-1.9156, -1.6805, -0.0275,  ..., -1.4683, -0.0037, -0.2294],\n",
            "         [-2.8510, -0.4007,  0.7073,  ...,  0.7650,  0.7288, -0.9239],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [-0.9154, -1.1200, -1.2465,  ...,  0.6600,  0.1496, -0.7033],\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         ...,\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [ 0.1092,  0.4512, -0.9212,  ...,  0.3459,  0.8125, -1.8275]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.3517,  0.2925,  1.1224,  ..., -0.0297, -0.8901,  1.3333],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.3128, -0.2570,  0.3336,  ..., -0.4578, -1.1063, -0.7198],\n",
            "         ...,\n",
            "         [-0.5804,  0.1116, -0.1618,  ..., -1.3464,  0.7731, -1.3799],\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         [ 1.4470, -0.0848, -0.7287,  ..., -1.9911,  2.6161,  0.5186]],\n",
            "\n",
            "        [[ 0.1156, -0.1521, -0.9222,  ..., -0.3877, -0.4002,  0.2716],\n",
            "         [-0.2813,  1.5953, -0.7724,  ...,  1.0549,  1.2401, -0.9255],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         ...,\n",
            "         [-0.2122,  0.2130,  0.6530,  ...,  0.0757,  0.1124, -1.2027],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.2423,  0.7831, -0.4994,  ...,  0.1702,  0.6767,  0.9578]],\n",
            "\n",
            "        [[-0.3128, -0.2570,  0.3336,  ..., -0.4578, -1.1063, -0.7198],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         ...,\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 0.1908, -0.6951,  0.4462,  ...,  0.5089,  1.2425,  1.7761],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  329,   345,  1701,   198,   198,     1,  5297,   438, 37121,  1035],\n",
            "        [  326,   314,  2993,  1576,   284,  2666,   572,  1701,   198,   198],\n",
            "        [  286,  1683,  1719,   587,   973,   355,   257,  8034,    13,   198],\n",
            "        [ 5229,   373, 37895,   422,   428, 25179,   257, 19217,   475,  8904],\n",
            "        [  307,    13,   679,   550, 17273,   465,  2426,    11, 19233,   340],\n",
            "        [  465,  2426,    11, 19233,   340,    11, 11027,   515,   340,    13],\n",
            "        [  520,  5493,  8104,   287,   262,   717, 14000,    11,   339,  2993],\n",
            "        [   40,   550,  1239,  1900, 44807,  5514,    11,   351,   616,  1650]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.9922,  1.1803, -0.9523,  ...,  1.1973,  0.0708,  0.3740],\n",
            "         [ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222],\n",
            "         [-0.7266, -1.4021, -0.8509,  ...,  0.0454,  0.8863,  0.4863],\n",
            "         ...,\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 0.5611,  2.2247,  0.6886,  ...,  0.5151, -0.6571, -1.0432],\n",
            "         [-1.0368, -0.7231,  0.4259,  ..., -0.4366,  0.7100,  0.6565]],\n",
            "\n",
            "        [[-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 0.9950, -1.5282,  1.0779,  ...,  0.7032, -1.0330,  1.5122],\n",
            "         ...,\n",
            "         [-0.7266, -1.4021, -0.8509,  ...,  0.0454,  0.8863,  0.4863],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-1.4094,  0.2276, -0.7972,  ...,  0.6008, -1.9227, -0.7803],\n",
            "         [-1.2467, -1.0731, -0.0362,  ...,  1.4086, -0.0758,  1.4353],\n",
            "         ...,\n",
            "         [-0.2399,  0.5476,  1.8327,  ...,  0.7174, -0.7994, -1.3785],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [-0.1554,  0.0559,  0.7297,  ...,  0.3874, -2.6133,  0.1438],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [ 1.6123,  0.3840,  0.2095,  ...,  1.6995,  1.0796,  1.3579],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[-0.2142, -1.3219, -0.9208,  ..., -0.7035, -0.8742, -2.0800],\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669],\n",
            "         [-1.4806, -0.8341, -0.0134,  ..., -0.7100,  1.0064,  0.4856],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.9950, -1.5282,  1.0779,  ...,  0.7032, -1.0330,  1.5122]],\n",
            "\n",
            "        [[ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [ 0.5474, -0.9886,  2.2438,  ...,  1.9493,  0.3414,  1.4793],\n",
            "         ...,\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         [ 0.2826, -0.4646, -0.7355,  ...,  0.3864,  0.5140,  0.2913]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 6290,   739,   257,  3355,    13,   198,   198,     1,  3886,   449],\n",
            "        [ 3200,  2861,  8208,   286,   465,     0,   314, 37901,   379,   262],\n",
            "        [  572,   438,   392,   379,   616,   266,   896,     6,   886,   314],\n",
            "        [  607,  8098,    13,   314,  3505,  1972,   572,   257, 40426, 10956],\n",
            "        [  338,  7062,   373,   523,  2429,   498,   326,    11,   287,   262],\n",
            "        [  760,   526,   198,   198,  3347, 27846,   503,  2048,  4628, 24882],\n",
            "        [  520,  5493,  2241,   318,   262,  1738,   526,   198,   198,  1890],\n",
            "        [  402,   271, 10899,    11, 17728,   257,  8500,  4417,   284,   670]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.3731, -0.3856, -0.2471,  ..., -0.1562, -0.8016, -0.4466],\n",
            "         [-1.2379, -1.0293,  0.7280,  ...,  0.0620, -1.6237, -0.0263],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         ...,\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [-1.6905, -0.1052,  1.1620,  ..., -0.7548, -0.2053, -0.3518],\n",
            "         [ 1.4754, -0.5834, -0.2844,  ...,  1.6068,  1.2106, -0.7831]],\n",
            "\n",
            "        [[-0.1167,  0.6598,  2.5211,  ...,  1.0725, -1.3538,  0.7001],\n",
            "         [ 1.9802,  1.8210,  0.2560,  ...,  1.2132,  0.7559,  0.2142],\n",
            "         [-0.2777,  1.6516, -0.5871,  ...,  0.2654,  0.5658, -0.7094],\n",
            "         ...,\n",
            "         [ 0.6263, -1.6153, -0.7190,  ...,  0.6204,  1.7039, -0.1225],\n",
            "         [-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[ 0.6684,  0.4809,  0.5424,  ..., -0.5277,  1.2469, -0.0171],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 1.0818, -0.0166, -0.1110,  ..., -0.8440, -0.8880,  0.6695],\n",
            "         ...,\n",
            "         [-1.4413, -0.1894,  0.2892,  ..., -0.5915,  0.2801, -0.6825],\n",
            "         [ 0.4003, -1.0779,  0.9404,  ..., -0.5071,  1.7688,  1.1111],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.5400,  0.4149,  1.1748,  ...,  0.5854, -1.7530, -1.5975],\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [ 1.1280, -1.0164,  0.5921,  ...,  1.2849,  0.2995, -0.7424],\n",
            "         [ 1.0148,  0.6515,  0.8623,  ..., -0.6934,  0.1872,  2.0225],\n",
            "         [-0.9449,  0.1562, -1.0978,  ...,  0.1760, -0.0585,  0.3018]],\n",
            "\n",
            "        [[-0.2142, -1.3219, -0.9208,  ..., -0.7035, -0.8742, -2.0800],\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669],\n",
            "         [-1.4038, -1.0566, -0.1379,  ..., -1.7105, -1.0874, -0.1505],\n",
            "         ...,\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-0.5778, -0.2548,  0.1531,  ..., -0.8639,  2.1404, -2.4277]],\n",
            "\n",
            "        [[ 0.1605,  0.5546, -1.5836,  ..., -0.6178,  0.3921,  0.3794],\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932],\n",
            "         [ 1.1719, -1.1535, -0.8172,  ...,  0.6310,  0.1205,  1.0727],\n",
            "         ...,\n",
            "         [ 0.2772,  0.3029, -0.6453,  ..., -1.1636, -0.9590,  0.0646],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.1329, -0.2949,  1.4879,  ...,  0.8537, -0.2309, -0.9426]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 3393, 34953,   856,   326,   607,  5229,   373, 37895,   422,   428],\n",
            "        [ 2392,   284,  1645,    13,   764,   764,   764,   314,   460,  3505],\n",
            "        [  286,    11,   465,  5986,   438,   568, 22665,    11,   523, 23332],\n",
            "        [  286,  9074,    13,   402,   271, 10899,   438,    69,   623,  1576],\n",
            "        [10927,   290,  8627,    13,   198,   198,     1,  7454,    11,   618],\n",
            "        [  417,    12, 12239,    11,   475,   339,  3636,   470,  1309,   340],\n",
            "        [   13, 23676,  2415,     0,  1375,   338,   655,   257, 24225, 39136],\n",
            "        [  553,   673,   531,  2407,  2391,    13,   198,   198,    40,  3114]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.7218, -0.0548,  0.1067,  ...,  0.7061,  0.1956, -1.4233],\n",
            "         [ 0.6691,  1.5898,  1.0029,  ...,  0.0786,  0.7174,  0.0360],\n",
            "         [ 0.8793,  0.9809,  0.7523,  ..., -0.3192,  1.7062,  0.9848],\n",
            "         ...,\n",
            "         [-1.3434, -0.7597,  1.5506,  ...,  0.0306, -1.4255, -1.4305],\n",
            "         [-0.1729,  0.6175,  2.3042,  ...,  1.0319, -0.2190, -0.3214],\n",
            "         [ 0.3309,  2.2000, -0.6995,  ...,  0.5590,  2.4344, -1.0442]],\n",
            "\n",
            "        [[-0.6959,  0.6665, -1.0595,  ...,  0.8827,  0.1636, -0.7738],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [ 0.4402, -1.4864,  0.0550,  ...,  0.4787,  1.1615, -1.4822],\n",
            "         ...,\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-0.5026, -0.7407,  0.3110,  ...,  0.2714, -0.7383,  2.2537],\n",
            "         [ 1.3885,  0.3855, -1.2999,  ...,  0.2419,  1.0455,  1.9107]],\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.5801, -1.7379, -0.3187,  ..., -0.7272, -1.4554,  0.0465],\n",
            "         [-0.5571, -1.8109, -0.5870,  ...,  1.0269,  1.5063,  0.2366]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.4257, -2.3803,  0.9339,  ..., -0.7389,  0.4786,  0.0558],\n",
            "         [-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         [-0.5861,  0.2201, -0.1110,  ..., -0.8595, -1.8356,  1.3523],\n",
            "         ...,\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [ 1.8064, -0.4439, -0.9988,  ...,  1.6441,  2.4144, -0.7375],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-2.1285, -0.5479, -1.2840,  ...,  0.8408, -0.2746,  0.4593],\n",
            "         [-0.5804,  0.1116, -0.1618,  ..., -1.3464,  0.7731, -1.3799],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 1.1294,  0.3892, -0.0777,  ...,  0.6814, -0.0115, -0.8969],\n",
            "         [-3.0852,  0.3953, -0.6516,  ...,  1.6752,  2.4115, -0.7311]],\n",
            "\n",
            "        [[ 1.3361,  0.6034,  0.8908,  ..., -0.9077,  0.3499, -0.5623],\n",
            "         [ 0.1583,  0.0856, -1.6712,  ..., -1.3325, -0.4703, -0.9782],\n",
            "         [ 1.1944,  1.4784, -0.9098,  ..., -0.9145, -0.3798,  2.2964],\n",
            "         ...,\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [-1.1473, -0.0528,  0.6099,  ...,  0.8102, -0.1196, -0.3952]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[13055,   366, 11576,   306,     1,   780,   673,   373, 10032,   286],\n",
            "        [   25,   611,   339,  4808, 22474,    62,  4964,   502,    11,   644],\n",
            "        [   13, 12622, 41379,   293,   373,    11,   287,  1109,    11,  5033],\n",
            "        [14022,   616,  2951,   625,     0, 19672,   484,   550,   262,  1295],\n",
            "        [   12,    83,  6037,    26,   290,  9074,    13,   402,   271, 10899],\n",
            "        [ 4241,   286, 19217,   290, 18876,  5563,    11,  9174,   530,   286],\n",
            "        [ 1165,  3888,    13,  1375,  2138,  8288,   262,  2126,   438,  7091],\n",
            "        [  414,    13, 23676,  3619,   402,   271, 10899,     0,   383,  1466]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.9286,  1.3668, -0.3015,  ...,  1.7035, -0.7477,  0.7099],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273],\n",
            "         [-1.3596,  1.5118, -1.2019,  ..., -2.0397, -1.7812, -1.1054],\n",
            "         ...,\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [-1.1936, -0.7177,  1.0181,  ..., -0.4489,  0.9408,  1.1867],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168]],\n",
            "\n",
            "        [[-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [-0.3348, -1.2737, -0.1899,  ..., -0.5984,  1.5246, -1.2114],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         ...,\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.2886, -0.8704,  0.6625,  ..., -1.6532,  0.8268, -1.4911]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.2068, -0.3138, -1.4124,  ...,  0.8957,  0.2003, -0.7495],\n",
            "         [ 1.1306, -0.2570,  1.3432,  ..., -2.3130, -1.9117,  1.8070],\n",
            "         ...,\n",
            "         [ 0.5677, -0.3773, -0.8361,  ..., -0.2578,  1.7016,  0.1218],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.7032,  1.5249,  0.1042,  ..., -0.2206, -2.3271, -0.3157]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.4318,  0.8553, -0.9220,  ..., -0.8813, -0.8086, -0.3633],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.4192, -1.5328, -2.6889,  ..., -0.6191,  0.4701,  1.1289],\n",
            "         ...,\n",
            "         [ 0.4503,  1.0617,  0.9515,  ...,  0.9091, -1.1787,  1.2409],\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168]],\n",
            "\n",
            "        [[-0.5105,  1.1820,  1.4333,  ..., -2.4149,  1.3646,  0.9757],\n",
            "         [-0.3692,  0.5751, -0.5738,  ...,  0.0986, -1.1385, -1.3625],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         ...,\n",
            "         [ 0.0549, -1.9509,  0.5829,  ..., -0.5812,  0.2354,  1.0255],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 1.0259,  1.2715, -0.1839,  ...,  0.3529,  0.8780, -1.4835]],\n",
            "\n",
            "        [[-0.8005,  0.0077, -0.3846,  ...,  0.8394, -0.9666, -0.0122],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-2.1285, -0.5479, -1.2840,  ...,  0.8408, -0.2746,  0.4593],\n",
            "         ...,\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         [ 1.0611,  0.6114,  0.0168,  ..., -1.9903, -1.6095, -0.8438],\n",
            "         [-0.2240,  0.1875, -0.6680,  ..., -0.7734, -1.0837, -0.0281]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 3094, 16046,   351,  1059,   430,    12,    66, 12375,   299, 20896],\n",
            "        [ 1114,  3619,    11,   477,   465,  1204,    11,   550,   587, 11191],\n",
            "        [  765,   284,   467,   319, 12036,    26,   475,   340,   561,   423],\n",
            "        [  617,   530,   905,    88,     0,  1629,   717,   314,   373,  7787],\n",
            "        [  257,  1808,   314,  1234,  2063,    12,  1326,  3147,  1146,   438],\n",
            "        [  326,   530,   890,   276,   284,  3960,   503,    25,   366,  3856],\n",
            "        [28112, 10197,   832,   262, 46475,   286, 18113,   544,   338, 10953],\n",
            "        [   62,  1364,  2157,   438, 13893,   339,   550,  1282,   284,  2652]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.5140e+00, -5.4020e-01, -1.9295e+00,  ...,  3.1472e-01,\n",
            "           1.5251e+00,  2.7349e-01],\n",
            "         [ 1.7706e-02,  5.4806e-02, -1.3633e+00,  ..., -2.2373e+00,\n",
            "           5.7445e-01, -1.2532e+00],\n",
            "         [-3.2174e-01, -1.2322e+00, -2.6197e-01,  ..., -2.2384e+00,\n",
            "          -1.3085e+00,  1.6677e+00],\n",
            "         ...,\n",
            "         [ 1.8024e+00,  9.1943e-01,  2.5072e-01,  ..., -2.7054e-02,\n",
            "          -1.3068e-01, -1.2276e-01],\n",
            "         [-2.5796e+00,  1.8135e-01,  8.2018e-01,  ...,  3.9330e-03,\n",
            "          -2.0629e-02, -2.6330e-01],\n",
            "         [ 1.4848e-02, -8.6745e-01, -1.1005e-01,  ...,  3.7815e-01,\n",
            "           1.6124e+00,  1.0737e+00]],\n",
            "\n",
            "        [[-6.5033e-01, -9.5548e-01,  7.6407e-01,  ...,  1.3805e-01,\n",
            "           5.4236e-01,  2.3129e-01],\n",
            "         [-1.4202e-01,  1.9369e+00, -1.3475e+00,  ...,  7.9702e-01,\n",
            "          -1.7525e+00, -1.5364e+00],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         ...,\n",
            "         [ 1.1637e+00, -1.1183e+00, -1.0012e+00,  ...,  1.8436e-01,\n",
            "           5.0564e-01, -9.0855e-01],\n",
            "         [-5.9430e-01, -3.2627e-01,  1.4159e+00,  ...,  1.0044e+00,\n",
            "           1.4835e+00, -1.5602e+00],\n",
            "         [ 1.0732e-01,  1.9322e+00, -5.2966e-02,  ...,  1.7281e+00,\n",
            "           1.6543e-01, -1.7414e-01]],\n",
            "\n",
            "        [[-1.8516e+00, -3.1743e-02, -9.0598e-01,  ..., -7.4966e-01,\n",
            "           6.9992e-02,  5.0659e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [-1.2287e+00, -9.3050e-01,  3.2363e-01,  ...,  1.1124e+00,\n",
            "          -1.0906e+00,  1.2814e+00],\n",
            "         ...,\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01],\n",
            "         [-2.2530e+00,  7.8581e-01, -1.5418e+00,  ...,  3.4132e-01,\n",
            "          -3.5590e-01,  4.9379e-01],\n",
            "         [ 7.8450e-01,  1.3598e+00, -1.1044e+00,  ...,  2.9561e-02,\n",
            "          -3.5540e-02, -3.0833e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         [ 2.0277e-01, -3.2441e-01,  5.8122e-02,  ...,  1.2838e+00,\n",
            "           1.1483e+00,  1.3023e+00],\n",
            "         [ 5.1530e-01,  2.0588e-01,  1.0240e+00,  ..., -2.3118e-01,\n",
            "          -9.2922e-01,  1.8714e+00],\n",
            "         ...,\n",
            "         [-1.0923e-01, -1.0082e+00, -8.2644e-01,  ...,  6.3462e-01,\n",
            "          -1.5135e+00, -7.5331e-01],\n",
            "         [-4.6720e-01, -9.1476e-01,  2.1816e+00,  ...,  1.5576e+00,\n",
            "          -6.5105e-01, -2.2725e-01],\n",
            "         [-2.4559e-01,  2.3439e-01,  1.5273e+00,  ..., -6.0408e-01,\n",
            "          -2.0414e+00, -1.6174e-01]],\n",
            "\n",
            "        [[-2.1450e-01,  1.7155e-01,  5.1090e-01,  ..., -2.6517e+00,\n",
            "           1.8091e-01,  4.3599e-01],\n",
            "         [-1.9344e-01, -1.7136e+00, -9.2521e-01,  ..., -1.1323e+00,\n",
            "          -1.0551e+00, -6.1459e-01],\n",
            "         [-2.0414e+00,  1.9721e-01,  8.4603e-01,  ...,  8.5928e-01,\n",
            "          -9.8686e-01, -9.8075e-01],\n",
            "         ...,\n",
            "         [-1.8508e-01,  2.0343e-01,  1.7849e+00,  ...,  8.7963e-01,\n",
            "          -6.4424e-01,  1.4131e+00],\n",
            "         [ 4.5941e-01, -5.5795e-01, -7.1025e-01,  ..., -8.5924e-01,\n",
            "           1.5418e-01, -4.9474e-01],\n",
            "         [-9.6881e-01,  8.4649e-03,  5.1455e-01,  ...,  8.6268e-01,\n",
            "           7.1089e-01, -2.3572e-01]],\n",
            "\n",
            "        [[-8.4558e-01, -1.2353e+00, -3.8301e-01,  ...,  8.4102e-01,\n",
            "          -1.3609e+00, -3.3840e-01],\n",
            "         [ 1.3818e+00,  7.3743e-01, -1.0480e+00,  ...,  7.8724e-02,\n",
            "           1.3369e-01,  1.3897e+00],\n",
            "         [ 3.4149e-01, -4.6010e-02,  1.3161e-03,  ...,  9.7844e-01,\n",
            "           4.1616e-01, -1.2199e+00],\n",
            "         ...,\n",
            "         [ 2.5432e+00, -1.6971e-01,  6.6372e-01,  ..., -4.0816e-01,\n",
            "          -1.9256e+00,  4.8489e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [-2.7044e+00,  1.1892e+00,  1.0832e+00,  ...,  1.3416e+00,\n",
            "           2.9077e-01, -1.0619e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  262, 34686, 41976,    11,   340,  6451,  5091,   284,   502,   284],\n",
            "        [  502,   351,   257,  1611,   286, 24354, 20154, 11293,    25,   262],\n",
            "        [13431,    13,   198,   198,     1, 19242,   339,   442, 17758,   465],\n",
            "        [ 1973,   262, 37918,   411,   290,  8465,   286,   281, 33954,   271],\n",
            "        [  835,   286,  1762,    30,  2011, 29483,  2540,   284,   467,   257],\n",
            "        [  510,     1,   438,  7091,   550,   407,  2957,   683,   736,   284],\n",
            "        [  262, 26394,    12,   301,   971,    13,   314,   531, 10722,   292],\n",
            "        [  286,   465, 13476,     1,   438,  5562,   373,   644,   262,  1466]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 2.3915,  1.3330, -0.9104,  ..., -0.7661, -0.1587,  0.0928],\n",
            "         [ 0.6506,  1.0083, -0.7479,  ...,  0.4177,  0.8132, -0.6996],\n",
            "         ...,\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         ...,\n",
            "         [-0.5263,  0.7196,  0.6686,  ..., -0.5144,  0.8339,  0.1478],\n",
            "         [-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[-1.5386, -0.0503,  2.8654,  ...,  0.2482,  1.4030, -0.2774],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [-0.5832, -0.7594, -0.6373,  ..., -1.1156,  0.3075,  0.5766],\n",
            "         [-1.2443, -1.0001,  1.3434,  ...,  0.3107,  1.2247,  0.7603],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         ...,\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [ 1.2641, -0.2539, -1.1079,  ..., -1.1639, -0.7542,  1.3690],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.8607, -0.7593,  0.6594,  ..., -0.7286,  0.6598,  0.2094],\n",
            "         [-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         ...,\n",
            "         [ 1.1944,  1.4784, -0.9098,  ..., -0.9145, -0.3798,  2.2964],\n",
            "         [ 0.6399,  0.7544, -0.7258,  ...,  0.4112,  0.0359,  2.1918],\n",
            "         [-0.2678, -0.0238,  1.0052,  ..., -0.9925,  0.6703,  0.5228]],\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 0.0090,  0.8745,  0.4864,  ..., -0.3722,  0.5785, -0.1484],\n",
            "         ...,\n",
            "         [-0.2886, -0.8704,  0.6625,  ..., -1.6532,  0.8268, -1.4911],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.2240,  0.1875, -0.6680,  ..., -0.7734, -1.0837, -0.0281]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 4286,   373,   530,   286,  3619,   338,   366, 11576,   395,   553],\n",
            "        [   13,   632,   373,   465,   898, 41793,   339,  3947,   284,   307],\n",
            "        [   40,   423,  4750,   326,  9074,    13,   402,   271, 10899,   373],\n",
            "        [ 5025,   502,   878,   402,   271, 10899,   338,   366, 31640,    12],\n",
            "        [  595,    67,  1328,   340,   438,   392,   314,  2936,   340,  1244],\n",
            "        [ 1234,  8737,   656, 19133,   553,   373,   530,   286,   262,  7877],\n",
            "        [33096,   663,  4808,  3808,    62,   355,   996,   484,   547, 12548],\n",
            "        [  262,  6576,    12,   565,   418,  1039,    11,   262,  4057,  2655]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.0838, -0.7042,  1.6023,  ...,  0.2107, -3.0558, -1.6331],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         ...,\n",
            "         [-1.3596,  1.5118, -1.2019,  ..., -2.0397, -1.7812, -1.1054],\n",
            "         [ 0.1482,  0.8656, -1.0927,  ...,  0.0213,  1.0604,  1.5769],\n",
            "         [ 1.3361,  0.6034,  0.8908,  ..., -0.9077,  0.3499, -0.5623]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 1.4850,  0.9785,  1.0932,  ..., -0.3438,  0.5035, -0.7521],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         ...,\n",
            "         [-0.2591,  0.0812,  1.3068,  ...,  1.3313,  0.7646, -0.2166],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.0322, -0.6280, -1.0561,  ..., -0.4515,  1.2108,  0.3305]],\n",
            "\n",
            "        [[ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         [-0.2505, -0.5478, -0.8084,  ...,  0.3543,  0.9120,  0.5674],\n",
            "         ...,\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932],\n",
            "         [ 1.1719, -1.1535, -0.8172,  ...,  0.6310,  0.1205,  1.0727],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.3848, -1.1319, -0.1868,  ...,  0.2167,  0.6678, -0.2727],\n",
            "         [-0.9421,  0.3943,  1.2472,  ..., -0.5420, -0.3759, -0.1635],\n",
            "         [ 0.2733, -0.4545,  0.3124,  ..., -0.4667, -0.4967,  0.2976],\n",
            "         ...,\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.7248, -0.8200,  1.0117,  ...,  0.9049,  1.1084, -1.8725]],\n",
            "\n",
            "        [[ 0.7399,  1.4346,  0.4396,  ...,  1.3680, -0.7020,  0.2045],\n",
            "         [-0.9758,  0.0445, -0.2164,  ...,  0.1606, -0.7652, -1.8104],\n",
            "         [-3.0595, -0.2339,  0.5616,  ..., -0.7120, -0.0500, -0.6366],\n",
            "         ...,\n",
            "         [ 0.4209, -0.2613, -0.9257,  ..., -1.0392, -0.7258,  0.0094],\n",
            "         [ 0.8212,  0.3809, -0.7229,  ..., -0.5552, -0.2895, -2.3285],\n",
            "         [-0.6757, -0.7563,  1.2248,  ...,  0.0922,  2.1538,  2.4232]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-1.6627, -1.9878, -0.2610,  ..., -0.4359, -0.3066,  0.5979],\n",
            "         [-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-1.1035,  1.6612,  0.5084,  ..., -1.0873, -1.5808,  0.0497],\n",
            "         [ 1.5238,  1.0424, -0.0774,  ..., -0.1047, -0.2679,  0.3828]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  764,   764,   764,   198,   198,     1,    39,   648,   340,    11],\n",
            "        [ 9568,  5017,   510,   262,  1109,   438,    40,   655,  9617,  7521],\n",
            "        [  748,   586,   652,  1204,   286,   262, 34686, 41976, 37733,  2346],\n",
            "        [ 2187,   314,  1683,  2993,   526,   198,   198,     1,  1639,  1683],\n",
            "        [ 4118,    84, 16579,    13,   383,  4286,   373,   530,   286,  3619],\n",
            "        [ 5032,    11,   339,  5257,   284, 36583,  3241,   422,   262,  1103],\n",
            "        [  314,  1549,  1239, 12615,   257, 14093,   526,   198,   198,  1870],\n",
            "        [  765,   683,   284,  2883,  2241,   553,   673,   531,  2407,  2391]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-8.5991e-01,  2.2641e+00,  2.0736e+00,  ...,  6.5700e-01,\n",
            "           5.9097e-01, -1.6616e+00],\n",
            "         [-8.5991e-01,  2.2641e+00,  2.0736e+00,  ...,  6.5700e-01,\n",
            "           5.9097e-01, -1.6616e+00],\n",
            "         [-8.5991e-01,  2.2641e+00,  2.0736e+00,  ...,  6.5700e-01,\n",
            "           5.9097e-01, -1.6616e+00],\n",
            "         ...,\n",
            "         [ 5.1632e-01, -4.7839e-03, -2.2028e+00,  ..., -1.1160e+00,\n",
            "           6.1792e-01, -6.8696e-01],\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01]],\n",
            "\n",
            "        [[ 1.0732e+00, -3.2224e+00,  4.6420e-01,  ..., -1.8879e+00,\n",
            "          -1.7677e-01, -7.7398e-02],\n",
            "         [ 6.2524e-01,  1.8788e-01,  1.7939e+00,  ...,  3.3534e-01,\n",
            "          -1.6949e+00, -2.4569e-03],\n",
            "         [ 2.8984e-01,  1.4311e+00, -6.8838e-01,  ...,  1.4353e+00,\n",
            "          -7.3147e-01, -4.6282e-01],\n",
            "         ...,\n",
            "         [-1.0407e-03, -1.2642e+00,  8.1672e-01,  ...,  2.3681e+00,\n",
            "          -8.9181e-01,  6.7308e-01],\n",
            "         [ 1.0493e+00,  1.1308e+00,  8.1250e-01,  ...,  5.4831e-01,\n",
            "          -2.9165e+00,  2.0831e+00],\n",
            "         [ 1.3837e+00, -7.1455e-01, -1.2462e+00,  ...,  1.7979e-01,\n",
            "           1.2741e-01, -1.1049e+00]],\n",
            "\n",
            "        [[-1.6108e+00, -3.9537e-01, -2.0443e-01,  ...,  2.6839e+00,\n",
            "          -2.2376e-01, -6.1126e-01],\n",
            "         [ 1.5379e-01,  1.1376e+00,  1.0343e+00,  ...,  1.0992e+00,\n",
            "           3.3927e-01,  1.9791e-01],\n",
            "         [ 6.8010e-01, -1.0734e+00, -7.8008e-01,  ...,  4.7832e-01,\n",
            "           1.3850e-01,  1.1441e-01],\n",
            "         ...,\n",
            "         [ 6.5061e-01,  1.0083e+00, -7.4791e-01,  ...,  4.1768e-01,\n",
            "           8.1318e-01, -6.9956e-01],\n",
            "         [ 1.4781e+00,  7.3351e-01, -1.2652e+00,  ..., -2.5404e+00,\n",
            "          -1.6588e+00, -5.1643e-01],\n",
            "         [-8.3560e-02,  3.5030e-01,  2.5315e-01,  ...,  8.5933e-01,\n",
            "           1.4570e+00,  9.1949e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 7.0769e-02, -1.7594e+00,  3.6450e-01,  ...,  3.0005e-01,\n",
            "          -2.3403e-01, -1.1549e+00],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [-3.5449e-01, -2.3002e-01, -2.0778e-01,  ..., -1.5570e-01,\n",
            "           1.1122e-01,  2.2748e+00],\n",
            "         ...,\n",
            "         [-1.7289e-01,  6.1746e-01,  2.3042e+00,  ...,  1.0319e+00,\n",
            "          -2.1905e-01, -3.2141e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 5.8606e-01,  9.3769e-01,  8.7668e-01,  ..., -8.6758e-01,\n",
            "           3.2791e-01, -6.9557e-01]],\n",
            "\n",
            "        [[ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         [ 7.8292e-01,  2.2020e-01,  2.9774e+00,  ..., -6.2138e-01,\n",
            "           2.2832e-01, -2.1553e-01],\n",
            "         [ 5.4743e-01, -9.8863e-01,  2.2438e+00,  ...,  1.9493e+00,\n",
            "           3.4144e-01,  1.4793e+00],\n",
            "         ...,\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-7.1010e-01, -1.1495e+00,  6.3521e-01,  ...,  4.4136e-01,\n",
            "          -1.4519e+00, -4.7586e-02]],\n",
            "\n",
            "        [[-1.8516e+00, -3.1743e-02, -9.0598e-01,  ..., -7.4966e-01,\n",
            "           6.9992e-02,  5.0659e-01],\n",
            "         [ 9.9937e-01,  1.4933e+00,  1.5044e-01,  ...,  8.0270e-01,\n",
            "          -4.9967e-01, -7.8062e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         ...,\n",
            "         [ 1.1944e+00,  1.4784e+00, -9.0983e-01,  ..., -9.1449e-01,\n",
            "          -3.7983e-01,  2.2964e+00],\n",
            "         [-3.8652e-01,  8.1957e-01, -1.3392e+00,  ...,  1.3532e-01,\n",
            "           1.6247e-01, -1.6587e-02],\n",
            "         [ 1.5634e+00, -9.4107e-01,  1.8389e-01,  ...,  7.7333e-01,\n",
            "           7.0427e-01,  3.8251e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  257,   922,  5891,  1576,   438,   568,   340,   373,   645,  1049],\n",
            "        [  373,   326,   326,   925,   607,  1577,   502,   262, 50085,    13],\n",
            "        [27846,   503,  2048,  4628, 24882,   379,   262,  8812,   558,   810],\n",
            "        [  262,  3211,    12, 16337,  1474,  6164,    11,  8104,   736,   465],\n",
            "        [   11,   262,  2756,   286,   366,    38,   271, 10899,    82,     1],\n",
            "        [   11,   616, 13674,  8759,  2763,     0,   314,   373, 24380,   284],\n",
            "        [  351,   597,   286,   616,  1243,    30,  1119,  8020,   470,   587],\n",
            "        [   11,   314,  1422,   470,  1337,   257, 14787,   618,   314,  4762]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-0.7423,  0.9699, -1.5757,  ...,  2.8940,  1.2396,  1.5012],\n",
            "         [-2.3544, -0.6533, -0.7238,  ...,  0.5010, -0.2760, -0.5170],\n",
            "         ...,\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [-0.9154, -1.1200, -1.2465,  ...,  0.6600,  0.1496, -0.7033],\n",
            "         [-1.7606,  0.1919, -1.2019,  ..., -0.8646,  0.5448,  0.6032]],\n",
            "\n",
            "        [[ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.3529,  0.7288,  0.2554,  ...,  1.3014, -0.3387, -1.1856],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[ 0.7412, -1.4065, -1.2917,  ..., -1.5429, -0.1806,  1.1448],\n",
            "         [-1.5821,  0.8331, -1.0998,  ...,  0.3167,  0.5193, -0.7538],\n",
            "         [ 1.1280, -1.0164,  0.5921,  ...,  1.2849,  0.2995, -0.7424],\n",
            "         ...,\n",
            "         [ 0.1693,  0.2353, -2.7662,  ..., -0.0648, -0.2086,  0.9384],\n",
            "         [-0.4501,  0.0609,  0.2453,  ..., -1.3115,  0.5857,  0.1403],\n",
            "         [-1.0453,  1.7011, -0.8623,  ...,  1.2479, -0.0131, -1.8740]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         [-0.4204,  0.7502,  0.1324,  ..., -0.7546, -1.3105, -2.5873],\n",
            "         ...,\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 1.5263,  0.9533, -1.1465,  ..., -0.2752,  0.8974,  1.6358],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [ 0.2496,  0.3955,  0.0805,  ..., -0.6985, -0.3505, -0.0510],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         ...,\n",
            "         [ 0.6923,  0.8144,  0.2414,  ..., -0.3863, -0.5204, -1.2255],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [-0.5943, -0.3263,  1.4159,  ...,  1.0044,  1.4835, -1.5602]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-1.7231, -0.1417,  1.0724,  ...,  0.1451,  0.0061,  1.0362],\n",
            "         ...,\n",
            "         [ 0.5868,  1.3891, -1.6561,  ...,  0.7081,  1.3799, -0.5942],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 0.0636, -1.3460,  0.8502,  ...,  1.8437, -0.9728, -1.2313]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  618,   339,   373,  2636,   526,   198,   198,     1,  2215,   339],\n",
            "        [   30,   314,   460,  1560,   345,   287,  1936,  2431,   438,   392],\n",
            "        [12004,   262,  6473,   438,  5562,   314,  1043,   607,   523,    13],\n",
            "        [  286,   465, 13476,    11,   339,   550,  5710,   465, 12036,    11],\n",
            "        [ 1310,  4295,   438,    40,  2936, 10927,   290,  8627,    13,   198],\n",
            "        [  257,  1308, 27461,  1171,    13,   843,   379,   262,  2589,   314],\n",
            "        [ 2636,   691,  8208,    12, 14337,  2250,    11,   290,   339,  3724],\n",
            "        [   11,   290,  4978,  6504,   286,   326, 17548,   286,   262, 50085]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.5868,  1.3891, -1.6561,  ...,  0.7081,  1.3799, -0.5942],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         ...,\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [ 0.1817, -0.8641,  0.2625,  ...,  0.1630,  0.1150,  0.8715],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748]],\n",
            "\n",
            "        [[ 0.9895, -0.3105,  1.0758,  ...,  0.5757, -1.7812,  1.7524],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-0.5026, -0.7407,  0.3110,  ...,  0.2714, -0.7383,  2.2537],\n",
            "         ...,\n",
            "         [ 0.4577, -0.4249, -0.5254,  ..., -0.1722, -0.9851, -0.1397],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 1.0818, -0.0166, -0.1110,  ..., -0.8440, -0.8880,  0.6695]],\n",
            "\n",
            "        [[-0.5653,  0.4430,  3.4639,  ..., -0.8481, -0.0794, -1.4892],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 1.6408,  0.4737, -1.9273,  ...,  0.2045,  0.3352,  0.8959],\n",
            "         ...,\n",
            "         [-1.9156, -1.6805, -0.0275,  ..., -1.4683, -0.0037, -0.2294],\n",
            "         [ 0.5801, -1.7379, -0.3187,  ..., -0.7272, -1.4554,  0.0465],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 1.4890, -2.4453,  0.2060,  ..., -0.0115,  0.7218, -0.7929],\n",
            "         [-0.4882,  0.1430, -0.9137,  ..., -1.8764,  0.1350,  0.0840],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 1.0847,  0.8447, -1.1057,  ..., -0.7799,  0.5680, -0.0892],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888]],\n",
            "\n",
            "        [[-0.7813, -0.4880,  1.4194,  ..., -0.7981, -0.9985,  2.2210],\n",
            "         [-0.6035,  0.7153, -1.1398,  ...,  0.4031, -0.6096,  1.0566],\n",
            "         [-0.2777,  1.6516, -0.5871,  ...,  0.2654,  0.5658, -0.7094],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.7772, -0.0833,  0.0892,  ...,  0.7170, -0.9470,  0.3797]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-0.5175,  0.2783, -1.6479,  ...,  0.1475,  0.5757,  0.3374],\n",
            "         ...,\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.3529,  0.7288,  0.2554,  ...,  1.3014, -0.3387, -1.1856]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  764,   764, 22135,   198,   198,  1544, 45111,  2241,   866,   287],\n",
            "        [  883,   905,    88,  6685, 42070,   351,  4738,  6276,   871,   326],\n",
            "        [12239,   438,  1169,   691,  2134,  7163,   262,  8631, 26210,  3425],\n",
            "        [ 2492,   470,  4964,   262,   905,    88, 10340,   438,    40,  3521],\n",
            "        [  314,   892,   286,   526,   383,  1573,    11,   319,  9074,    13],\n",
            "        [ 3947,   284,   766,   257,  8212,  2157,   465,  1969, 12768,   680],\n",
            "        [  339, 13055,    11,   345,   760,   553,  9074,    13,   402,   271],\n",
            "        [  338,   655,   257, 24225, 39136,   278,   329,   584, 21441,    13]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-8.5991e-01,  2.2641e+00,  2.0736e+00,  ...,  6.5700e-01,\n",
            "           5.9097e-01, -1.6616e+00],\n",
            "         [-8.5991e-01,  2.2641e+00,  2.0736e+00,  ...,  6.5700e-01,\n",
            "           5.9097e-01, -1.6616e+00],\n",
            "         [-1.6014e+00,  3.1334e-01,  6.8645e-01,  ..., -5.7221e-01,\n",
            "           1.0324e+00, -1.6753e+00],\n",
            "         ...,\n",
            "         [-1.4038e+00, -1.0566e+00, -1.3794e-01,  ..., -1.7105e+00,\n",
            "          -1.0874e+00, -1.5050e-01],\n",
            "         [-1.7779e+00,  9.0664e-01, -3.4847e-01,  ..., -1.0286e+00,\n",
            "          -1.2427e+00,  7.4478e-01],\n",
            "         [ 1.1606e+00,  6.6746e-01,  9.5967e-01,  ...,  1.3476e+00,\n",
            "           1.1898e+00,  6.4805e-01]],\n",
            "\n",
            "        [[-1.2949e+00, -8.0979e-01, -6.5886e-01,  ...,  1.0077e+00,\n",
            "          -8.5314e-01, -1.0976e-01],\n",
            "         [ 1.3720e+00,  7.9245e-01,  4.6076e-01,  ..., -7.2270e-03,\n",
            "          -6.0719e-01, -2.4953e-01],\n",
            "         [-1.7982e+00, -1.4933e+00, -7.9320e-01,  ...,  6.0523e-01,\n",
            "          -2.2488e-02, -5.6144e-01],\n",
            "         ...,\n",
            "         [ 6.7230e-01, -2.1772e+00,  1.1479e+00,  ...,  1.2783e+00,\n",
            "          -1.7269e-01,  3.7224e-01],\n",
            "         [-1.9080e+00, -2.6676e+00,  9.4221e-01,  ...,  2.9854e-01,\n",
            "          -2.6628e-01,  1.6004e+00],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01]],\n",
            "\n",
            "        [[-5.8613e-01,  2.2015e-01, -1.1100e-01,  ..., -8.5950e-01,\n",
            "          -1.8356e+00,  1.3523e+00],\n",
            "         [-1.6872e+00,  3.5494e-01,  1.5316e+00,  ...,  1.4605e-01,\n",
            "           4.5568e-02,  3.7156e-02],\n",
            "         [ 2.3421e-01,  1.2221e+00,  2.2005e-01,  ..., -1.5481e+00,\n",
            "           3.0688e-01,  6.6418e-01],\n",
            "         ...,\n",
            "         [-6.8506e-01, -1.4627e+00, -2.2321e-01,  ...,  7.5791e-01,\n",
            "           3.2795e-03,  1.4862e+00],\n",
            "         [-9.9989e-01,  1.0707e+00, -8.6178e-01,  ..., -5.5153e-01,\n",
            "          -2.1850e+00, -8.6106e-02],\n",
            "         [ 1.4605e+00,  1.3503e+00,  2.0333e+00,  ...,  6.8356e-01,\n",
            "           2.0534e-01,  8.0274e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.5906e-01,  8.1244e-02,  1.3068e+00,  ...,  1.3313e+00,\n",
            "           7.6465e-01, -2.1661e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [-3.1282e-01, -2.5704e-01,  3.3363e-01,  ..., -4.5781e-01,\n",
            "          -1.1063e+00, -7.1982e-01],\n",
            "         ...,\n",
            "         [-1.0093e+00,  7.1604e-01, -5.1753e-01,  ..., -1.2096e+00,\n",
            "          -6.2109e-01, -1.6495e-01],\n",
            "         [ 1.3511e+00, -4.5087e-01, -1.6048e-01,  ..., -9.3145e-01,\n",
            "          -1.9994e-01,  1.3914e+00],\n",
            "         [-6.9925e-02, -5.5022e-01,  1.2660e+00,  ...,  6.5234e-01,\n",
            "          -7.1400e-01,  7.0414e-01]],\n",
            "\n",
            "        [[-3.5449e-01, -2.3002e-01, -2.0778e-01,  ..., -1.5570e-01,\n",
            "           1.1122e-01,  2.2748e+00],\n",
            "         [ 9.2856e-01,  1.3668e+00, -3.0151e-01,  ...,  1.7035e+00,\n",
            "          -7.4768e-01,  7.0991e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         ...,\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 1.6052e-01,  5.5458e-01, -1.5836e+00,  ..., -6.1778e-01,\n",
            "           3.9215e-01,  3.7935e-01],\n",
            "         [-5.3808e-01,  2.7976e-01,  4.3889e-01,  ..., -1.5520e+00,\n",
            "           1.2393e+00, -2.9317e-01]],\n",
            "\n",
            "        [[ 4.5941e-01, -5.5795e-01, -7.1025e-01,  ..., -8.5924e-01,\n",
            "           1.5418e-01, -4.9474e-01],\n",
            "         [-1.0407e-03, -1.2642e+00,  8.1672e-01,  ...,  2.3681e+00,\n",
            "          -8.9181e-01,  6.7308e-01],\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         ...,\n",
            "         [-1.1858e+00, -7.0213e-01, -7.0864e-01,  ...,  7.1789e-01,\n",
            "          -1.1733e+00,  2.0449e-01],\n",
            "         [-1.8215e+00,  1.9775e-01,  2.3708e-02,  ...,  1.0496e+00,\n",
            "           8.5232e-01,  5.3328e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  257,   905,    88, 22870,   286,  9568,  5017,   510,   262,  1109],\n",
            "        [ 6364,    25,   366, 27034,    13,   520,  5493,  2921,   340,   284],\n",
            "        [  198,     1,  5812,    11,  8759,  2763,  1043,   502,   503,   890],\n",
            "        [40830, 12719,  3874,    13,   632,   373,   655,   780,   673,   373],\n",
            "        [  257,  5287,    11,   530,   286,   262,  1611,   326,   389,  1364],\n",
            "        [   11,   379,   262,   938,   402,  1617,   261, 12917,   905,    11],\n",
            "        [  597,   517,    11,   616, 13674,  8759,  2763,    26,   393,  2138],\n",
            "        [  691,   284,   900,   510,   262,  1396,   417,   290,   651,   284]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 1.3720,  0.7924,  0.4608,  ..., -0.0072, -0.6072, -0.2495],\n",
            "         [-1.7982, -1.4933, -0.7932,  ...,  0.6052, -0.0225, -0.5614],\n",
            "         ...,\n",
            "         [ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.5677, -0.3773, -0.8361,  ..., -0.2578,  1.7016,  0.1218]],\n",
            "\n",
            "        [[ 0.7534,  0.1683, -0.1730,  ..., -0.6375,  1.6242,  1.3226],\n",
            "         [-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273],\n",
            "         ...,\n",
            "         [ 1.6991, -1.6463, -0.3822,  ...,  0.5746, -1.1788, -0.6846],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [-0.5175, -0.5807, -0.7034,  ..., -1.5931, -0.5740,  1.3111],\n",
            "         ...,\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [-1.5821,  0.8331, -1.0998,  ...,  0.3167,  0.5193, -0.7538],\n",
            "         [ 0.5153,  0.2059,  1.0240,  ..., -0.2312, -0.9292,  1.8714]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [-0.2573,  0.1668,  0.4726,  ...,  0.4853,  1.5384, -0.7777],\n",
            "         [ 1.3720,  0.7924,  0.4608,  ..., -0.0072, -0.6072, -0.2495],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[ 0.2496,  0.3955,  0.0805,  ..., -0.6985, -0.3505, -0.0510],\n",
            "         [-0.8319, -1.0101,  1.3246,  ..., -0.5300,  1.5858,  0.1537],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [ 0.5921, -1.0570,  0.0323,  ...,  0.3138,  1.1976, -0.9763],\n",
            "         [ 1.1244, -1.2054, -0.3469,  ..., -1.1796,  1.0199,  0.2553],\n",
            "         [ 1.0796,  0.5387, -0.5124,  ...,  3.0793, -0.7899, -0.8292]],\n",
            "\n",
            "        [[-0.6035,  0.7153, -1.1398,  ...,  0.4031, -0.6096,  1.0566],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-1.2038, -1.1570,  0.5143,  ..., -1.0287, -1.1155, -0.8511],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-0.3591,  0.8786,  1.0945,  ...,  1.7085,  0.4014, -2.3091],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 3303,    11,   772,  6562,  1473,    11,   530,  1139,  2063,   262],\n",
            "        [   11,   465, 10904,  4252,  6236,   429, 25839,  9230,   808,   276],\n",
            "        [  438,  1092,   517,   621,   611,   314,  1549,  1239, 12615,   257],\n",
            "        [  314,  3940,   607,  1022,   262, 30623,  2295, 49406,   286,   262],\n",
            "        [  351,   257,  6974, 19713, 14676,    25,  9675,   284,   423,   616],\n",
            "        [  547, 28297,  2241,   416,  4769,   340,   736,   422,   502,    13],\n",
            "        [ 1598,   290, 36519,    13,   314,   550,  1138,   683,  1752,   393],\n",
            "        [30960,   198,   198,     1,  1026,  4808,  9776,    62,  1165,  2739]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.4685,  1.2969, -1.2048,  ...,  0.1986,  0.3755, -0.0442],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.4148,  0.9884, -0.1131,  ..., -0.0085, -0.2986,  0.1696],\n",
            "         ...,\n",
            "         [-0.0293, -1.5136, -0.2247,  ..., -0.5071, -0.6353,  2.4972],\n",
            "         [-0.9614, -0.9523, -1.5480,  ..., -0.1192, -0.6724, -0.7958],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 0.6652, -0.6995,  1.7108,  ...,  0.4619,  0.5670, -0.4352],\n",
            "         ...,\n",
            "         [ 0.2896,  0.1334,  1.6999,  ..., -0.8960,  2.1079,  0.7449],\n",
            "         [ 0.1022,  0.6514, -2.0811,  ...,  1.3011,  0.3066, -1.6939],\n",
            "         [-0.4460,  0.8671,  0.3254,  ...,  0.6196,  0.2657, -0.7750]],\n",
            "\n",
            "        [[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-0.2674,  1.6199, -1.0803,  ..., -0.8215, -0.0509, -0.0222],\n",
            "         [-0.8319, -1.0101,  1.3246,  ..., -0.5300,  1.5858,  0.1537],\n",
            "         ...,\n",
            "         [ 0.5474, -0.9886,  2.2438,  ...,  1.9493,  0.3414,  1.4793],\n",
            "         [ 0.6852,  2.1398, -1.2688,  ..., -0.0608, -1.0647,  0.0324],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.8212,  0.3809, -0.7229,  ..., -0.5552, -0.2895, -2.3285],\n",
            "         [ 0.4833,  0.3646, -1.4679,  ...,  0.7678,  1.1916,  0.1404],\n",
            "         [-1.4038, -1.0566, -0.1379,  ..., -1.7105, -1.0874, -0.1505],\n",
            "         ...,\n",
            "         [-0.1729,  0.6175,  2.3042,  ...,  1.0319, -0.2190, -0.3214],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[ 1.2264, -0.5539,  0.5647,  ..., -0.4410, -0.1152, -2.2726],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 0.0553,  1.0427, -0.4247,  ...,  0.3289,  1.6515, -1.1342],\n",
            "         ...,\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [ 1.0754, -0.6297, -0.0627,  ..., -0.9119,  1.3890,  1.3794],\n",
            "         [ 1.1244, -1.2054, -0.3469,  ..., -1.1796,  1.0199,  0.2553]],\n",
            "\n",
            "        [[ 1.4230,  0.1983, -0.6023,  ..., -0.8571,  0.2215, -0.2810],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [-0.8456, -1.2353, -0.3830,  ...,  0.8410, -1.3609, -0.3384],\n",
            "         [-0.5105,  1.1820,  1.4333,  ..., -2.4149,  1.3646,  0.9757],\n",
            "         [-1.3845,  0.5592, -0.8671,  ...,  0.6272, -0.2311, -0.2797]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 2084,   553,   339,   531, 15376,    26,   788,    11,  6427,   465],\n",
            "        [   11,   262, 15393,   286,   262,  5977,   373, 29178,  3474,   416],\n",
            "        [  423,   683,  1760,   416,   257, 38378, 34537,   438,   993,    11],\n",
            "        [  284,  1061,   510,   428, 18437,   618,   314,  2982,   257,  2366],\n",
            "        [ 1640,   340,   373,   407, 10597,   706,   326,  1785,   326,   262],\n",
            "        [   13,   366,  2215,   673,  1908,   329,   345,  1701,   198,   198],\n",
            "        [   11,   618,   339,   373,   866,   287,  6245,   684, 10695, 20222],\n",
            "        [  438,    66,  1522,   502,    13,  1320,   338,   262,  1738,  1521]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.9898, -2.3875, -0.8996,  ..., -0.6135,  1.8363,  0.6794],\n",
            "         [ 1.3361,  0.6034,  0.8908,  ..., -0.9077,  0.3499, -0.5623],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.0453, -1.1479, -0.7634,  ...,  0.5862, -1.5359,  0.3841],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 1.8094,  1.4205,  0.2023,  ..., -0.2895,  0.9482,  1.3301],\n",
            "         ...,\n",
            "         [ 2.3992,  0.5390, -0.0692,  ..., -0.3825,  0.9197,  0.5638],\n",
            "         [ 0.3219,  1.5584,  0.5403,  ...,  0.9504, -0.5137, -1.0467],\n",
            "         [ 0.5290,  1.2444, -1.8292,  ...,  0.2727, -1.6876,  0.5176]],\n",
            "\n",
            "        [[ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [ 0.1886,  0.3268,  0.4563,  ...,  0.0597,  0.7715,  0.6002],\n",
            "         ...,\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-0.1318,  1.9788,  0.0664,  ...,  1.1666, -1.1299,  0.0979],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273],\n",
            "         [ 0.1817, -0.8641,  0.2625,  ...,  0.1630,  0.1150,  0.8715],\n",
            "         ...,\n",
            "         [-0.7266, -1.4021, -0.8509,  ...,  0.0454,  0.8863,  0.4863],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.5868,  1.3891, -1.6561,  ...,  0.7081,  1.3799, -0.5942],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         ...,\n",
            "         [ 0.8448,  0.2084, -0.0647,  ...,  0.9813, -1.0252,  1.7690],\n",
            "         [ 0.5439, -1.4566,  0.8885,  ...,  0.1314,  0.6024,  2.2091],\n",
            "         [ 0.7533,  0.5477,  1.0203,  ..., -0.4140, -0.5813,  1.0808]],\n",
            "\n",
            "        [[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-0.8297, -0.2966,  1.7941,  ...,  0.2029,  0.1096,  0.7914],\n",
            "         [-0.7266, -0.4799,  0.6936,  ...,  0.2901, -0.1760, -1.6057],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.8100,  3.2752, -0.1348,  ..., -0.3060,  0.5543, -1.3433],\n",
            "         [-0.6229,  0.9358,  0.8869,  ...,  2.1902, -0.1176, -0.9525]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  314,  3114,   510,    11,   314,  3947,   284,   766,   257,  8212],\n",
            "        [  262, 16704, 14482,  1625,   503,   438,   439,   262, 10818, 20597],\n",
            "        [ 8288,   262,  2126,   438,  7091,   338,   523, 14348,     0,   632],\n",
            "        [  262,  1711,    13,   383,  7099,  6802,   373,   531,   284,   423],\n",
            "        [  262, 34686, 41976, 37733,  2346,   284,   884, 14177,  8233,  1020],\n",
            "        [  262,  4469,   286,   607,   898,  4286,   438, 18108, 26269,  5223],\n",
            "        [ 1245,   262,   366, 25124,  3101,  8137,   286, 16957,  1696,   414],\n",
            "        [  262,  1396,   417,    13,  1675,  1234,   262, 14093,   656,   465]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-1.1473, -0.0528,  0.6099,  ...,  0.8102, -0.1196, -0.3952],\n",
            "         [ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628],\n",
            "         ...,\n",
            "         [-0.3128, -0.2570,  0.3336,  ..., -0.4578, -1.1063, -0.7198],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-1.1224, -1.0744, -1.3093,  ..., -0.3153, -0.7966,  0.0362]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.4475,  1.0902, -0.1384,  ..., -0.8740, -0.6446,  0.0485],\n",
            "         [ 0.1510,  0.1201, -2.0914,  ..., -2.6024, -0.0520,  1.2433],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.8515,  1.8308,  2.0973,  ..., -0.8084, -0.7167,  0.7874],\n",
            "         [-0.9748, -1.0109,  0.8488,  ...,  1.0795, -0.0626, -0.3527]],\n",
            "\n",
            "        [[ 0.9687,  0.4395, -0.1382,  ..., -0.4418, -0.6206,  0.1463],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.0549, -1.9509,  0.5829,  ..., -0.5812,  0.2354,  1.0255],\n",
            "         ...,\n",
            "         [-0.4537,  1.0846, -0.7538,  ...,  0.1203, -0.3157, -2.2898],\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         [ 1.4850,  0.9785,  1.0932,  ..., -0.3438,  0.5035, -0.7521]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.3968, -1.1985,  2.2177,  ...,  0.6345,  1.7633, -0.0845],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         ...,\n",
            "         [-1.3860,  1.2220, -0.6090,  ..., -1.3778, -0.6024, -0.2443],\n",
            "         [-0.5406, -1.0363,  0.7572,  ...,  0.2203, -0.5489,  0.0787],\n",
            "         [-0.1406, -0.1560,  0.0866,  ..., -0.5454, -1.0774,  1.9277]],\n",
            "\n",
            "        [[ 0.5759, -0.5332,  0.7330,  ..., -0.1789,  1.2003,  0.1225],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273],\n",
            "         ...,\n",
            "         [ 0.8385, -0.1143, -0.5812,  ...,  0.8508, -2.5695,  0.4040],\n",
            "         [ 0.0135, -1.4376, -0.6828,  ..., -0.1984, -0.4835, -0.0761],\n",
            "         [-0.8005,  0.0077, -0.3846,  ...,  0.8394, -0.9666, -0.0122]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.0508, -0.9930,  2.0781,  ..., -1.2802,  0.2225,  0.8319],\n",
            "         [ 0.4257, -2.3803,  0.9339,  ..., -0.7389,  0.4786,  0.0558],\n",
            "         ...,\n",
            "         [ 1.2796,  0.3274,  0.6681,  ..., -0.3687,  0.7753, -0.3436],\n",
            "         [ 0.2733, -0.4545,  0.3124,  ..., -0.4667, -0.4967,  0.2976],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[   11,   465,  2832,   287,   262, 16511,   286,   465, 11555,   303],\n",
            "        [  314,  2900,    11,   616,  4151,  3214,   319,   257,  1402,  4286],\n",
            "        [  366,  7109, 14655,   683,   866,   526,  1114,  9074,    13,   402],\n",
            "        [ 3022,   553,   314,   531,    13,   198,   198,  1544,  6204,  2045],\n",
            "        [ 1244,   423,  1674, 15898,   329,   683,    13,  5514,   339,   373],\n",
            "        [   13,   536,  5469,   550, 11001,    11,   262,  2756,   286,   366],\n",
            "        [35987,    11,   290,  7121,   530,   286,   262,  2769,  3211,    12],\n",
            "        [  517,    13,   383,  3200,    30,  4162,    11,   314,   550,   257]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 0.1734, -0.4277,  1.8173,  ..., -0.1688, -0.9574,  0.1904],\n",
            "         ...,\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 0.6978, -0.2012, -0.3831,  ..., -0.8493, -1.2698, -0.1296],\n",
            "         [ 0.7850, -0.0952, -0.1886,  ...,  0.3968,  0.3668, -0.6964]],\n",
            "\n",
            "        [[ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-0.5769,  0.2599, -0.6822,  ..., -0.6519,  0.0247,  0.1310],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-0.2682, -1.5571, -0.3079,  ..., -1.4315,  0.4674, -1.0939],\n",
            "         [-0.0838, -0.7042,  1.6023,  ...,  0.2107, -3.0558, -1.6331]],\n",
            "\n",
            "        [[-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273],\n",
            "         [-0.3514, -1.3924, -1.8550,  ..., -0.5831,  0.6223, -0.3804],\n",
            "         [ 0.7512,  1.0343, -0.1023,  ..., -1.6257,  0.7959, -1.1372],\n",
            "         ...,\n",
            "         [-1.7958, -0.2559, -0.0259,  ..., -0.3978,  0.0792, -0.6153],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.1605,  0.5546, -1.5836,  ..., -0.6178,  0.3921,  0.3794]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.4794,  0.1027,  1.3507,  ...,  1.0545, -0.5200, -1.2857],\n",
            "         [ 1.8558, -0.4207,  0.9219,  ...,  0.0690,  0.5103,  0.3716],\n",
            "         ...,\n",
            "         [ 1.5709, -2.2405,  0.6461,  ..., -0.8094,  0.1945,  0.4165],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273]],\n",
            "\n",
            "        [[-0.3506,  0.5889, -1.0391,  ..., -0.0285, -0.8495, -0.4601],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [ 1.9911,  0.3918,  0.3999,  ..., -0.9714, -1.3532,  1.3488],\n",
            "         [ 0.0721, -1.3084,  0.1502,  ..., -0.4055, -0.4681, -0.1809],\n",
            "         [-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307]],\n",
            "\n",
            "        [[-0.8319, -1.0101,  1.3246,  ..., -0.5300,  1.5858,  0.1537],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 1.0611,  0.6114,  0.0168,  ..., -1.9903, -1.6095, -0.8438],\n",
            "         ...,\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  607,  5229,   338,  1243,    13,   764,   764, 22135,   198,   198],\n",
            "        [  339,   373,    13,   198,   198,  6653,  3656, 27846,   379,   683],\n",
            "        [  198,   198,     1,  3886,   449,   659,   438,    64,   520,  5493],\n",
            "        [   13,  1675, 24456,   465,  3656,   561,   423,   587,  1165,  2562],\n",
            "        [  550,   262,  3200,    11,   290,   547, 28297,  2241,   416,  4769],\n",
            "        [ 1310,  2952,    13,   198,   198,     1,  2061,   257,  4240,     0],\n",
            "        [  198,   198,    40,  3888,  1497,    11, 43045, 21100,   416,   616],\n",
            "        [  546,   502,   438,  9930,   910,   340,   546, 12622, 41379,   293]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.9156, -1.6805, -0.0275,  ..., -1.4683, -0.0037, -0.2294],\n",
            "         [-0.4780,  0.1790,  1.6725,  ..., -0.7053,  2.3334, -0.9757],\n",
            "         [ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947],\n",
            "         ...,\n",
            "         [-1.6014,  0.3133,  0.6864,  ..., -0.5722,  1.0324, -1.6753],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        [[-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         ...,\n",
            "         [ 0.7412, -1.4065, -1.2917,  ..., -1.5429, -0.1806,  1.1448],\n",
            "         [-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         ...,\n",
            "         [-1.6555,  0.4294, -0.5327,  ..., -1.6245, -0.9936, -0.8078],\n",
            "         [-0.2142, -1.3219, -0.9208,  ..., -0.7035, -0.8742, -2.0800],\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.8033,  0.6010,  0.2252,  ..., -0.6313,  1.8349, -1.3884],\n",
            "         [-0.9562, -2.8608, -1.4400,  ..., -1.3088,  0.6336,  1.6182],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 1.8252, -1.0332, -1.2493,  ...,  0.5530, -0.6146, -1.7345],\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         ...,\n",
            "         [-1.3536,  1.6212,  1.4676,  ..., -0.1110,  1.0348, -2.1451],\n",
            "         [ 0.5290,  1.2444, -1.8292,  ...,  0.2727, -1.6876,  0.5176],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252]],\n",
            "\n",
            "        [[ 0.1116, -0.2741,  0.2720,  ...,  0.2087, -1.9009,  1.2337],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         ...,\n",
            "         [ 0.2068, -0.3138, -1.4124,  ...,  0.8957,  0.2003, -0.7495],\n",
            "         [ 1.1306, -0.2570,  1.3432,  ..., -2.3130, -1.9117,  1.8070],\n",
            "         [ 1.2842,  0.6056,  1.7327,  ...,  0.0999, -0.4588,  1.1103]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  373,  6616,   290,  7586,   290, 11620,    88,    25,   645,   366],\n",
            "        [  558,   286,  2282,   326,  9074,    13,   402,   271, 10899,   550],\n",
            "        [30050,   503,    13,   366,  2215,   262,   530,  1517,   326,  6774],\n",
            "        [  262,   938,  1517,   339,   550,  1760,   438,  3137,   257,  3465],\n",
            "        [ 4286,   329,  2147,   438,    40,  1297,  9074,    13,   520,  5493],\n",
            "        [ 3888,    11,  4453, 20927,   502,    11,   379,   262,  3108,   418],\n",
            "        [ 1204,    11,   550,   587, 11191,   416,  3499,  1466,    25,   484],\n",
            "        [  286,   262,  2156,   526,   198,   198,  1544,  3751,   340,   284]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 1.9574,  0.4299, -1.1878,  ...,  0.4990,  0.4680,  0.5702],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [-0.9154, -1.1200, -1.2465,  ...,  0.6600,  0.1496, -0.7033],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273]],\n",
            "\n",
            "        [[-0.4501,  0.0609,  0.2453,  ..., -1.3115,  0.5857,  0.1403],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-2.2381,  1.2810,  1.5915,  ...,  1.7785,  0.3904,  0.6593],\n",
            "         ...,\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932],\n",
            "         [ 1.1719, -1.1535, -0.8172,  ...,  0.6310,  0.1205,  1.0727],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086]],\n",
            "\n",
            "        [[-0.2930, -0.8585,  0.5206,  ...,  0.4465,  0.6052, -2.5646],\n",
            "         [-1.5821,  0.8331, -1.0998,  ...,  0.3167,  0.5193, -0.7538],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         ...,\n",
            "         [ 0.0540,  0.8285, -0.6112,  ..., -0.5483, -1.0730,  0.2075],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 1.3274,  0.0707,  0.1847,  ..., -0.2055, -0.3283, -1.2133]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.3692,  0.5751, -0.5738,  ...,  0.0986, -1.1385, -1.3625],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.9407, -0.1376, -0.4645,  ...,  1.1529, -1.0991, -0.7770],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.2619, -0.0275, -1.2577,  ...,  0.1236, -1.8362, -0.4228],\n",
            "         [-1.1514,  0.3299, -1.2767,  ...,  1.0253,  0.4722, -0.1519]],\n",
            "\n",
            "        [[-0.2951, -0.5393,  0.7463,  ..., -0.0185,  2.4136, -0.3748],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         ...,\n",
            "         [-0.2240,  0.1875, -0.6680,  ..., -0.7734, -1.0837, -0.0281],\n",
            "         [-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [ 0.4209, -0.2613, -0.9257,  ..., -1.0392, -0.7258,  0.0094]],\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.2429, -1.2897,  0.5451,  ..., -1.4117,  0.3493, -1.7464],\n",
            "         ...,\n",
            "         [ 0.3565,  0.1219, -1.3932,  ...,  1.3017,  0.1978, -1.7786],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  290,  1807,   683, 32081,   290, 44852,    88,    13,  2735,   314],\n",
            "        [11487,    11,   618,    11,   319,   257,  1568,  1110,    11,   314],\n",
            "        [  198,   198,    40,  1276,   423,  1309,   257,  1310,  1165,   881],\n",
            "        [  198,     1,  2437,   340,  3022,    30,   314,   460,  1560,   345],\n",
            "        [ 1650,   353,   438,  2934,   489,  3255,   465, 48422,   540,   450],\n",
            "        [    1,    40,  3114,   510,   757,    11,   290,  4978,  6504,   286],\n",
            "        [14676,    13,   632,   318,    11,   355,   257,  3896,    11,   262],\n",
            "        [  616,  7363,     0,   198,   198,     1,    40,  3114,   510,   757]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.1610e+00, -3.3992e-01,  6.4933e-01,  ..., -1.1030e-01,\n",
            "           4.8025e-01, -1.4159e+00],\n",
            "         [ 6.0825e-01, -8.3576e-01,  8.1374e-01,  ...,  1.3855e+00,\n",
            "          -2.2521e-01, -2.8407e+00],\n",
            "         [ 9.9937e-01,  1.4933e+00,  1.5044e-01,  ...,  8.0270e-01,\n",
            "          -4.9967e-01, -7.8062e-01],\n",
            "         ...,\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 1.1703e-01,  5.3029e-01, -1.5759e-02,  ...,  4.2674e-01,\n",
            "          -9.0402e-01,  1.5274e-02],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00]],\n",
            "\n",
            "        [[-3.0151e-01, -1.4855e-01,  5.8085e-01,  ..., -2.0519e+00,\n",
            "          -4.5032e-01, -3.1216e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [ 5.8679e-01,  1.3891e+00, -1.6561e+00,  ...,  7.0807e-01,\n",
            "           1.3799e+00, -5.9418e-01],\n",
            "         ...,\n",
            "         [ 1.3356e+00, -9.7758e-01, -1.3349e+00,  ..., -7.6646e-01,\n",
            "           1.1032e-02, -9.7572e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00]],\n",
            "\n",
            "        [[-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [ 5.7356e-01,  6.7885e-01,  6.8100e-01,  ...,  7.7412e-01,\n",
            "           1.9809e+00,  1.2333e+00],\n",
            "         ...,\n",
            "         [ 8.0332e-01,  6.0096e-01,  2.2521e-01,  ..., -6.3133e-01,\n",
            "           1.8349e+00, -1.3884e+00],\n",
            "         [-5.1049e-01,  1.1820e+00,  1.4333e+00,  ..., -2.4149e+00,\n",
            "           1.3646e+00,  9.7567e-01],\n",
            "         [-1.9662e+00, -3.9582e-01, -1.9617e-01,  ..., -2.2137e-01,\n",
            "          -4.2637e-01, -1.2814e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 6.7616e-01,  1.0905e+00, -8.1296e-02,  ...,  9.5518e-01,\n",
            "          -1.8204e-01,  2.1222e-01],\n",
            "         [ 5.7356e-01,  6.7885e-01,  6.8100e-01,  ...,  7.7412e-01,\n",
            "           1.9809e+00,  1.2333e+00],\n",
            "         [-1.1473e+00, -5.2751e-02,  6.0993e-01,  ...,  8.1023e-01,\n",
            "          -1.1959e-01, -3.9522e-01],\n",
            "         ...,\n",
            "         [-5.1752e-01,  2.7830e-01, -1.6479e+00,  ...,  1.4753e-01,\n",
            "           5.7567e-01,  3.3739e-01],\n",
            "         [-3.6176e-01, -9.1125e-04,  5.5037e-01,  ...,  7.0871e-01,\n",
            "          -5.8999e-01, -5.0535e-01],\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01]],\n",
            "\n",
            "        [[ 7.8565e-01, -2.2127e-01,  1.5254e+00,  ..., -1.2505e+00,\n",
            "          -7.2509e-01, -2.4820e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 1.4850e+00,  9.7850e-01,  1.0932e+00,  ..., -3.4377e-01,\n",
            "           5.0353e-01, -7.5207e-01],\n",
            "         ...,\n",
            "         [ 1.7774e-01,  9.0179e-01, -1.0256e+00,  ..., -1.4831e+00,\n",
            "          -6.7659e-01,  7.9891e-02],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01]],\n",
            "\n",
            "        [[ 9.3177e-02, -1.4416e+00, -1.1102e+00,  ...,  3.1926e-01,\n",
            "           2.5096e+00,  1.2252e+00],\n",
            "         [-1.2593e+00, -8.9156e-01,  1.0783e+00,  ..., -1.1149e+00,\n",
            "          -7.3120e-01,  5.9566e-01],\n",
            "         [ 5.0511e-01,  2.0639e-01,  9.4309e-01,  ..., -1.2557e+00,\n",
            "           4.4932e-01, -3.1742e-01],\n",
            "         ...,\n",
            "         [-1.1473e+00, -5.2751e-02,  6.0993e-01,  ...,  8.1023e-01,\n",
            "          -1.1959e-01, -3.9522e-01],\n",
            "         [ 2.8984e-01,  1.4311e+00, -6.8838e-01,  ...,  1.4353e+00,\n",
            "          -7.3147e-01, -4.6282e-01],\n",
            "         [-3.3816e-01, -5.9479e-01,  2.6745e-01,  ...,  2.3675e+00,\n",
            "          -6.6126e-01, -2.8266e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 1320,   338,   262,  1738,  1521,   314,   836,   470, 45553,   903],\n",
            "        [ 2332,   691,  2126,   373,   284,   423,   683,  1760,   416,   257],\n",
            "        [   12,  8439,   274,   438,   439,   262,  3716,  7106,  6637,   286],\n",
            "        [  314,   550,  1683,   550,   284, 14022,   616,  2951,   625,     0],\n",
            "        [  465,  5101, 11061,   340,    11,  3114,   510,   379,   262,  4286],\n",
            "        [   30,  3894,   438,  5562,   373,   262,   835,   314, 13055,    26],\n",
            "        [  760,   345,   772,  2993,   262,   520,  5493,    82,    13,   679],\n",
            "        [  550,   284,  1309,  6731,   307, 17676,  1863,   393,   467,   739]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.9778,  1.2004,  1.7365,  ..., -0.1927,  0.9541,  0.5285],\n",
            "         [ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [-0.4698, -0.7730,  0.7997,  ...,  0.7337, -1.1284,  0.1507],\n",
            "         [ 0.2080,  1.8966, -0.0844,  ...,  0.2918,  0.5487, -0.7367]],\n",
            "\n",
            "        [[ 0.6272,  0.2963,  0.5850,  ..., -1.3496, -0.1485,  0.4420],\n",
            "         [-0.6035,  0.7153, -1.1398,  ...,  0.4031, -0.6096,  1.0566],\n",
            "         [ 0.0549, -1.9509,  0.5829,  ..., -0.5812,  0.2354,  1.0255],\n",
            "         ...,\n",
            "         [ 0.1886,  0.3268,  0.4563,  ...,  0.0597,  0.7715,  0.6002],\n",
            "         [ 0.5290,  1.2444, -1.8292,  ...,  0.2727, -1.6876,  0.5176],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310]],\n",
            "\n",
            "        [[-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         [ 0.2889,  2.5470, -0.1245,  ...,  1.4696,  0.8647,  0.4542],\n",
            "         [ 0.7522,  0.6320,  0.4220,  ..., -1.3889,  0.4170, -0.1621],\n",
            "         ...,\n",
            "         [ 1.7014,  1.0642,  0.6274,  ...,  1.8360, -0.2661,  1.3913],\n",
            "         [-1.4452, -0.4472, -0.3313,  ..., -1.4748,  0.1119, -0.8425],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.9895, -0.3105,  1.0758,  ...,  0.5757, -1.7812,  1.7524],\n",
            "         [ 0.5196, -1.2704,  0.2824,  ..., -0.8817, -0.1147, -0.0058],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         ...,\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 0.9286,  1.3668, -0.3015,  ...,  1.7035, -0.7477,  0.7099],\n",
            "         [ 0.5921, -1.0570,  0.0323,  ...,  0.3138,  1.1976, -0.9763]],\n",
            "\n",
            "        [[-1.5400,  0.4149,  1.1748,  ...,  0.5854, -1.7530, -1.5975],\n",
            "         [ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222],\n",
            "         [ 0.4148,  0.9884, -0.1131,  ..., -0.0085, -0.2986,  0.1696],\n",
            "         ...,\n",
            "         [-0.4841,  0.2688,  0.8787,  ...,  0.8826, -0.0787, -0.6992],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.4436,  0.2945,  1.0645,  ..., -0.2296,  0.2733,  0.2512]],\n",
            "\n",
            "        [[ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [ 1.8064, -0.4439, -0.9988,  ...,  1.6441,  2.4144, -0.7375],\n",
            "         ...,\n",
            "         [ 1.1244, -1.2054, -0.3469,  ..., -1.1796,  1.0199,  0.2553],\n",
            "         [-1.2287, -0.9305,  0.3236,  ...,  1.1124, -1.0906,  1.2814],\n",
            "         [-1.2379, -1.0293,  0.7280,  ...,  0.0620, -1.6237, -0.0263]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  523,   618,   673,  2540,   284,   336,   321,   647,  1223,   546],\n",
            "        [ 8263,    12,  9649,   351,   607,    13,  1375,  3521,   470,  6842],\n",
            "        [  314,  3947,   284,  3285,   262,  1808,    25,   705,  8491,   345],\n",
            "        [  262,  1109,   351,  1602, 11227,   414,    13, 23676,  3619,   402],\n",
            "        [  338,   407,  1165,  2739,   438,    40,  1183,   905,   345,   703],\n",
            "        [  373,   530,   286,   262,  7877,    72,  3150,   339,  8104,   866],\n",
            "        [ 1295,  2627,   262,  4286,  1365,    26,  1865,    11,   355,   616],\n",
            "        [20777,   339,  8288,   465, 10152,   438, 13893,   339,  1422,   470]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.5801, -1.7379, -0.3187,  ..., -0.7272, -1.4554,  0.0465],\n",
            "         [ 0.5868,  1.3891, -1.6561,  ...,  0.7081,  1.3799, -0.5942],\n",
            "         [ 0.1583,  0.0856, -1.6712,  ..., -1.3325, -0.4703, -0.9782],\n",
            "         ...,\n",
            "         [-0.5053, -1.0502, -0.3800,  ..., -1.0520, -0.9811,  0.2823],\n",
            "         [-0.9221,  0.4398,  1.1058,  ..., -0.6756, -1.1533, -0.2487],\n",
            "         [ 0.1116, -0.2741,  0.2720,  ...,  0.2087, -1.9009,  1.2337]],\n",
            "\n",
            "        [[-0.9056,  0.1612,  0.1972,  ..., -1.2546,  0.3972,  0.1832],\n",
            "         [-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         [-0.4793,  0.9530, -0.0977,  ...,  0.1699,  0.7533,  0.0232],\n",
            "         ...,\n",
            "         [-0.5430, -0.9748, -0.5825,  ..., -0.2468, -0.0488,  0.4508],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [ 0.4451, -0.5404,  0.5278,  ...,  0.1397,  0.7446,  0.7623]],\n",
            "\n",
            "        [[ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-0.2591,  0.0812,  1.3068,  ...,  1.3313,  0.7646, -0.2166],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         ...,\n",
            "         [ 0.6064,  0.5206,  0.7622,  ..., -0.4967, -0.5741,  0.3031],\n",
            "         [ 0.0306,  0.6584, -1.3019,  ...,  0.7101,  0.9297,  0.2168],\n",
            "         [ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         ...,\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [-1.4806, -0.8341, -0.0134,  ..., -0.7100,  1.0064,  0.4856],\n",
            "         [-1.7779,  0.9066, -0.3485,  ..., -1.0286, -1.2427,  0.7448]],\n",
            "\n",
            "        [[-0.6091,  0.4791,  1.4211,  ..., -0.9553,  0.0793,  0.1767],\n",
            "         [-0.7905,  0.3888, -0.4733,  ..., -0.7626, -1.2883, -0.1905],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.6854,  1.3182,  0.0065,  ..., -0.0078,  0.6241,  2.8329],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252]],\n",
            "\n",
            "        [[-0.6415,  0.4916, -0.6478,  ..., -1.2041,  0.1542, -1.0859],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.9687,  0.4395, -0.1382,  ..., -0.4418, -0.6206,  0.1463],\n",
            "         ...,\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [-1.7231, -0.1417,  1.0724,  ...,  0.1451,  0.0061,  1.0362],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  326,  1110,   526,   198,   198,  1870,    11,   287,  3280,   284],\n",
            "        [  198,     1,  6423,   314,   373,  2077,   510,   290,  1364,  3436],\n",
            "        [  550,   757,  1057,   625,   422, 22489, 40089,    26,   290,  9074],\n",
            "        [  852, 13055,   366, 34751,   306,     1,   438,   392,  1865,   407],\n",
            "        [   11,   314,   815,   423,  1760,   257,  1049,  1517,    13,   383],\n",
            "        [  284,   766,   340,    13,   314,   550,   340,   625,   262, 24818],\n",
            "        [  373,  9675,   379,   717,    11,   351,   257,  6974, 19713, 14676],\n",
            "        [  286,   683,    25,   262,  1109,   815,   307,   900,   866,   287]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 1.3356, -0.9776, -1.3349,  ..., -0.7665,  0.0110, -0.9757],\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053],\n",
            "         ...,\n",
            "         [ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         [-0.6356, -0.2065,  0.1641,  ...,  0.7927, -0.0315,  0.0107],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [ 0.4604, -0.1027, -0.0537,  ..., -0.9904, -0.7147,  0.0392],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 1.3818,  0.7374, -1.0480,  ...,  0.0787,  0.1337,  1.3897],\n",
            "         [ 0.6331,  0.0095, -0.6400,  ..., -1.5703, -0.8957, -0.5084]],\n",
            "\n",
            "        [[ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-0.3382, -0.5948,  0.2674,  ...,  2.3675, -0.6613, -0.2827],\n",
            "         [-0.1389, -0.8295,  0.6532,  ...,  0.9444,  1.0417,  0.2850],\n",
            "         ...,\n",
            "         [ 0.5921, -1.0570,  0.0323,  ...,  0.3138,  1.1976, -0.9763],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-1.7958, -0.2559, -0.0259,  ..., -0.3978,  0.0792, -0.6153]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.3128, -0.2570,  0.3336,  ..., -0.4578, -1.1063, -0.7198],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         ...,\n",
            "         [-0.2405, -0.1489,  0.4910,  ...,  0.4731, -1.2184,  2.2132],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.5284, -0.1556,  0.9998,  ...,  0.6858,  0.9018,  0.4365]],\n",
            "\n",
            "        [[ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 1.0340, -0.3313,  1.3499,  ..., -0.5154, -0.1073, -0.5112],\n",
            "         [-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         ...,\n",
            "         [ 1.3040, -1.5266, -0.6352,  ...,  0.3861, -0.7685, -0.2224],\n",
            "         [ 1.6215,  0.0965, -0.8667,  ...,  0.1742,  0.5686, -1.5906],\n",
            "         [ 0.7857, -0.2213,  1.5254,  ..., -1.2505, -0.7251, -0.2482]],\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         ...,\n",
            "         [-1.2038, -1.1570,  0.5143,  ..., -1.0287, -1.1155, -0.8511],\n",
            "         [-1.7779,  0.9066, -0.3485,  ..., -1.0286, -1.2427,  0.7448],\n",
            "         [ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[   67, 20811,     1,   284,   910,    11,   351, 10953,   287,   607],\n",
            "        [  198,     1,    40,  1422,   470,   438,    83,   359,   706,    13],\n",
            "        [   12,  5532, 14000,    13,   764,   764,   764,   198,   198,     1],\n",
            "        [  351,   262,  3960,   319,   616, 11914,    11,   616, 13669,  6989],\n",
            "        [  355,   257,  3896,    11,   262,   661,   508, 40987,  1637,   508],\n",
            "        [  271, 10899,     0,   383,  1466,   550,   925,   683,   438,   270],\n",
            "        [  286,  5827, 40987,   913, 30802,   287,   790,  1627,    13,   317],\n",
            "        [ 2769,   866,    11,   314,   550,  1464,  4808, 31985,    62,   612]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.6907,  1.5618,  1.3103,  ...,  0.4717,  1.0093,  0.1023],\n",
            "         [ 0.2436,  0.2577,  0.6827,  ..., -0.3318, -0.6252,  0.6372],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         ...,\n",
            "         [-0.9688,  0.0085,  0.5146,  ...,  0.8627,  0.7109, -0.2357],\n",
            "         [ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         [-1.9156, -1.6805, -0.0275,  ..., -1.4683, -0.0037, -0.2294]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         ...,\n",
            "         [-1.7341,  0.4921, -1.8344,  ...,  0.3779, -0.2384,  1.0013],\n",
            "         [-0.7781,  0.2370, -0.9810,  ...,  0.5340,  0.3601,  0.8367],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         [ 1.8062,  1.5107, -0.6982,  ...,  1.3500,  0.1937, -0.5744],\n",
            "         [ 0.9360, -1.5745,  0.1299,  ...,  0.0998,  1.2441,  0.1171],\n",
            "         ...,\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932],\n",
            "         [ 1.1719, -1.1535, -0.8172,  ...,  0.6310,  0.1205,  1.0727],\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         ...,\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 0.5821,  1.9366,  0.8448,  ..., -0.9704, -0.7925, -1.6757]],\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.0194, -0.4462, -2.8608,  ..., -0.5273, -1.2444, -0.7371],\n",
            "         [ 0.2420, -0.5692,  0.0675,  ..., -1.6051,  1.0022,  2.2186],\n",
            "         ...,\n",
            "         [ 1.4400, -0.9946, -1.4995,  ..., -1.9225,  0.6170,  1.7725],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-0.0459,  1.2312, -0.1976,  ..., -0.1618, -0.5171, -0.8885]],\n",
            "\n",
            "        [[ 1.9911,  0.3918,  0.3999,  ..., -0.9714, -1.3532,  1.3488],\n",
            "         [-1.7779,  0.9066, -0.3485,  ..., -1.0286, -1.2427,  0.7448],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [ 0.7466, -0.1584,  0.3794,  ..., -0.1898,  1.4839,  0.7055],\n",
            "         [-0.8456, -1.2353, -0.3830,  ...,  0.8410, -1.3609, -0.3384],\n",
            "         [-0.8823,  0.2951,  0.7940,  ..., -1.3889, -1.3655,  0.3754]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  465,  8216,  1297,   502,   287,   257,  7644,   326,   339,  1239],\n",
            "        [ 1231,  1592,  2259,    26,   290,   673,  9174,   262,  4286,  1871],\n",
            "        [31414,  1576,    11,   340,  2627,  4156,   326,   339,   373, 16245],\n",
            "        [ 2029,   262, 18205,  1681,    12, 12239,    13,   198,   198,     1],\n",
            "        [  407,  2957,   683,   736,   284,   262,  1396,   417,    13,  1675],\n",
            "        [  257,  7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438],\n",
            "        [ 5514,    11,   351,   616,  1650,  1010,   290,   616,  1171,    11],\n",
            "        [ 2106,  1701,   198,   198,     1,  2504,   373,   465,  2106,    13]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [-0.4891,  1.0140,  0.2598,  ..., -0.8754, -1.7198, -0.7552],\n",
            "         [ 0.2140,  0.1935,  1.0648,  ...,  2.1137,  3.4164,  0.3580],\n",
            "         ...,\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.5474, -0.9886,  2.2438,  ...,  1.9493,  0.3414,  1.4793]],\n",
            "\n",
            "        [[ 0.1493, -1.4356,  2.2383,  ..., -1.5074,  0.4848, -0.4251],\n",
            "         [-1.3921, -0.1615, -0.5388,  ...,  1.5891,  0.1397,  1.2098],\n",
            "         [-0.2312,  1.0024,  1.6244,  ...,  0.4327, -1.4229,  0.2038],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.0838, -0.7042,  1.6023,  ...,  0.2107, -3.0558, -1.6331],\n",
            "         [-0.6334, -0.3352, -0.4789,  ...,  0.7198,  0.9344,  0.4141]],\n",
            "\n",
            "        [[-1.3166, -2.2376,  1.0897,  ..., -0.8773,  0.1038,  0.4809],\n",
            "         [-1.3517,  0.2925,  1.1224,  ..., -0.0297, -0.8901,  1.3333],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 1.1444,  0.2787,  2.9443,  ...,  1.2125,  2.2535, -0.0347]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 0.0506,  0.9025,  0.3018,  ..., -0.8349,  1.6523, -0.1247],\n",
            "         [ 0.3603, -0.7610,  0.0411,  ...,  0.9168,  0.8359, -0.2233],\n",
            "         ...,\n",
            "         [-2.3544, -0.6533, -0.7238,  ...,  0.5010, -0.2760, -0.5170],\n",
            "         [-1.3517,  0.2925,  1.1224,  ..., -0.0297, -0.8901,  1.3333],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372]],\n",
            "\n",
            "        [[ 0.1805,  0.1697, -0.4166,  ...,  1.9568, -0.2134,  0.7935],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         ...,\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         [-0.5252, -0.3621, -0.1902,  ..., -0.7659, -1.6971,  0.2220],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[ 1.6224, -0.8414,  0.3604,  ..., -0.0514, -1.4483,  0.5047],\n",
            "         [-0.7266, -1.4021, -0.8509,  ...,  0.0454,  0.8863,  0.4863],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 1.6224, -0.8414,  0.3604,  ..., -0.0514, -1.4483,  0.5047],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[14028,   611,   257,   256, 11912,   286, 35394,   739, 10724,   262],\n",
            "        [ 2157,    13,  2750,   449,   659,    11,   290,   339,  4808,  9776],\n",
            "        [ 1182,   284,   804,   510,   379,   262, 17548,   286,   262, 50085],\n",
            "        [  407,   326,   616,  2583,   408,   373,   366, 47914,  1298,   319],\n",
            "        [  351,   326,  1808,   319,   340,    11,   314,   815,   423,  1760],\n",
            "        [ 1517,   484,  1444,   616,   705, 23873,  2350,     6, 14707,   588],\n",
            "        [  550, 18459,  1068,   284,  1577,   257, 23844,   286,  7543,   284],\n",
            "        [  423, 13055,   326,  1986,    11,   351,   326,  1808,   319,   340]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 2.5913e+00,  4.0464e-01, -3.3842e-01,  ..., -2.1012e+00,\n",
            "           5.1945e-01, -9.6534e-01],\n",
            "         [-3.3477e-01, -1.2737e+00, -1.8986e-01,  ..., -5.9835e-01,\n",
            "           1.5246e+00, -1.2114e+00],\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         ...,\n",
            "         [-1.2379e+00, -1.0293e+00,  7.2796e-01,  ...,  6.1979e-02,\n",
            "          -1.6237e+00, -2.6296e-02],\n",
            "         [-2.1631e+00, -1.4046e+00,  3.4425e-01,  ..., -1.9321e+00,\n",
            "           2.2632e-01, -3.5060e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01]],\n",
            "\n",
            "        [[ 3.4149e-01, -4.6010e-02,  1.3161e-03,  ...,  9.7844e-01,\n",
            "           4.1616e-01, -1.2199e+00],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 7.9607e-01,  1.1434e+00, -3.5159e-01,  ..., -4.4308e-01,\n",
            "           5.7676e-01, -3.1311e+00],\n",
            "         ...,\n",
            "         [-3.5449e-01, -2.3002e-01, -2.0778e-01,  ..., -1.5570e-01,\n",
            "           1.1122e-01,  2.2748e+00],\n",
            "         [-3.0595e+00, -2.3386e-01,  5.6158e-01,  ..., -7.1203e-01,\n",
            "          -4.9988e-02, -6.3656e-01],\n",
            "         [ 1.2210e+00,  9.7979e-01,  1.1341e+00,  ..., -3.0859e-01,\n",
            "          -6.1453e-01,  7.4185e-01]],\n",
            "\n",
            "        [[-1.6710e+00, -1.0517e-01, -1.1116e-01,  ...,  4.4828e-02,\n",
            "           3.7677e-01, -3.7028e-02],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [ 1.0755e+00,  2.3874e-01, -1.9040e+00,  ...,  7.0210e-01,\n",
            "           2.8813e-01,  2.6725e-01],\n",
            "         ...,\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 3.5290e-01,  7.2882e-01,  2.5539e-01,  ...,  1.3014e+00,\n",
            "          -3.3865e-01, -1.1856e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 5.3971e-02,  8.2846e-01, -6.1118e-01,  ..., -5.4833e-01,\n",
            "          -1.0730e+00,  2.0751e-01],\n",
            "         [ 4.2091e-01, -2.6131e-01, -9.2567e-01,  ..., -1.0392e+00,\n",
            "          -7.2582e-01,  9.4441e-03],\n",
            "         [ 6.2132e-01,  4.0623e-02,  1.0963e+00,  ...,  5.4325e-01,\n",
            "          -5.5014e-01, -9.2272e-01],\n",
            "         ...,\n",
            "         [-1.4413e+00, -1.8941e-01,  2.8916e-01,  ..., -5.9145e-01,\n",
            "           2.8013e-01, -6.8250e-01],\n",
            "         [ 5.1068e-01, -9.9722e-01, -8.5817e-02,  ..., -1.8256e+00,\n",
            "           7.0490e-01, -7.8461e-01],\n",
            "         [-9.7364e-01, -7.0711e-01, -9.0073e-01,  ...,  2.8945e+00,\n",
            "           1.1000e-01, -1.5532e+00]],\n",
            "\n",
            "        [[ 1.1637e+00, -1.1183e+00, -1.0012e+00,  ...,  1.8436e-01,\n",
            "           5.0564e-01, -9.0855e-01],\n",
            "         [-1.5536e+00,  9.6288e-01,  2.1260e+00,  ...,  1.3125e+00,\n",
            "          -6.8060e-01, -1.4113e+00],\n",
            "         [-6.7033e-01, -1.2200e-01,  1.5265e+00,  ...,  2.5255e-01,\n",
            "          -6.8345e-01, -4.8204e-01],\n",
            "         ...,\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-1.0363e+00,  2.3697e-01, -8.6165e-01,  ..., -1.1341e+00,\n",
            "          -1.6621e+00, -1.4525e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01]],\n",
            "\n",
            "        [[ 7.8450e-01,  1.3598e+00, -1.1044e+00,  ...,  2.9561e-02,\n",
            "          -3.5540e-02, -3.0833e-01],\n",
            "         [ 9.2856e-01,  1.3668e+00, -3.0151e-01,  ...,  1.7035e+00,\n",
            "          -7.4768e-01,  7.0991e-01],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         ...,\n",
            "         [ 3.5172e-01,  1.0456e-01,  6.8173e-01,  ...,  1.0936e+00,\n",
            "          -1.5083e+00, -7.6110e-02],\n",
            "         [-4.5832e-01, -1.6412e+00, -5.1882e-01,  ...,  1.0188e+00,\n",
            "           1.6275e-01,  1.2691e+00],\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 8759,  2763,  2227,   284,   766,   340,   553,   673,  2540,    11],\n",
            "        [   11, 43045, 21100,   416,   616, 10059,  9412,    26,   290,   355],\n",
            "        [  502,   526,   198,   198,     1, 10910,   438,    40,  1422,   470],\n",
            "        [ 1072,    13,   198,   198,     1,  3666, 13674,    11,  1201,   314],\n",
            "        [  663,  4808, 44769,  8270,    12,   332,   660,    62,   410,  1386],\n",
            "        [  423,   520,  5493,  6776,   878,   502,    11,   290,   284,  3285],\n",
            "        [  198,   198,  1544, 13818,   757,    11,   290,  9617,   736,   465],\n",
            "        [ 6405,   257,  5527, 27075,    11,   290,  4920,  2241,   287,   257]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 1.0927, -1.1613, -0.3028,  ...,  0.0971, -0.3969,  0.4718],\n",
            "         [ 1.1981, -1.1688, -0.4651,  ..., -0.7270, -1.1385,  0.9982],\n",
            "         [ 1.5495, -0.0719,  1.3282,  ...,  0.6263,  0.3803, -2.5637],\n",
            "         ...,\n",
            "         [ 0.1583,  0.0856, -1.6712,  ..., -1.3325, -0.4703, -0.9782],\n",
            "         [ 0.9725, -0.6512,  0.0769,  ...,  0.1816, -0.0705, -0.1653],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.2339,  0.6567, -0.5306,  ..., -1.1477, -1.6790, -0.6399],\n",
            "         [-1.3536,  1.6212,  1.4676,  ..., -0.1110,  1.0348, -2.1451],\n",
            "         ...,\n",
            "         [ 0.5921, -1.0570,  0.0323,  ...,  0.3138,  1.1976, -0.9763],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-0.6854,  1.3182,  0.0065,  ..., -0.0078,  0.6241,  2.8329]],\n",
            "\n",
            "        [[ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [-1.7231, -0.1417,  1.0724,  ...,  0.1451,  0.0061,  1.0362],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         [-0.2142, -1.3219, -0.9208,  ..., -0.7035, -0.8742, -2.0800],\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-1.0632,  0.3421, -0.5531,  ...,  0.6742,  1.2355, -0.8793]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-0.2523,  0.4677,  0.1485,  ..., -0.2896,  0.4759, -1.5621],\n",
            "         ...,\n",
            "         [ 1.0493,  1.1308,  0.8125,  ...,  0.5483, -2.9165,  2.0831],\n",
            "         [ 1.2641, -0.2539, -1.1079,  ..., -1.1639, -0.7542,  1.3690],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093]],\n",
            "\n",
            "        [[ 0.2580, -0.0369,  0.2577,  ...,  0.7784, -0.2354, -0.1915],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-0.2007,  0.0241,  0.8518,  ..., -0.4058, -2.1377,  0.8034],\n",
            "         ...,\n",
            "         [-1.4038, -1.0566, -0.1379,  ..., -1.7105, -1.0874, -0.1505],\n",
            "         [ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  416,  3499,  1466,    25,   484,   550, 26546,  1068,   465,  1242],\n",
            "        [   12,  1326,  3147,  1146,   438,     1, 44140,   757,  1701,   339],\n",
            "        [  284,   766,   340,   438,  1169,   717, 18560,   286,  3619,   338],\n",
            "        [  307,  3499,   284,  1064,   503,  1521,    13,   198,   198,   464],\n",
            "        [ 9074,    13,   520,  5493,    13,  2332,   691,  2126,   373,   284],\n",
            "        [   11,   355,   339,  8278,   422,   262,  3084,   290,   336,  8375],\n",
            "        [  438,    40,   714,   655,  6687,   284,   766,   340,   438,  1169],\n",
            "        [  550,   587,   262,   582,   286,   262,  1711,    13,   383,  7099]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.5290,  1.2444, -1.8292,  ...,  0.2727, -1.6876,  0.5176],\n",
            "         [-0.1868,  0.4341, -0.6836,  ..., -0.7903,  0.2608, -0.3897],\n",
            "         [-0.2240,  0.1875, -0.6680,  ..., -0.7734, -1.0837, -0.0281],\n",
            "         ...,\n",
            "         [-0.6703, -0.1220,  1.5265,  ...,  0.2526, -0.6834, -0.4820],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 1.4834, -1.3164, -1.7361,  ...,  0.3722, -0.7625,  0.8043]],\n",
            "\n",
            "        [[-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         [ 1.1051,  1.6651,  0.1714,  ..., -1.0775, -0.3077,  0.3992],\n",
            "         [-0.5822,  0.0719,  0.1552,  ..., -0.9540, -2.1426, -1.2549],\n",
            "         ...,\n",
            "         [-0.3382, -0.5948,  0.2674,  ...,  2.3675, -0.6613, -0.2827],\n",
            "         [-0.7266, -1.4021, -0.8509,  ...,  0.0454,  0.8863,  0.4863],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748]],\n",
            "\n",
            "        [[-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.3128, -0.2570,  0.3336,  ..., -0.4578, -1.1063, -0.7198],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         ...,\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.1420,  1.9369, -1.3475,  ...,  0.7970, -1.7525, -1.5364],\n",
            "         [ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.6854,  1.3182,  0.0065,  ..., -0.0078,  0.6241,  2.8329],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 0.0905,  0.0437,  1.3667,  ...,  1.5907, -0.3445,  0.6018],\n",
            "         [ 0.3207, -1.4223, -0.4261,  ..., -1.0943,  0.0420,  0.8283]],\n",
            "\n",
            "        [[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [ 1.0208,  0.4613, -0.1690,  ...,  1.0675, -1.1652,  0.2891],\n",
            "         ...,\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 0.2342,  1.2221,  0.2201,  ..., -1.5481,  0.3069,  0.6642]],\n",
            "\n",
            "        [[ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-0.5943, -0.3263,  1.4159,  ...,  1.0044,  1.4835, -1.5602],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 1.0611,  0.6114,  0.0168,  ..., -1.9903, -1.6095, -0.8438],\n",
            "         [ 0.8553, -2.4346,  1.4910,  ..., -2.0121,  1.2488, -0.5710]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 7425,   502,   783,   373,   326,    11,   329,   262,   717,   640],\n",
            "        [  338, 10568,   550,   587,  2077,    13,   632,  1244,   307,   326],\n",
            "        [  198,     1, 12295,   892,   286,   340,    11,   616, 13674,  5891],\n",
            "        [  257,  4286, 10273,   438, 29370,   477,    11,   645,  1551,  1051],\n",
            "        [  553,   373,   465,   691,  5402,    11,   355,   339,  8278,   422],\n",
            "        [ 1781,    11,   611,   673,   550,   407, 17901,   683,   866,    11],\n",
            "        [  314,  2936,  1498,   284,  1986,   262,  1109,   351,  1602, 11227],\n",
            "        [ 1396,   417,   290,   651,   284,   670,    13,   679,   550,   587]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.4392, -0.7600,  1.6267,  ..., -0.7762,  0.0656, -0.8395],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [ 0.0421, -1.0840, -1.4136,  ..., -0.2519,  0.4297, -1.3407],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.6313,  0.3005,  1.7098,  ..., -0.4809,  0.4106,  0.9097],\n",
            "         [ 1.6024,  0.3533, -0.2030,  ...,  0.2098,  0.0812,  1.3969]],\n",
            "\n",
            "        [[ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947],\n",
            "         [-2.9716, -0.9002, -0.0871,  ..., -2.2899, -0.2901, -0.7990],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         ...,\n",
            "         [ 1.2216,  0.2716,  0.4705,  ...,  0.0685, -0.1863, -0.1148],\n",
            "         [-0.0322, -0.6280, -1.0561,  ..., -0.4515,  1.2108,  0.3305],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [ 1.3189, -1.3196, -0.0979,  ..., -0.3113, -0.8005,  0.1759],\n",
            "         ...,\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         [-0.4204,  0.7502,  0.1324,  ..., -0.7546, -1.3105, -2.5873],\n",
            "         [-2.3544, -0.6533, -0.7238,  ...,  0.5010, -0.2760, -0.5170]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.1556,  0.1446, -1.1558,  ...,  0.3983,  0.3114,  0.7821],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.3348, -1.2737, -0.1899,  ..., -0.5984,  1.5246, -1.2114],\n",
            "         ...,\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [-1.7779,  0.9066, -0.3485,  ..., -1.0286, -1.2427,  0.7448],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-1.2386,  1.5231,  0.5863,  ..., -0.7034,  0.9240,  1.0341],\n",
            "         [-1.9772,  0.0391, -0.1296,  ..., -0.3855,  0.4425,  0.3314],\n",
            "         ...,\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [-1.5381, -0.2028,  0.4802,  ...,  1.3852,  2.1004, -1.0164],\n",
            "         [ 1.9837,  0.5343,  0.9158,  ...,  1.2133, -1.4688, -1.3575]],\n",
            "\n",
            "        [[ 0.0508, -0.9930,  2.0781,  ..., -1.2802,  0.2225,  0.8319],\n",
            "         [ 0.4257, -2.3803,  0.9339,  ..., -0.7389,  0.4786,  0.0558],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [ 0.4436,  0.2945,  1.0645,  ..., -0.2296,  0.2733,  0.2512],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-0.5943, -0.3263,  1.4159,  ...,  1.0044,  1.4835, -1.5602]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  510,   379,   262, 17548,    11,   290,   665, 24297,  1022,   465],\n",
            "        [  339,   550,  1282,   284,  2652,     0,   383,  1334,   286,   514],\n",
            "        [  438,  4360,   319, 45697, 19369,    13,   921,  9670, 28022,    11],\n",
            "        [14150,    62,   284,   783,    11,   345,   760,    26,   290,   314],\n",
            "        [  749, 34372, 10038,   438, 34330,  3888,    11,  4453, 20927,   502],\n",
            "        [ 1807,   286,  1997,  2073,    13,   198,   198,    40,  3888,  1497],\n",
            "        [  198,    32,  3731, 17979,   286, 32315, 12606,  9074,    13,   402],\n",
            "        [    0,   383,  1334,   286,   514,   550,   284,  1309,  6731,   307]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628],\n",
            "         [-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [-0.9093,  0.8517, -0.1780,  ..., -0.8422, -0.7985,  0.3508],\n",
            "         [-2.8510, -0.4007,  0.7073,  ...,  0.7650,  0.7288, -0.9239],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093]],\n",
            "\n",
            "        [[-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [ 2.5432, -0.1697,  0.6637,  ..., -0.4082, -1.9256,  0.4849],\n",
            "         ...,\n",
            "         [ 0.3277,  0.6030, -1.6587,  ...,  0.1158,  0.2659,  0.9081],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.6573,  0.2050, -1.1197,  ...,  0.6030,  0.0820,  0.7867]],\n",
            "\n",
            "        [[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-0.8208,  0.0423, -0.2230,  ...,  0.2334, -1.2991,  0.8684],\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691],\n",
            "         ...,\n",
            "         [-0.9489,  0.4688, -0.5735,  ...,  0.2705,  0.2297, -1.1777],\n",
            "         [ 0.9537,  1.5271, -0.5596,  ...,  0.2023, -0.1973,  1.8262],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.6083, -0.8358,  0.8137,  ...,  1.3855, -0.2252, -2.8407],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-1.3061, -0.7769, -0.5426,  ..., -0.0923,  0.5525,  0.6030],\n",
            "         ...,\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [-0.3692,  0.5751, -0.5738,  ...,  0.0986, -1.1385, -1.3625],\n",
            "         [ 1.1452,  0.1078, -0.2417,  ...,  2.6383,  0.6205, -0.2097]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-0.6087, -0.7237, -1.6022,  ..., -0.0078, -1.2888,  0.5979],\n",
            "         [ 0.4757,  0.2258, -0.5199,  ..., -0.3703, -1.8289,  0.8458],\n",
            "         ...,\n",
            "         [-1.7958, -0.2559, -0.0259,  ..., -0.3978,  0.0792, -0.6153],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.1605,  0.5546, -1.5836,  ..., -0.6178,  0.3921,  0.3794]],\n",
            "\n",
            "        [[ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         [ 1.0611,  0.6114,  0.0168,  ..., -1.9903, -1.6095, -0.8438],\n",
            "         [ 0.3277,  0.6030, -1.6587,  ...,  0.1158,  0.2659,  0.9081],\n",
            "         ...,\n",
            "         [ 1.8064, -0.4439, -0.9988,  ...,  1.6441,  2.4144, -0.7375],\n",
            "         [ 0.0590, -0.4896, -0.3901,  ..., -0.2483,  0.2418,  0.2212],\n",
            "         [-0.0322, -0.6280, -1.0561,  ..., -0.4515,  1.2108,  0.3305]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 3636,   470,   423,  1813,   284,   423,   520,  5493,  6776,   878],\n",
            "        [ 5986,   438,  1169,  3081,   286,  2045,  1190,  4119,    81,   621],\n",
            "        [   11,   530,  1139,  2063,   262,   640,   407,   644,   530,  3382],\n",
            "        [ 3465,    13,  3226,  1781,    11,  2769,   866,    11,   314,   550],\n",
            "        [  550,   587,  6699,   262,  1540,   558,   286,  2282,   326,  9074],\n",
            "        [  520,  5493,  2921,   340,   284,   502,   526,   198,   198,     1],\n",
            "        [  287,   262,  2156,   526,   198,   198,    32,  3731, 17979,   286],\n",
            "        [  392,   994,   389,   262, 33204,   345,   588,   526,   198,   198]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.5611, -0.3022, -0.0248,  ...,  1.1916,  0.3670,  1.8461],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         ...,\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669],\n",
            "         [-0.0966,  0.5474, -0.1443,  ...,  0.8664,  1.1504,  0.8010],\n",
            "         [ 0.8793, -1.1962,  0.4589,  ..., -0.7711, -2.2812,  0.6270]],\n",
            "\n",
            "        [[-0.8886, -1.2092, -0.2833,  ..., -0.2667,  1.2319,  1.5421],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 0.2342,  1.2221,  0.2201,  ..., -1.5481,  0.3069,  0.6642],\n",
            "         ...,\n",
            "         [-1.8203,  1.5152,  1.5883,  ...,  1.4521,  1.4647, -0.8589],\n",
            "         [-0.4905,  1.8454,  0.5789,  ...,  2.4571, -0.8484, -0.7420],\n",
            "         [-0.3872,  0.4354,  1.6094,  ...,  1.0863, -0.1417, -0.7822]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         [-0.0293, -1.5136, -0.2247,  ..., -0.5071, -0.6353,  2.4972],\n",
            "         ...,\n",
            "         [-0.2886, -0.8704,  0.6625,  ..., -1.6532,  0.8268, -1.4911],\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         [ 1.0408, -1.4172,  0.8102,  ..., -2.3839, -0.5781, -0.7736]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.2142, -1.3219, -0.9208,  ..., -0.7035, -0.8742, -2.0800],\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669],\n",
            "         [ 1.6991, -1.6463, -0.3822,  ...,  0.5746, -1.1788, -0.6846],\n",
            "         ...,\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122]],\n",
            "\n",
            "        [[ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.2429, -1.2897,  0.5451,  ..., -1.4117,  0.3493, -1.7464],\n",
            "         ...,\n",
            "         [ 0.4757,  0.2258, -0.5199,  ..., -0.3703, -1.8289,  0.8458],\n",
            "         [-0.7434, -0.3094, -0.4503,  ..., -1.5657,  0.3672,  0.9442],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168]],\n",
            "\n",
            "        [[ 1.0818, -0.0166, -0.1110,  ..., -0.8440, -0.8880,  0.6695],\n",
            "         [-1.4115,  1.5391, -0.6777,  ...,  0.0700, -0.0109,  0.6465],\n",
            "         [ 0.2191, -0.5033,  0.4197,  ..., -1.5638, -0.4778, -1.8545],\n",
            "         ...,\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  561,   339,   910,   284,   616,   835,   286,  1762,    30,  2011],\n",
            "        [ 5469,   438, 14363,   938,  4842,  1650,   353,   438,  2934,   489],\n",
            "        [  351,   262,  4269,    11, 22211,   262,  6678, 40315, 10455,   546],\n",
            "        [ 1908,   477,   616, 20348,   287,  5963,    11,   290,   314,   550],\n",
            "        [ 8465,   286,   281, 33954,   271,  3973,  9899, 14678, 40556,    12],\n",
            "        [ 5019, 19001,   286,   262,  5739,  1444,   510,   477,   402,   271],\n",
            "        [ 2138,  1807,   340,   561,   423,   587, 10598,   393, 28537,  2014],\n",
            "        [ 6451,  5091,   284,   502,   284,  4240,  1521,   402,   271, 10899]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-2.2530,  0.7858, -1.5418,  ...,  0.3413, -0.3559,  0.4938],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.6074,  1.0642,  0.0900,  ...,  0.4162, -1.2428, -1.2814],\n",
            "         ...,\n",
            "         [-0.5388,  1.3834, -0.0118,  ..., -0.6513,  0.7522,  0.0220],\n",
            "         [ 0.9895, -0.3105,  1.0758,  ...,  0.5757, -1.7812,  1.7524],\n",
            "         [ 0.2750, -0.4921, -0.8413,  ..., -1.3869, -0.2290, -0.3564]],\n",
            "\n",
            "        [[ 1.8558, -0.4207,  0.9219,  ...,  0.0690,  0.5103,  0.3716],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-0.1539, -1.2487, -0.2578,  ...,  0.5349, -0.1340, -0.4338],\n",
            "         ...,\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-2.2346, -0.0349,  0.2781,  ..., -2.2120,  1.4665,  2.3028],\n",
            "         [-0.7436, -1.1724, -0.4809,  ...,  1.6121, -0.8172, -0.3760]],\n",
            "\n",
            "        [[-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 1.3907, -1.8170, -1.1618,  ..., -0.4571, -0.9212,  1.7550],\n",
            "         ...,\n",
            "         [-0.7125, -1.5649, -0.9436,  ..., -0.8540,  0.6916,  0.3048],\n",
            "         [-1.2727, -1.3931, -0.8026,  ...,  1.1272,  1.0234, -0.4924],\n",
            "         [ 0.1116, -0.2741,  0.2720,  ...,  0.2087, -1.9009,  1.2337]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.1828,  1.4910,  0.8042,  ...,  0.7597,  0.2075, -1.5580],\n",
            "         [ 0.3507,  0.6427, -1.2619,  ...,  2.5427,  1.4590, -0.7813],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         ...,\n",
            "         [-1.8818, -0.1470,  1.4267,  ...,  1.2142, -0.4687,  1.1407],\n",
            "         [ 0.1605,  0.5546, -1.5836,  ..., -0.6178,  0.3921,  0.3794],\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932]],\n",
            "\n",
            "        [[ 1.0796,  0.5387, -0.5124,  ...,  3.0793, -0.7899, -0.8292],\n",
            "         [ 0.6083, -0.8358,  0.8137,  ...,  1.3855, -0.2252, -2.8407],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         ...,\n",
            "         [ 1.1244, -1.2054, -0.3469,  ..., -1.1796,  1.0199,  0.2553],\n",
            "         [-1.3703,  0.5391, -0.8399,  ..., -2.2624,  0.4898, -0.7184],\n",
            "         [ 0.2588, -0.8815, -0.2177,  ...,  0.9409,  0.3939,  1.4858]],\n",
            "\n",
            "        [[ 0.0842, -0.2990,  0.0408,  ..., -1.4210, -0.2550,  0.3935],\n",
            "         [ 1.5248,  1.1893, -1.1195,  ..., -0.9639, -0.1961, -1.7437],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         ...,\n",
            "         [ 0.1605,  0.5546, -1.5836,  ..., -0.6178,  0.3921,  0.3794],\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932],\n",
            "         [ 1.1719, -1.1535, -0.8172,  ...,  0.6310,  0.1205,  1.0727]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  257,  8500,  4417,   284,   670,   319,   438, 15464,    11,   355],\n",
            "        [21595,  1133,   340,   656,  5563,   286,  1242,   290, 13064,    13],\n",
            "        [  683,    13,  5514,   339,   373,    11,   832,   340,   477,   290],\n",
            "        [ 7837,    12,  9649,    11,   262,  5486,    12,    83, 29080,    11],\n",
            "        [    1,  5297,   438, 37121,  1035, 27339,   284,   262, 21296,    13],\n",
            "        [  373,   884,   281,  1167,  2588,   856,   607,  2781,   526,   198],\n",
            "        [ 1234,   262, 14093,   656,   465,  1021,   757,   438, 10919,   257],\n",
            "        [ 1573,    11,   319,  9074,    13,   536,  5469,   338, 11914,    11]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 0.0275, -2.0599,  0.1847,  ...,  1.6160, -0.0329,  1.7109],\n",
            "         [ 0.2772,  0.3029, -0.6453,  ..., -1.1636, -0.9590,  0.0646],\n",
            "         ...,\n",
            "         [ 0.4852,  2.1005, -0.4457,  ..., -0.5831,  0.3422, -0.4744],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.6854,  1.3182,  0.0065,  ..., -0.0078,  0.6241,  2.8329]],\n",
            "\n",
            "        [[ 1.3834, -1.1135,  0.6797,  ..., -0.5946,  0.6208, -1.2035],\n",
            "         [ 0.4574, -1.4052, -1.2801,  ...,  0.9460,  0.4571,  0.3490],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 1.1924,  1.1321,  1.2684,  ...,  0.5575,  0.8307, -0.0892],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.1805,  0.1697, -0.4166,  ...,  1.9568, -0.2134,  0.7935],\n",
            "         ...,\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [-1.8818, -0.1470,  1.4267,  ...,  1.2142, -0.4687,  1.1407],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [ 0.2632,  0.7728,  0.9803,  ..., -1.3675, -0.2758,  1.1261],\n",
            "         [ 0.0549, -2.4333, -0.2990,  ...,  2.0638,  0.1869,  0.3926],\n",
            "         ...,\n",
            "         [ 0.9787, -2.1209, -0.4712,  ...,  0.2912, -1.8307,  2.1007],\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        [[ 0.3848, -1.1319, -0.1868,  ...,  0.2167,  0.6678, -0.2727],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 1.2796,  0.3274,  0.6681,  ..., -0.3687,  0.7753, -0.3436],\n",
            "         ...,\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-0.0246, -0.9546,  1.5227,  ...,  1.5419,  0.9871, -2.7504],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310]],\n",
            "\n",
            "        [[-0.3683,  0.7111,  0.6609,  ..., -0.0249,  0.4604, -1.1605],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691],\n",
            "         ...,\n",
            "         [ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947],\n",
            "         [ 0.5945, -1.0674,  1.2868,  ...,  1.5214, -0.2000, -0.4052],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  498,   326,    11,   287,   262, 29543,  2745,    11,   314,  4752],\n",
            "        [ 7997,    11,   319,   465,   636,    11,   257, 29844,   286, 12749],\n",
            "        [ 4808,  9776,    62,  1165,  2739,   438,   270,   561,   423,   587],\n",
            "        [ 5527,    26,   290,   340,   373,  3393, 34953,   856,   326,   607],\n",
            "        [  340,    11,   616, 13674,  5891,   438,  1092,   517,   621,   611],\n",
            "        [   13,  2329,   257,  3465,     0,   887,   340,  4952,   465,  2187],\n",
            "        [ 1022,   514,  2474,   198,   198,  1544, 13818,  4622,    11,  1231],\n",
            "        [  266,   896,     6,   886,   314,  5220, 41379,   293,    13,  3363]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.0718, -1.7699, -0.1238,  ..., -0.0843,  0.5223, -1.1041],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [-2.3914, -0.3890,  0.0341,  ...,  0.7225,  1.2186,  0.9979]],\n",
            "\n",
            "        [[ 1.2382,  0.5441,  0.3119,  ..., -0.0770, -0.3442,  0.2675],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691],\n",
            "         ...,\n",
            "         [ 1.8738, -0.8161, -0.1728,  ..., -1.1043,  0.2098,  1.3321],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.2581, -1.4176, -0.0334,  ..., -1.3588,  0.8057, -1.4865]],\n",
            "\n",
            "        [[-3.0595, -0.2339,  0.5616,  ..., -0.7120, -0.0500, -0.6366],\n",
            "         [ 1.2210,  0.9798,  1.1341,  ..., -0.3086, -0.6145,  0.7419],\n",
            "         [-0.8456, -1.2353, -0.3830,  ...,  0.8410, -1.3609, -0.3384],\n",
            "         ...,\n",
            "         [-2.2530,  0.7858, -1.5418,  ...,  0.3413, -0.3559,  0.4938],\n",
            "         [ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         [-0.5943, -0.3263,  1.4159,  ...,  1.0044,  1.4835, -1.5602]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.1785, -1.6427, -0.1530,  ...,  0.7322,  0.1999,  1.9654],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         ...,\n",
            "         [ 0.8169,  1.4974, -0.1988,  ..., -0.2778, -1.7087,  0.6866],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [-0.5536, -0.0424,  0.5344,  ..., -2.4553,  0.5610, -1.4110]],\n",
            "\n",
            "        [[-2.8510, -0.4007,  0.7073,  ...,  0.7650,  0.7288, -0.9239],\n",
            "         [ 0.6573,  0.2050, -1.1197,  ...,  0.6030,  0.0820,  0.7867],\n",
            "         [ 1.0062,  2.2786,  1.9551,  ..., -0.2413, -1.2359,  0.7069],\n",
            "         ...,\n",
            "         [ 0.0163,  1.1493,  2.1597,  ...,  1.0274, -0.7004, -0.8696],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.1493, -1.4356,  2.2383,  ..., -1.5074,  0.4848, -0.4251]],\n",
            "\n",
            "        [[ 0.6059, -0.0871,  0.7775,  ...,  0.4497, -0.5611, -1.4997],\n",
            "         [-0.0360, -1.2682,  0.0375,  ..., -2.1487, -0.5944, -0.2497],\n",
            "         [-1.4413, -0.1894,  0.2892,  ..., -0.5915,  0.2801, -0.6825],\n",
            "         ...,\n",
            "         [ 1.2842,  0.6056,  1.7327,  ...,  0.0999, -0.4588,  1.1103],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.0194, -0.1575,  0.1045,  ...,  0.2300,  1.5971, -1.6286]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 2745,     6,  4686,  1359,   319,   262, 34686, 41976,    11,   340],\n",
            "        [  284,  1234,   340,   438,    62,    40,   550,  1239,  1900, 44807],\n",
            "        [  673,  3636,   470,  1309,   502,   572,   438,   392,   379,   616],\n",
            "        [50085,   438,   272,  1468, 10032, 50085,    11,  5055,   287,   262],\n",
            "        [  373,   366, 47914,  1298,   319,   326,   966,   314,   714,   423],\n",
            "        [  326,    11,   287,   262,  6001,   286,   465, 13476,    11,   339],\n",
            "        [  329,   502,   284,  7521,   683,   618,   339,   373,  2636,   526],\n",
            "        [ 6899,    11,   290,   510,   262,  3094, 16046,   351,  1059,   430]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 1.2807,  2.3773,  0.6948,  ..., -0.5253, -1.7752,  0.5699],\n",
            "         [-1.4413, -0.1894,  0.2892,  ..., -0.5915,  0.2801, -0.6825],\n",
            "         [ 0.1977, -1.9625, -0.6076,  ...,  0.6191,  2.3611, -0.6713],\n",
            "         ...,\n",
            "         [ 0.6506,  1.0083, -0.7479,  ...,  0.4177,  0.8132, -0.6996],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311]],\n",
            "\n",
            "        [[-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [ 0.3848, -1.1319, -0.1868,  ...,  0.2167,  0.6678, -0.2727],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         ...,\n",
            "         [ 0.5474, -0.9886,  2.2438,  ...,  1.9493,  0.3414,  1.4793],\n",
            "         [ 1.4878, -0.0861,  0.3809,  ...,  0.2990,  0.4737,  0.1026],\n",
            "         [ 0.9742, -1.7226, -0.3402,  ..., -1.1091,  1.2485,  0.0605]],\n",
            "\n",
            "        [[ 0.1583,  0.0856, -1.6712,  ..., -1.3325, -0.4703, -0.9782],\n",
            "         [-1.5611, -0.3022, -0.0248,  ...,  1.1916,  0.3670,  1.8461],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         ...,\n",
            "         [ 1.0818, -0.0166, -0.1110,  ..., -0.8440, -0.8880,  0.6695],\n",
            "         [-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         ...,\n",
            "         [ 0.0090,  0.8745,  0.4864,  ..., -0.3722,  0.5785, -0.1484],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748]],\n",
            "\n",
            "        [[ 0.9922,  1.1803, -0.9523,  ...,  1.1973,  0.0708,  0.3740],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         ...,\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415],\n",
            "         [-0.7813, -0.4880,  1.4194,  ..., -0.7981, -0.9985,  2.2210],\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053]],\n",
            "\n",
            "        [[-0.7737,  0.4774,  1.7610,  ...,  1.0773, -1.0808, -2.0465],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [ 0.8207,  1.6457, -0.9612,  ...,  0.0937, -0.2815, -0.8480],\n",
            "         [-0.4027,  1.8826, -0.1600,  ...,  1.1329, -0.0473,  0.4250]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  422,   257,  2180,  2612,  1368,    13,  2329,   257,  3465,     0],\n",
            "        [   82, 24357,  1871, 12734,   379,  1123,  9581,    13,   198,   198],\n",
            "        [   13,   198,   198,    40,  3114,   546,   262, 40894,  2330,    12],\n",
            "        [   77,   470,  1986,   340,    13,   887,   314,  4137,  3589,   284],\n",
            "        [ 6653,  3656, 27846,   379,   683,  1207,  8344,   803,   306,    11],\n",
            "        [  198,     1,  5195,  4808, 10134,    62,   339,   442, 17758, 12036],\n",
            "        [ 2087,   329,   616, 35957,    25,   366, 14295,   318,   523, 34813],\n",
            "        [ 2081,    13,   764,   764,   764,   843,   339, 13055,   520,  5493]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.1729,  0.6175,  2.3042,  ...,  1.0319, -0.2190, -0.3214],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 0.3498, -0.3233, -0.5414,  ...,  2.1640,  0.8493, -0.3598],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-0.2138, -0.3677,  0.4517,  ...,  0.3898,  0.8514,  0.0786],\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174]],\n",
            "\n",
            "        [[-0.4841,  0.2688,  0.8787,  ...,  0.8826, -0.0787, -0.6992],\n",
            "         [-1.6567,  0.7164, -0.6389,  ...,  0.1117,  0.7835,  0.3739],\n",
            "         [-0.6334, -0.3352, -0.4789,  ...,  0.7198,  0.9344,  0.4141],\n",
            "         ...,\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [-1.2713, -0.9224, -0.9832,  ..., -0.0364,  1.6537, -2.1935],\n",
            "         [ 0.8108,  0.3175, -0.3640,  ...,  0.1031,  0.5812,  1.5810],\n",
            "         [-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [-1.7000,  0.4125, -1.0001,  ...,  0.6677,  0.8427, -0.6363],\n",
            "         ...,\n",
            "         [-0.5832, -0.7594, -0.6373,  ..., -1.1156,  0.3075,  0.5766],\n",
            "         [-1.2443, -1.0001,  1.3434,  ...,  0.3107,  1.2247,  0.7603],\n",
            "         [-0.2122,  0.2130,  0.6530,  ...,  0.0757,  0.1124, -1.2027]],\n",
            "\n",
            "        [[-2.2833, -0.1711, -0.5038,  ..., -1.4326,  0.9504, -0.8680],\n",
            "         [ 0.9922,  1.1803, -0.9523,  ...,  1.1973,  0.0708,  0.3740],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         ...,\n",
            "         [ 2.1120,  1.0673, -1.0083,  ...,  0.2292,  1.3644, -0.4726],\n",
            "         [ 0.5801, -1.7379, -0.3187,  ..., -0.7272, -1.4554,  0.0465],\n",
            "         [ 0.5417, -0.8924, -0.8329,  ..., -2.1396, -0.6802, -1.6355]],\n",
            "\n",
            "        [[-0.4422, -0.4098,  0.6754,  ..., -0.6289, -1.7703, -1.4365],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-0.8599,  2.2641,  2.0736,  ...,  0.6570,  0.5910, -1.6616],\n",
            "         ...,\n",
            "         [ 0.9286,  1.3668, -0.3015,  ...,  1.7035, -0.7477,  0.7099],\n",
            "         [-0.2142, -1.3219, -0.9208,  ..., -0.7035, -0.8742, -2.0800],\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 3211,   832,  6164,    25,   366, 16773,   290,   766,   262,  1334],\n",
            "        [  584,  1595,   470,   954,    11,   780,   339,  6572,   340,   526],\n",
            "        [  612,  1997,   319,  4534,   314,  3636,   470,   423,  1813,   284],\n",
            "        [ 3589,   588,   530,   286,   616,   898,  1650,  1010,    13,   198],\n",
            "        [ 1123,  9581,    13,   198,   198,   818,   262,  5391,    76,   395],\n",
            "        [  287,  3589,   438,   392,   783,   340,   338,   281,  2087,  9839],\n",
            "        [20394,   262, 23755,   286,   262, 14005,  1801,  2093, 41160,    11],\n",
            "        [  429, 25839,  9230,   808,   276,   416,   257,  8212,   326, 13663]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.0721, -1.3084,  0.1502,  ..., -0.4055, -0.4681, -0.1809],\n",
            "         [-2.0414,  0.1972,  0.8460,  ...,  0.8593, -0.9869, -0.9807],\n",
            "         [-1.6290, -0.3647, -1.0031,  ...,  1.4112, -0.3414,  1.4907],\n",
            "         ...,\n",
            "         [-0.3128, -0.2570,  0.3336,  ..., -0.4578, -1.1063, -0.7198],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.3277,  0.6030, -1.6587,  ...,  0.1158,  0.2659,  0.9081]],\n",
            "\n",
            "        [[-1.1858, -0.7021, -0.7086,  ...,  0.7179, -1.1733,  0.2045],\n",
            "         [-1.5816,  0.4821,  1.3468,  ..., -0.1353, -1.0360,  0.6760],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         ...,\n",
            "         [ 0.6209,  0.8307,  0.1653,  ..., -1.7517, -0.0668, -1.5959],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053]],\n",
            "\n",
            "        [[-0.8823,  0.2951,  0.7940,  ..., -1.3889, -1.3655,  0.3754],\n",
            "         [-1.3061, -0.7769, -0.5426,  ..., -0.0923,  0.5525,  0.6030],\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691],\n",
            "         ...,\n",
            "         [ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         [ 0.3681, -0.5106, -0.6107,  ...,  0.0823, -0.1694, -0.6275],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         [-1.1278, -1.5124,  1.2512,  ..., -1.0049,  0.2106, -0.1484],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         ...,\n",
            "         [ 0.0549, -2.4333, -0.2990,  ...,  2.0638,  0.1869,  0.3926],\n",
            "         [-2.2833, -0.1711, -0.5038,  ..., -1.4326,  0.9504, -0.8680],\n",
            "         [ 1.2531,  1.2102, -0.2875,  ..., -0.5065, -0.4502,  1.5457]],\n",
            "\n",
            "        [[-0.0129, -1.2174,  1.6770,  ...,  0.6285,  1.3765, -0.5715],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 1.4992,  0.2794,  0.9899,  ..., -0.1853, -0.2631,  1.6390],\n",
            "         ...,\n",
            "         [-1.6003,  0.2415, -0.4158,  ...,  0.8999,  0.0560, -0.1399],\n",
            "         [-0.4193,  0.0063, -0.3856,  ..., -1.6812, -0.4690, -0.6410],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[ 0.0925, -0.6257, -0.2761,  ..., -0.7193, -0.2528,  0.6815],\n",
            "         [-0.0156, -1.4376,  0.3112,  ..., -0.4724, -0.9550, -1.2708],\n",
            "         [ 0.2896,  0.1334,  1.6999,  ..., -0.8960,  2.1079,  0.7449],\n",
            "         ...,\n",
            "         [-1.1224, -1.0744, -1.3093,  ..., -0.3153, -0.7966,  0.0362],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [-0.8316,  1.3643, -0.8612,  ...,  0.2916, -0.2240,  0.7088]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  262,  1611,   326,   389,  1364,  2157,    13,  2750,   449,   659],\n",
            "        [44852,    88,    13,  2735,   314,  2497,   326,   339,   373, 21840],\n",
            "        [  812,  1568,   326,    11,   287,   262,  1781,   286,   257,  1178],\n",
            "        [ 2138,   588,   284,  1560,   345,   438, 13893,   314,  1053,  1464],\n",
            "        [   11,   257, 22791,   278,   286, 32375,    11,   257, 22486,    11],\n",
            "        [10840,    11, 10371,   257,  1534,  4241,   286, 19217,   290, 18876],\n",
            "        [   62,  4964,   502,    11,   644,   561,   339,   910,   284,   616],\n",
            "        [  607,  4808,  5562,    62,   438,   270,   561,   423,   587,  8312]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 1.5390e+00, -1.9419e+00,  6.6731e-01,  ..., -1.1945e+00,\n",
            "           7.3522e-01, -9.9032e-01],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         ...,\n",
            "         [ 7.9607e-01,  1.1434e+00, -3.5159e-01,  ..., -4.4308e-01,\n",
            "           5.7676e-01, -3.1311e+00],\n",
            "         [ 1.4754e+00, -5.8343e-01, -2.8439e-01,  ...,  1.6068e+00,\n",
            "           1.2106e+00, -7.8312e-01],\n",
            "         [-1.1720e+00,  2.5678e-01,  1.4024e+00,  ...,  6.0325e-01,\n",
            "           7.4403e-01,  8.9391e-01]],\n",
            "\n",
            "        [[ 5.3637e-03,  7.0587e-01,  9.2918e-01,  ..., -3.1302e-01,\n",
            "           1.5942e+00, -1.1917e+00],\n",
            "         [-1.7982e+00, -1.4933e+00, -7.9320e-01,  ...,  6.0523e-01,\n",
            "          -2.2488e-02, -5.6144e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         ...,\n",
            "         [-3.5449e-01, -2.3002e-01, -2.0778e-01,  ..., -1.5570e-01,\n",
            "           1.1122e-01,  2.2748e+00],\n",
            "         [ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [ 2.8346e-01, -3.3718e-01, -1.5391e+00,  ..., -3.1401e-01,\n",
            "          -4.7309e-01, -2.0172e-03]],\n",
            "\n",
            "        [[ 8.7992e-01,  2.3234e+00, -1.8037e+00,  ...,  1.7807e+00,\n",
            "          -1.5918e+00, -8.3647e-01],\n",
            "         [-2.5216e-01,  1.0295e-02, -4.3785e-01,  ..., -7.8810e-02,\n",
            "           6.7418e-01, -1.1329e+00],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         ...,\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         [-8.2702e-01,  5.7216e-01, -1.1308e+00,  ..., -1.2577e+00,\n",
            "           9.1682e-01,  4.2039e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.0097e+00,  5.1306e-01,  7.5484e-01,  ...,  9.3992e-01,\n",
            "           9.3453e-01, -7.6885e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [-5.2616e-01,  1.5002e+00, -9.1308e-01,  ...,  6.4895e-01,\n",
            "           1.3045e+00,  7.5949e-01],\n",
            "         ...,\n",
            "         [ 4.1922e-01, -1.5328e+00, -2.6889e+00,  ..., -6.1910e-01,\n",
            "           4.7012e-01,  1.1289e+00],\n",
            "         [-1.1610e+00, -3.3992e-01,  6.4933e-01,  ..., -1.1030e-01,\n",
            "           4.8025e-01, -1.4159e+00],\n",
            "         [-7.6655e-01, -4.8398e-01,  2.9960e-01,  ..., -2.2167e-01,\n",
            "          -1.1776e+00,  1.2294e+00]],\n",
            "\n",
            "        [[-8.4558e-01, -1.2353e+00, -3.8301e-01,  ...,  8.4102e-01,\n",
            "          -1.3609e+00, -3.3840e-01],\n",
            "         [-3.3066e-01, -9.9804e-01,  1.3099e-01,  ..., -1.1845e+00,\n",
            "          -3.7369e-01,  4.1907e-01],\n",
            "         [ 8.9528e-01, -1.4435e-01,  9.4515e-01,  ...,  2.2872e-01,\n",
            "          -9.7809e-03, -5.8368e-01],\n",
            "         ...,\n",
            "         [ 6.0738e-01,  1.0642e+00,  8.9991e-02,  ...,  4.1625e-01,\n",
            "          -1.2428e+00, -1.2814e+00],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [ 9.3177e-02, -1.4416e+00, -1.1102e+00,  ...,  3.1926e-01,\n",
            "           2.5096e+00,  1.2252e+00]],\n",
            "\n",
            "        [[-1.9156e+00, -1.6805e+00, -2.7495e-02,  ..., -1.4683e+00,\n",
            "          -3.7265e-03, -2.2936e-01],\n",
            "         [-3.0595e+00, -2.3386e-01,  5.6158e-01,  ..., -7.1203e-01,\n",
            "          -4.9988e-02, -6.3656e-01],\n",
            "         [ 4.4494e-01, -2.2295e+00,  3.6817e-01,  ...,  4.1714e-01,\n",
            "          -2.6349e-01, -7.9117e-01],\n",
            "         ...,\n",
            "         [ 7.8450e-01,  1.3598e+00, -1.1044e+00,  ...,  2.9561e-02,\n",
            "          -3.5540e-02, -3.0833e-01],\n",
            "         [-5.9430e-01, -3.2627e-01,  1.4159e+00,  ...,  1.0044e+00,\n",
            "           1.4835e+00, -1.5602e+00],\n",
            "         [ 1.3329e-01, -5.1743e-01, -5.0665e-01,  ...,  1.2276e-01,\n",
            "          -8.4983e-01,  4.1994e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  717, 18560,   286,  3619,   338,   314,   550,  1683,   550,   284],\n",
            "        [ 3842,    13,   198,   198,     1, 12295,   553,   339,   531, 11589],\n",
            "        [ 1297,  9074,    13,   520,  5493,   339,   373,   262,   705,  4976],\n",
            "        [  438, 13893,   314,  1053,  1464,  9885,   345,   286,  2376, 26927],\n",
            "        [ 2077,   510,   290,  1364,  3436,   351,   683,    13,   314,   550],\n",
            "        [  287,   281,  8468,  4922,   284,   262,  3359,   286,   428,  3991],\n",
            "        [ 4286,   705,  1014,   510,    26,   475,   314,   836,   470,   892],\n",
            "        [10938,   319,   262,  3355,  1474,   465,  3996,    13,  2399,  3656]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-6.3135e-01,  3.0046e-01,  1.7098e+00,  ..., -4.8088e-01,\n",
            "           4.1058e-01,  9.0966e-01],\n",
            "         [-5.5027e-01, -1.8688e-01,  7.3975e-01,  ...,  9.6038e-01,\n",
            "          -6.5985e-01, -1.1398e+00],\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         ...,\n",
            "         [-1.4094e+00,  2.2755e-01, -7.9725e-01,  ...,  6.0085e-01,\n",
            "          -1.9227e+00, -7.8031e-01],\n",
            "         [ 1.1637e+00, -1.1183e+00, -1.0012e+00,  ...,  1.8436e-01,\n",
            "           5.0564e-01, -9.0855e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01]],\n",
            "\n",
            "        [[-2.5557e-02, -4.3652e-02, -9.3262e-02,  ..., -7.0153e-01,\n",
            "          -1.0032e+00,  1.6064e+00],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         ...,\n",
            "         [-3.5449e-01, -2.3002e-01, -2.0778e-01,  ..., -1.5570e-01,\n",
            "           1.1122e-01,  2.2748e+00],\n",
            "         [ 1.1944e+00,  1.4784e+00, -9.0983e-01,  ..., -9.1449e-01,\n",
            "          -3.7983e-01,  2.2964e+00],\n",
            "         [-8.9493e-01, -9.8927e-01,  1.0718e+00,  ...,  2.7644e-01,\n",
            "          -4.3649e-01,  1.0597e+00]],\n",
            "\n",
            "        [[ 2.1399e-01,  1.9347e-01,  1.0648e+00,  ...,  2.1137e+00,\n",
            "           3.4164e+00,  3.5804e-01],\n",
            "         [-1.7958e+00, -2.5592e-01, -2.5860e-02,  ..., -3.9778e-01,\n",
            "           7.9161e-02, -6.1532e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         ...,\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 6.0641e-01,  5.2062e-01,  7.6219e-01,  ..., -4.9666e-01,\n",
            "          -5.7407e-01,  3.0310e-01],\n",
            "         [ 4.6267e-01, -1.5052e+00,  1.4354e+00,  ..., -5.6050e-01,\n",
            "           1.1524e+00, -3.2073e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.1606e+00,  6.6746e-01,  9.5967e-01,  ...,  1.3476e+00,\n",
            "           1.1898e+00,  6.4805e-01],\n",
            "         [ 5.4922e-02, -2.4333e+00, -2.9900e-01,  ...,  2.0638e+00,\n",
            "           1.8694e-01,  3.9260e-01],\n",
            "         [-6.4362e-01,  1.8909e-01, -1.8678e-01,  ...,  8.6743e-01,\n",
            "          -4.2304e-01, -1.1535e-01],\n",
            "         ...,\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [ 3.3093e-01,  2.2000e+00, -6.9947e-01,  ...,  5.5905e-01,\n",
            "           2.4344e+00, -1.0442e+00],\n",
            "         [ 9.0888e-01, -2.0559e-02, -8.7919e-01,  ...,  2.0621e+00,\n",
            "          -6.7620e-01, -7.8288e-01]],\n",
            "\n",
            "        [[-8.3819e-02, -7.0415e-01,  1.6023e+00,  ...,  2.1075e-01,\n",
            "          -3.0558e+00, -1.6331e+00],\n",
            "         [ 6.0641e-01,  5.2062e-01,  7.6219e-01,  ..., -4.9666e-01,\n",
            "          -5.7407e-01,  3.0310e-01],\n",
            "         [-8.2068e-01,  2.3296e-02, -3.5166e-01,  ..., -5.0072e-01,\n",
            "           1.0315e+00, -6.1829e-01],\n",
            "         ...,\n",
            "         [-1.3206e+00,  1.2269e+00,  1.8095e-01,  ..., -9.4589e-02,\n",
            "           1.1827e+00, -2.2615e-03],\n",
            "         [ 1.0791e-01, -8.7473e-01, -1.6640e+00,  ..., -1.4962e+00,\n",
            "          -1.4791e+00, -6.8406e-01],\n",
            "         [-8.4130e-01, -2.4365e-01, -5.3264e-01,  ...,  6.7974e-01,\n",
            "          -5.3410e-01, -7.8986e-01]],\n",
            "\n",
            "        [[-4.3941e-01, -2.8094e-01,  1.0625e+00,  ..., -2.4242e-01,\n",
            "          -1.2178e+00, -6.9610e-01],\n",
            "         [-4.5832e-01, -1.6412e+00, -5.1882e-01,  ...,  1.0188e+00,\n",
            "           1.6275e-01,  1.2691e+00],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         ...,\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [-1.1337e-03,  1.0489e+00, -5.1993e-01,  ...,  6.8896e-01,\n",
            "          -1.9051e+00, -3.0615e-02],\n",
            "         [ 7.6380e-01, -3.5983e-01, -6.0103e-01,  ...,  2.4469e-01,\n",
            "          -2.2343e-01,  3.2076e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  416,   262, 13476,   286,   616, 12036,   683,     0,  3226,  1781],\n",
            "        [  257,  7644,   326,   339,  1239,  1807,   286,  1997,  2073,    13],\n",
            "        [  262,   530,  1517,   326,  6774,   502,  6609,  1474,   683,   318],\n",
            "        [  587,  1327,   284,  5879,   326,   339,   550,  1813,   510,   465],\n",
            "        [ 1401,    77,  3929,  1528,    11,   530,   714,  1464,   651,  1474],\n",
            "        [ 1207,  8344,   803,   306,    11,   475,   465,  2951, 21650,  1613],\n",
            "        [ 5562,   373,   644,   262,  1466,  1444,   340,    13,   314,   460],\n",
            "        [  438,   292,   314, 10226,   262,  1182,   287,   314,  2936,   355]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 5.2904e-01,  1.2444e+00, -1.8292e+00,  ...,  2.7274e-01,\n",
            "          -1.6876e+00,  5.1756e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 9.0040e-03,  8.7445e-01,  4.8641e-01,  ..., -3.7217e-01,\n",
            "           5.7854e-01, -1.4841e-01],\n",
            "         ...,\n",
            "         [ 5.0511e-01,  2.0639e-01,  9.4309e-01,  ..., -1.2557e+00,\n",
            "           4.4932e-01, -3.1742e-01],\n",
            "         [-1.3398e+00, -4.0596e-01,  5.0522e-01,  ...,  8.6774e-01,\n",
            "           1.8287e+00,  1.9109e+00],\n",
            "         [ 1.1556e+00,  1.4463e-01, -1.1558e+00,  ...,  3.9831e-01,\n",
            "           3.1140e-01,  7.8209e-01]],\n",
            "\n",
            "        [[-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         [-7.2872e-01, -1.0308e+00,  1.1150e+00,  ...,  5.1393e-01,\n",
            "           5.4418e-01,  2.1539e-01],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         ...,\n",
            "         [-1.3061e+00, -7.7685e-01, -5.4259e-01,  ..., -9.2273e-02,\n",
            "           5.5252e-01,  6.0297e-01],\n",
            "         [ 1.7554e+00,  5.1214e-02,  1.3383e+00,  ..., -2.1320e+00,\n",
            "           5.5523e-01, -2.0503e+00],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00]],\n",
            "\n",
            "        [[-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 2.0277e-01, -3.2441e-01,  5.8122e-02,  ...,  1.2838e+00,\n",
            "           1.1483e+00,  1.3023e+00],\n",
            "         [ 5.3971e-02,  8.2846e-01, -6.1118e-01,  ..., -5.4833e-01,\n",
            "          -1.0730e+00,  2.0751e-01],\n",
            "         ...,\n",
            "         [-9.4686e-02,  1.8411e+00, -1.5012e+00,  ..., -8.8356e-01,\n",
            "           6.1886e-01, -1.6787e+00],\n",
            "         [ 9.9937e-01,  1.4933e+00,  1.5044e-01,  ...,  8.0270e-01,\n",
            "          -4.9967e-01, -7.8062e-01],\n",
            "         [ 2.1120e+00,  1.0673e+00, -1.0083e+00,  ...,  2.2924e-01,\n",
            "           1.3644e+00, -4.7259e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.8100e-01,  4.8930e-01,  7.1935e-01,  ...,  2.7310e-01,\n",
            "           3.8165e-01,  2.4403e-01],\n",
            "         [-8.1718e-01, -2.2330e+00, -6.6295e-01,  ...,  3.7873e-01,\n",
            "           9.6865e-01, -1.2552e+00],\n",
            "         [ 5.4321e-01,  1.3440e+00,  1.4125e+00,  ..., -1.0351e+00,\n",
            "          -1.4391e+00, -5.0727e-01],\n",
            "         ...,\n",
            "         [ 1.4609e+00, -1.6441e+00,  6.3180e-01,  ...,  1.6115e+00,\n",
            "          -1.9263e+00, -7.9017e-01],\n",
            "         [-9.7836e-01,  8.6304e-01, -1.1318e+00,  ..., -1.2322e+00,\n",
            "          -6.2130e-01, -5.4507e-03],\n",
            "         [ 5.5328e-04, -4.7625e-01, -1.1714e+00,  ...,  4.4007e-02,\n",
            "          -4.5369e-02,  5.1856e-01]],\n",
            "\n",
            "        [[ 4.4494e-01, -2.2295e+00,  3.6817e-01,  ...,  4.1714e-01,\n",
            "          -2.6349e-01, -7.9117e-01],\n",
            "         [ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [-2.8860e-01, -8.7036e-01,  6.6246e-01,  ..., -1.6532e+00,\n",
            "           8.2684e-01, -1.4911e+00],\n",
            "         ...,\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         [-5.0260e-01, -7.4068e-01,  3.1095e-01,  ...,  2.7136e-01,\n",
            "          -7.3833e-01,  2.2537e+00]],\n",
            "\n",
            "        [[-1.6872e+00,  3.5494e-01,  1.5316e+00,  ...,  1.4605e-01,\n",
            "           4.5568e-02,  3.7156e-02],\n",
            "         [-2.6781e-01, -2.3841e-02,  1.0052e+00,  ..., -9.9253e-01,\n",
            "           6.7035e-01,  5.2284e-01],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         ...,\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         [-1.2386e+00,  1.5231e+00,  5.8632e-01,  ..., -7.0340e-01,\n",
            "           9.2396e-01,  1.0341e+00],\n",
            "         [-6.8540e-01,  1.3182e+00,  6.5168e-03,  ..., -7.8027e-03,\n",
            "           6.2407e-01,  2.8329e+00]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  656,   511,  6698,    13,   764,   764,   764,  3894,    11,  7521],\n",
            "        [  290,  4920,  2241,   287,   257,  4489,    64,   319,   262, 34686],\n",
            "        [   13,   679, 28271,   465, 12450,    11,   991, 16755,    13,   198],\n",
            "        [    1,  5779,    11,  1282,   981,   339,   338,   407,  2045,   553],\n",
            "        [  673,  9174,   262,  4286,  1871,   607,  5229,   338,  1243,    13],\n",
            "        [ 8137,   286, 16957,  1696,   414,     1,   357,    40,  9577,  4544],\n",
            "        [  843,   339, 13055,   520,  5493,  1231,  1592,  2259,    26,   290],\n",
            "        [  270,   561,   423,   587,  8312,   284,   607,    13,   314,  2391]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.2733, -0.4545,  0.3124,  ..., -0.4667, -0.4967,  0.2976],\n",
            "         [ 1.1834,  0.9042, -0.6899,  ..., -1.1641,  0.0888, -0.9276],\n",
            "         [ 0.2717,  0.8333, -0.3092,  ...,  1.1854,  1.0754,  0.2245],\n",
            "         ...,\n",
            "         [ 0.5196, -1.2704,  0.2824,  ..., -0.8817, -0.1147, -0.0058],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.3837, -0.7146, -1.2462,  ...,  0.1798,  0.1274, -1.1049]],\n",
            "\n",
            "        [[-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-1.4948, -0.9257,  0.6891,  ..., -1.1241,  0.1409, -0.9085],\n",
            "         [-1.4038, -1.0566, -0.1379,  ..., -1.7105, -1.0874, -0.1505],\n",
            "         ...,\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 2.3915,  1.3330, -0.9104,  ..., -0.7661, -0.1587,  0.0928]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.4436,  0.2945,  1.0645,  ..., -0.2296,  0.2733,  0.2512],\n",
            "         [-0.9225,  0.5981, -0.0408,  ..., -0.6403, -1.0464,  0.5692],\n",
            "         ...,\n",
            "         [ 0.0614, -1.0402, -1.6069,  ...,  1.9546,  0.5787, -0.8039],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.5179, -0.0823,  0.3577,  ...,  0.8245,  0.0818, -0.6817],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.8385, -0.1143, -0.5812,  ...,  0.8508, -2.5695,  0.4040],\n",
            "         ...,\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [-0.0919, -1.5572,  0.2070,  ...,  1.7536, -0.0868,  1.5244],\n",
            "         [-0.8261, -1.9834,  0.4281,  ..., -0.7589, -0.3248,  0.9707]],\n",
            "\n",
            "        [[ 0.2423,  0.7831, -0.4994,  ...,  0.1702,  0.6767,  0.9578],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.9286,  1.3668, -0.3015,  ...,  1.7035, -0.7477,  0.7099],\n",
            "         ...,\n",
            "         [-0.2312,  1.0024,  1.6244,  ...,  0.4327, -1.4229,  0.2038],\n",
            "         [ 0.5921, -1.0570,  0.0323,  ...,  0.3138,  1.1976, -0.9763],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159]],\n",
            "\n",
            "        [[ 0.5821,  1.9366,  0.8448,  ..., -0.9704, -0.7925, -1.6757],\n",
            "         [-2.2530,  0.7858, -1.5418,  ...,  0.3413, -0.3559,  0.4938],\n",
            "         [ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         ...,\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 1.5634, -0.9411,  0.1839,  ...,  0.7733,  0.7043,  0.3825]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  818,   262,  5391,    76,   395,  5228,   286,   607,   275,  2778],\n",
            "        [  402,   271, 10899,    11,   508,   550, 18459,  1068,   284,  1577],\n",
            "        [ 8673,    13,  1002,   340,   547,    11,   262, 15393,   286,   262],\n",
            "        [  281, 10059,  2198,    13,   198,   198,     1,  1212,   318,   616],\n",
            "        [  606,   286,   511,  6799,   454,    30,  1400,   438,  1640,    11],\n",
            "        [  284,   884, 14177,  8233,  1020,  5768,    26,   290,  1719,    11],\n",
            "        [   13,   402,   271, 10899,    11,   307,  3723,   319,   683,    11],\n",
            "        [  550,   655,  8197,   606,    13,   764,   764,   764,   198,   198]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 1.5764e+00, -5.0738e-01, -7.4672e-01,  ...,  9.9465e-01,\n",
            "           2.1075e-01,  6.4693e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-3.8886e-01, -5.8954e-01,  1.9382e-01,  ...,  7.3939e-02,\n",
            "          -4.5716e-02, -3.5797e-01],\n",
            "         ...,\n",
            "         [-1.9156e+00, -1.6805e+00, -2.7495e-02,  ..., -1.4683e+00,\n",
            "          -3.7265e-03, -2.2936e-01],\n",
            "         [ 1.0538e+00, -3.1063e+00, -1.0535e+00,  ...,  4.2879e-01,\n",
            "          -2.0632e+00,  5.6537e-01],\n",
            "         [-2.3902e+00,  6.5240e-01, -1.8231e-01,  ...,  5.7755e-01,\n",
            "          -1.6936e+00, -2.0462e-01]],\n",
            "\n",
            "        [[ 1.6052e-01,  5.5458e-01, -1.5836e+00,  ..., -6.1778e-01,\n",
            "           3.9215e-01,  3.7935e-01],\n",
            "         [-5.3808e-01,  2.7976e-01,  4.3889e-01,  ..., -1.5520e+00,\n",
            "           1.2393e+00, -2.9317e-01],\n",
            "         [ 1.1719e+00, -1.1535e+00, -8.1716e-01,  ...,  6.3096e-01,\n",
            "           1.2050e-01,  1.0727e+00],\n",
            "         ...,\n",
            "         [-6.7033e-01, -1.2200e-01,  1.5265e+00,  ...,  2.5255e-01,\n",
            "          -6.8345e-01, -4.8204e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [ 5.6207e-01, -1.7547e+00,  5.7393e-01,  ..., -2.8880e-01,\n",
            "          -8.3736e-01,  1.9398e+00]],\n",
            "\n",
            "        [[ 6.4508e-01,  3.5566e-01, -8.4431e-01,  ...,  9.7749e-02,\n",
            "          -5.6653e-01,  6.0582e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [-8.1065e-01, -1.6942e+00,  2.4801e+00,  ..., -1.4467e+00,\n",
            "          -5.5446e-01, -1.2258e+00],\n",
            "         ...,\n",
            "         [ 1.8094e+00,  1.4205e+00,  2.0234e-01,  ..., -2.8953e-01,\n",
            "           9.4825e-01,  1.3301e+00],\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [ 2.6318e-01,  7.7276e-01,  9.8035e-01,  ..., -1.3675e+00,\n",
            "          -2.7581e-01,  1.1261e+00],\n",
            "         [ 5.3664e-01,  6.9310e-01, -4.9884e-01,  ..., -2.3197e-02,\n",
            "           1.2020e+00, -1.1026e+00],\n",
            "         ...,\n",
            "         [-1.1610e+00, -3.3992e-01,  6.4933e-01,  ..., -1.1030e-01,\n",
            "           4.8025e-01, -1.4159e+00],\n",
            "         [-1.2467e+00, -1.0731e+00, -3.6221e-02,  ...,  1.4086e+00,\n",
            "          -7.5818e-02,  1.4353e+00],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01]],\n",
            "\n",
            "        [[ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 1.6052e-01,  5.5458e-01, -1.5836e+00,  ..., -6.1778e-01,\n",
            "           3.9215e-01,  3.7935e-01],\n",
            "         [-5.3808e-01,  2.7976e-01,  4.3889e-01,  ..., -1.5520e+00,\n",
            "           1.2393e+00, -2.9317e-01],\n",
            "         ...,\n",
            "         [-4.5832e-01, -1.6412e+00, -5.1882e-01,  ...,  1.0188e+00,\n",
            "           1.6275e-01,  1.2691e+00],\n",
            "         [ 9.9937e-01,  1.4933e+00,  1.5044e-01,  ...,  8.0270e-01,\n",
            "          -4.9967e-01, -7.8062e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01]],\n",
            "\n",
            "        [[ 1.1637e+00, -1.1183e+00, -1.0012e+00,  ...,  1.8436e-01,\n",
            "           5.0564e-01, -9.0855e-01],\n",
            "         [-1.0407e-03, -1.2642e+00,  8.1672e-01,  ...,  2.3681e+00,\n",
            "          -8.9181e-01,  6.7308e-01],\n",
            "         [-7.6633e-01, -2.6070e-01,  4.3399e-01,  ...,  2.0173e-01,\n",
            "          -5.3454e-01, -6.8265e-01],\n",
            "         ...,\n",
            "         [-8.5991e-01,  2.2641e+00,  2.0736e+00,  ...,  6.5700e-01,\n",
            "           5.9097e-01, -1.6616e+00],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 4286,   438, 18108, 26269,  5223,   287,   281,  8468,  4922,   284],\n",
            "        [  338,   691, 12226,   318,   284,  1234,  8737,   656, 19133,   553],\n",
            "        [44455,   351,   534, 24638,  2474,   355,  1752,   530,   550,   890],\n",
            "        [ 1813,  4544,  9325,   701,   262, 40830, 12719,  3874,    13,   632],\n",
            "        [  339,   655,  4030,   465,  2951,   319,   262,  1327, 22674,  1022],\n",
            "        [  345,  1683, 45553,   903,   351,  7521,   597,   517,  1701,   314],\n",
            "        [ 7872,   393,  4808, 13698, 10322,  6532,    62,  8263,    12,  3823],\n",
            "        [ 1649,   550,   314,  1760,   326,   351,   597,   286,   616,  1243]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.0838, -0.7042,  1.6023,  ...,  0.2107, -3.0558, -1.6331],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-1.3860,  1.2220, -0.6090,  ..., -1.3778, -0.6024, -0.2443],\n",
            "         ...,\n",
            "         [-0.6436,  0.1891, -0.1868,  ...,  0.8674, -0.4230, -0.1154],\n",
            "         [ 0.6788,  1.9601, -0.2835,  ..., -1.1742, -0.2933,  0.3273],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947],\n",
            "         [-0.6035,  0.7153, -1.1398,  ...,  0.4031, -0.6096,  1.0566],\n",
            "         [ 1.2772, -1.5178, -0.5967,  ..., -0.5769, -2.0643, -0.7395],\n",
            "         ...,\n",
            "         [ 0.2733, -0.4545,  0.3124,  ..., -0.4667, -0.4967,  0.2976],\n",
            "         [ 0.7696,  0.3293,  0.9376,  ...,  0.7302,  0.5129, -0.5712],\n",
            "         [ 1.3361,  0.6034,  0.8908,  ..., -0.9077,  0.3499, -0.5623]],\n",
            "\n",
            "        [[-0.0933,  1.6087, -0.5560,  ...,  1.4703, -0.8051,  0.5983],\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [ 1.9291, -1.0747,  0.6107,  ...,  0.0267,  0.6023, -1.5198],\n",
            "         ...,\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [ 0.5153,  0.2059,  1.0240,  ..., -0.2312, -0.9292,  1.8714]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222],\n",
            "         [-1.4094,  0.2276, -0.7972,  ...,  0.6008, -1.9227, -0.7803],\n",
            "         [-0.4698, -0.7730,  0.7997,  ...,  0.7337, -1.1284,  0.1507],\n",
            "         ...,\n",
            "         [-0.8319, -1.0101,  1.3246,  ..., -0.5300,  1.5858,  0.1537],\n",
            "         [-0.7266, -1.4021, -0.8509,  ...,  0.0454,  0.8863,  0.4863],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888]],\n",
            "\n",
            "        [[ 0.1145, -0.1796,  1.9372,  ..., -1.6519, -1.9189,  1.0457],\n",
            "         [ 1.1244, -1.2054, -0.3469,  ..., -1.1796,  1.0199,  0.2553],\n",
            "         [-3.0595, -0.2339,  0.5616,  ..., -0.7120, -0.0500, -0.6366],\n",
            "         ...,\n",
            "         [-0.9056,  0.1612,  0.1972,  ..., -1.2546,  0.3972,  0.1832],\n",
            "         [-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         [ 0.7267,  0.1496, -0.3410,  ...,  1.0477, -1.0172, -1.0008]],\n",
            "\n",
            "        [[ 1.0727, -1.6385, -1.6967,  ..., -1.1941,  0.5357, -0.9299],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         ...,\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         [-0.2502,  0.5964, -0.8495,  ...,  0.5607,  0.6825,  0.3249]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 7657,   438,  9776,   340,   262, 11644, 43778,  3465,   326, 26773],\n",
            "        [ 1138,    11,   287,  1790,    11,   379,   790,   966,   262,  3512],\n",
            "        [ 6532,    62,  8263,    12,  3823,    11,   393,   257, 36364,  1396],\n",
            "        [   11,   287,  1109,    11,  5033,   262,   582,   286,   262,  2589],\n",
            "        [48740,   546,   465,  5986,    30,  2011, 20136,   373,  3957,   588],\n",
            "        [  550, 26546,  1068,   465,  1242,    11,   340,   550,   587,   302],\n",
            "        [ 4891,    11,   314,  2936,   284,   644,   257,  4922,   339,   550],\n",
            "        [  262,  5385, 41186, 39614,  1386,    11,   287,   262, 13203,  5482]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.4895, -0.5274, -0.9904,  ..., -1.6036,  0.8337,  1.9201],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 1.2210,  0.9798,  1.1341,  ..., -0.3086, -0.6145,  0.7419],\n",
            "         ...,\n",
            "         [-0.2138, -0.3677,  0.4517,  ...,  0.3898,  0.8514,  0.0786],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [-0.1186, -0.4587, -0.4815,  ...,  0.7383,  1.5030,  0.9410]],\n",
            "\n",
            "        [[-0.9105,  0.1909,  0.1168,  ...,  1.3922,  0.4173,  1.0758],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         ...,\n",
            "         [-0.8939, -0.9880,  1.1724,  ..., -0.6184,  1.4365,  0.5729],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.5052,  0.1099,  0.3911,  ...,  0.4294,  0.0743,  0.4069]],\n",
            "\n",
            "        [[ 0.7469,  0.6086, -0.2388,  ...,  1.6936, -0.5257, -1.7566],\n",
            "         [-0.8456, -1.2353, -0.3830,  ...,  0.8410, -1.3609, -0.3384],\n",
            "         [-0.9056,  0.1612,  0.1972,  ..., -1.2546,  0.3972,  0.1832],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 1.5669,  0.6622, -0.7285,  ..., -0.7233, -0.2297,  0.7696],\n",
            "         [ 0.0508, -0.9930,  2.0781,  ..., -1.2802,  0.2225,  0.8319]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [ 0.9421, -1.0566, -1.1350,  ...,  1.5728, -0.0274,  0.2545],\n",
            "         [-0.6703, -0.1220,  1.5265,  ...,  0.2526, -0.6834, -0.4820],\n",
            "         ...,\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-0.5943, -0.3263,  1.4159,  ...,  1.0044,  1.4835, -1.5602],\n",
            "         [-0.3831, -2.5885,  1.0370,  ..., -0.6092,  0.5650,  0.7280]],\n",
            "\n",
            "        [[ 0.4933,  1.5946,  1.0712,  ...,  0.0633, -0.2495,  0.7526],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         ...,\n",
            "         [ 0.6788,  1.9601, -0.2835,  ..., -1.1742, -0.2933,  0.3273],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.0452, -0.1047,  0.1196,  ...,  0.2362,  0.1839, -0.4875],\n",
            "         [ 1.0792, -1.9705,  0.0477,  ..., -0.3326,  0.2745, -0.0240],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.1254,  0.4749,  0.9957,  ..., -1.0641,  0.3080,  1.6612],\n",
            "         [ 0.1230,  0.8896,  0.3905,  ...,  0.5751,  0.1350,  0.8028]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  523,   340,  1392,   284,   307,  2081,    13,   764,   764,   764],\n",
            "        [   12,    66,  3325,  1299,    11,  3888,  7263,   257,  4808,    73],\n",
            "        [  477,    11,   645,  1551,  1051,   286,  1683,  1719,   587,   973],\n",
            "        [ 1464,   587,   465, 10030,   284,   423,  1466,   910,   884,  1243],\n",
            "        [  198,  1722,   339,  6204,   612,    11,   465,  2832,   287,   262],\n",
            "        [    0,   314, 37901,   379,   262, 21978, 44896,    11,   290,  3088],\n",
            "        [  475,   530,   553,   673, 19267,  5223,   438,     1,  4360,   262],\n",
            "        [   25,   366,    40,  1276,  1107,   766,   534, 18560,    11,   345]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.5801, -1.7379, -0.3187,  ..., -0.7272, -1.4554,  0.0465],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [ 0.7058, -0.1971, -0.0638,  ...,  1.1204,  1.0437, -0.2445],\n",
            "         ...,\n",
            "         [-0.8599,  2.2641,  2.0736,  ...,  0.6570,  0.5910, -1.6616],\n",
            "         [-0.8599,  2.2641,  2.0736,  ...,  0.6570,  0.5910, -1.6616],\n",
            "         [-0.8599,  2.2641,  2.0736,  ...,  0.6570,  0.5910, -1.6616]],\n",
            "\n",
            "        [[-0.0238,  0.7207, -1.5676,  ...,  0.2592,  2.4894,  0.2307],\n",
            "         [-0.8297, -0.2966,  1.7941,  ...,  0.2029,  0.1096,  0.7914],\n",
            "         [ 0.6933,  1.2444,  0.7747,  ...,  0.6956, -1.2794,  0.7621],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-3.0595, -0.2339,  0.5616,  ..., -0.7120, -0.0500, -0.6366],\n",
            "         [ 0.2001,  0.3547,  0.2143,  ...,  0.2509, -0.1670, -1.3008]],\n",
            "\n",
            "        [[-1.8818, -0.1470,  1.4267,  ...,  1.2142, -0.4687,  1.1407],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.9154, -1.1200, -1.2465,  ...,  0.6600,  0.1496, -0.7033],\n",
            "         ...,\n",
            "         [-1.2467, -1.0731, -0.0362,  ...,  1.4086, -0.0758,  1.4353],\n",
            "         [-0.5943, -0.3263,  1.4159,  ...,  1.0044,  1.4835, -1.5602],\n",
            "         [-1.2529,  0.9876, -1.4272,  ..., -0.7367, -0.3765, -0.4435]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 0.6263, -1.6153, -0.7190,  ...,  0.6204,  1.7039, -0.1225],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 0.0677,  1.1009,  0.0716,  ...,  0.4005, -0.4854,  1.0573]],\n",
            "\n",
            "        [[-0.2840, -2.2967,  0.9100,  ..., -0.6104, -0.6851, -0.1691],\n",
            "         [ 0.2028, -0.3244,  0.0581,  ...,  1.2838,  1.1483,  1.3023],\n",
            "         [ 1.3361,  0.6034,  0.8908,  ..., -0.9077,  0.3499, -0.5623],\n",
            "         ...,\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [-0.8208,  0.0423, -0.2230,  ...,  0.2334, -1.2991,  0.8684],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273],\n",
            "         [ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         ...,\n",
            "         [-0.5503, -0.1869,  0.7398,  ...,  0.9604, -0.6598, -1.1398],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  379,   407,  1972,   262, 18560,   438,  7091,   750,   523,   765],\n",
            "        [   13,  1550, 14580,    11,   340,  1107,   373,   257, 29850,  1917],\n",
            "        [  898,  9408,   355,   281,  2134,   329,  5482,  4447,   290,   753],\n",
            "        [  644,   257,  4922,   339,   550,   262,   976,  3081,   355,   465],\n",
            "        [  379,   262,  8812,   558,   810,   607,  5229,    11, 21081,   782],\n",
            "        [ 7425,   416,   465,   938,  1573,    13, 12622, 41379,   293,   373],\n",
            "        [ 1597,   286,   262,  4286,   284,   617,  2495, 11331,  2768,   590],\n",
            "        [  379,   326,  1517,   438, 24089,    77,   470,  1986,   340,    13]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [ 1.8880,  0.6421,  0.7259,  ...,  0.3924,  0.9928,  0.5289],\n",
            "         [-0.6832, -0.2739, -0.1945,  ..., -0.7620,  0.9859,  2.1942],\n",
            "         ...,\n",
            "         [ 0.4179, -0.6158, -0.4685,  ..., -0.8495,  1.4789, -0.7553],\n",
            "         [ 0.5801, -1.7379, -0.3187,  ..., -0.7272, -1.4554,  0.0465],\n",
            "         [-1.8516, -0.0317, -0.9060,  ..., -0.7497,  0.0700,  0.5066]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.8912,  1.5133,  0.0925,  ..., -0.8769, -0.8124, -1.4581],\n",
            "         [-0.9894, -1.3980, -1.0853,  ...,  2.1384, -1.6330,  1.1343],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 0.0619, -1.2577,  0.5068,  ...,  0.5607, -0.1006,  1.0107],\n",
            "         [-0.2861, -2.1537, -1.7462,  ...,  0.4161, -1.3639, -0.2456]],\n",
            "\n",
            "        [[-1.2603,  0.2078,  0.6411,  ..., -0.3257,  0.6318, -0.9779],\n",
            "         [ 1.2787, -0.7987, -0.1161,  ...,  0.3127, -1.0399,  0.7017],\n",
            "         [-0.6854,  1.3182,  0.0065,  ..., -0.0078,  0.6241,  2.8329],\n",
            "         ...,\n",
            "         [ 1.9387,  0.5899, -1.1472,  ...,  1.0701,  1.2103,  0.1405],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-0.6870, -0.8027, -0.4303,  ...,  1.0265, -0.3020,  0.8571]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.4392, -0.7600,  1.6267,  ..., -0.7762,  0.0656, -0.8395],\n",
            "         [ 0.5290,  1.2444, -1.8292,  ...,  0.2727, -1.6876,  0.5176],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         ...,\n",
            "         [ 1.1306, -0.2570,  1.3432,  ..., -2.3130, -1.9117,  1.8070],\n",
            "         [ 1.2842,  0.6056,  1.7327,  ...,  0.0999, -0.4588,  1.1103],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415]],\n",
            "\n",
            "        [[ 0.0545,  2.2930,  0.0462,  ...,  0.1728,  0.1055, -0.6280],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [-0.5597, -0.3712, -0.8435,  ..., -0.8124,  1.3206, -0.0039],\n",
            "         [ 0.8911, -0.8910, -0.5653,  ...,  1.0727,  0.7165, -0.7990],\n",
            "         [-0.3873,  1.2751, -1.2977,  ...,  1.0001, -0.9053,  1.2121]],\n",
            "\n",
            "        [[-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [ 0.0540,  0.8285, -0.6112,  ..., -0.5483, -1.0730,  0.2075],\n",
            "         ...,\n",
            "         [ 0.5154, -0.4168,  0.0497,  ..., -0.8714, -0.9856,  1.1729],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[   26,   788,    11,  6427,   465,  3211,   832,  6164,    25,   366],\n",
            "        [  262,   279,  1127,    11,   314,   550,  3589, 28068,   294,  1555],\n",
            "        [ 8759,  2763,    26,   393,  2138,   520,  5493,  2241,   318,   262],\n",
            "        [ 1306,  6000,  1517,   373,   284,   766,   326,   314,  3521,   470],\n",
            "        [  898,  3292,  8941,   257,  4636, 28582,    13, 18612, 35394,    30],\n",
            "        [   25,   366,  1532,   345,  1302,   994,   345,   460,   655,  6687],\n",
            "        [ 5297,    11,   314,  1107,   836,   470,   766,   703,   661,  6687],\n",
            "        [ 3595,   520,  5493,     0,  1375,  1807,   340,   262,  1654,   301]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 5.9210e-01, -1.0570e+00,  3.2271e-02,  ...,  3.1380e-01,\n",
            "           1.1976e+00, -9.7631e-01],\n",
            "         [ 6.5632e-01,  6.0983e-01,  2.7245e-01,  ..., -1.3228e+00,\n",
            "          -8.6929e-01, -6.8865e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         ...,\n",
            "         [-1.6290e+00, -3.6468e-01, -1.0031e+00,  ...,  1.4112e+00,\n",
            "          -3.4142e-01,  1.4907e+00],\n",
            "         [-1.0923e-01, -1.0082e+00, -8.2644e-01,  ...,  6.3462e-01,\n",
            "          -1.5135e+00, -7.5331e-01],\n",
            "         [-4.6720e-01, -9.1476e-01,  2.1816e+00,  ...,  1.5576e+00,\n",
            "          -6.5105e-01, -2.2725e-01]],\n",
            "\n",
            "        [[-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 6.3879e-01,  3.6567e-01, -1.8981e+00,  ..., -1.0162e+00,\n",
            "           1.4604e+00, -3.9521e-01],\n",
            "         [-6.3887e-01,  1.0340e-01,  7.1325e-01,  ...,  3.2202e-01,\n",
            "          -3.3490e-01, -8.1244e-01],\n",
            "         ...,\n",
            "         [-2.1042e+00,  4.1875e-01, -7.1742e-01,  ...,  4.3462e-01,\n",
            "          -1.6859e+00,  1.0044e+00],\n",
            "         [ 1.0045e+00,  3.8876e+00, -3.5579e-01,  ...,  2.9507e-01,\n",
            "           2.1522e-01, -2.1268e-01],\n",
            "         [ 7.6783e-01, -1.1006e-01, -2.2304e-01,  ...,  3.2791e-01,\n",
            "           3.1579e-01, -4.7116e-01]],\n",
            "\n",
            "        [[ 1.0927e+00, -1.1613e+00, -3.0279e-01,  ...,  9.7078e-02,\n",
            "          -3.9688e-01,  4.7178e-01],\n",
            "         [ 1.1981e+00, -1.1688e+00, -4.6513e-01,  ..., -7.2701e-01,\n",
            "          -1.1385e+00,  9.9821e-01],\n",
            "         [ 5.9210e-01, -1.0570e+00,  3.2271e-02,  ...,  3.1380e-01,\n",
            "           1.1976e+00, -9.7631e-01],\n",
            "         ...,\n",
            "         [-1.4038e+00, -1.0566e+00, -1.3794e-01,  ..., -1.7105e+00,\n",
            "          -1.0874e+00, -1.5050e-01],\n",
            "         [ 2.1120e+00,  1.0673e+00, -1.0083e+00,  ...,  2.2924e-01,\n",
            "           1.3644e+00, -4.7259e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.0923e-01, -1.0082e+00, -8.2644e-01,  ...,  6.3462e-01,\n",
            "          -1.5135e+00, -7.5331e-01],\n",
            "         [-4.6720e-01, -9.1476e-01,  2.1816e+00,  ...,  1.5576e+00,\n",
            "          -6.5105e-01, -2.2725e-01],\n",
            "         [-1.0880e+00,  5.3164e-01, -5.8157e-01,  ..., -1.9775e+00,\n",
            "          -5.9515e-01, -4.9557e-01],\n",
            "         ...,\n",
            "         [-5.0260e-01, -7.4068e-01,  3.1095e-01,  ...,  2.7136e-01,\n",
            "          -7.3833e-01,  2.2537e+00],\n",
            "         [-1.0407e-03, -1.2642e+00,  8.1672e-01,  ...,  2.3681e+00,\n",
            "          -8.9181e-01,  6.7308e-01],\n",
            "         [ 9.7402e-01, -1.7277e-01,  6.2254e-02,  ...,  3.5662e-01,\n",
            "          -1.2104e+00,  6.1857e-01]],\n",
            "\n",
            "        [[ 2.2883e+00, -1.4861e+00,  8.3126e-01,  ..., -2.3136e+00,\n",
            "          -6.3073e-01, -4.3163e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         ...,\n",
            "         [ 3.0739e-01, -5.4441e-01, -2.5717e-01,  ...,  3.7321e-01,\n",
            "           1.0061e+00,  1.2564e-02],\n",
            "         [-4.0268e-01, -1.1385e+00, -5.8852e-01,  ...,  4.0397e-01,\n",
            "          -1.3216e+00,  7.6281e-01],\n",
            "         [ 9.7402e-01, -1.7277e-01,  6.2254e-02,  ...,  3.5662e-01,\n",
            "          -1.2104e+00,  6.1857e-01]],\n",
            "\n",
            "        [[-1.8442e-01,  3.0398e-01, -1.2384e-01,  ...,  6.2062e-01,\n",
            "           1.9251e+00,  6.2403e-01],\n",
            "         [-2.1421e-01, -1.3219e+00, -9.2078e-01,  ..., -7.0352e-01,\n",
            "          -8.7424e-01, -2.0800e+00],\n",
            "         [-1.2124e-01, -3.0303e+00,  1.8840e+00,  ...,  4.5246e-01,\n",
            "           1.8281e-01, -1.1669e+00],\n",
            "         ...,\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-2.7472e-01, -7.7061e-02, -1.2862e-01,  ...,  1.0022e+00,\n",
            "           1.7103e+00,  6.7628e-01],\n",
            "         [ 1.2043e+00,  5.4826e-01, -1.2414e+00,  ...,  9.9272e-01,\n",
            "           5.1873e-01, -5.7290e-02]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[   40, 27846,   706,   683,    11,  7425,   416,   465,   938,  1573],\n",
            "        [40642,   972,  6654,   832,   616,  5975,    11,   329,   339,  9373],\n",
            "        [  661,   508, 40987,  1637,   508,   651,   749,   503,   286,   340],\n",
            "        [   13,   632,  1244,   307,   326,   339,   550,  6405,   607,   438],\n",
            "        [  286,  1242,   290, 13064,    13,  1675,   262,  6846,    11,   314],\n",
            "        [   40,   367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138],\n",
            "        [ 3666, 13674,    11,  1201,   314,  1053,   442, 17758, 12036,   661],\n",
            "        [   38,   271, 10899,    82,     1,  1816,   510,    13,   198,   198]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [ 0.7412, -1.4065, -1.2917,  ..., -1.5429, -0.1806,  1.1448],\n",
            "         [-0.7781,  0.2370, -0.9810,  ...,  0.5340,  0.3601,  0.8367],\n",
            "         ...,\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [-0.9960,  0.7669, -0.0186,  ...,  0.5013,  2.1483, -0.0287],\n",
            "         [-0.3683,  0.7111,  0.6609,  ..., -0.0249,  0.4604, -1.1605]],\n",
            "\n",
            "        [[ 0.4836,  0.1534,  0.9267,  ..., -1.7824, -1.4801, -2.1585],\n",
            "         [ 1.2334,  0.5970,  1.2918,  ..., -1.9828,  0.9198,  2.1155],\n",
            "         [ 0.4171, -0.3463, -0.2797,  ..., -0.4074, -0.2664,  0.2478],\n",
            "         ...,\n",
            "         [ 0.9922,  1.1803, -0.9523,  ...,  1.1973,  0.0708,  0.3740],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.6713,  0.2651,  0.3073,  ...,  0.6473, -0.3860, -1.4894]],\n",
            "\n",
            "        [[-0.4027, -1.1385, -0.5885,  ...,  0.4040, -1.3216,  0.7628],\n",
            "         [-0.5768,  1.4488,  0.2243,  ..., -0.1859, -0.6737,  1.0192],\n",
            "         [ 0.2420, -0.5692,  0.0675,  ..., -1.6051,  1.0022,  2.2186],\n",
            "         ...,\n",
            "         [-1.5821,  0.8331, -1.0998,  ...,  0.3167,  0.5193, -0.7538],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [ 0.1307,  1.0502,  0.6412,  ..., -0.7290,  0.1103, -0.4152],\n",
            "         [-0.4038, -0.8782,  1.1117,  ..., -1.3638,  0.3295, -0.4456],\n",
            "         ...,\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932],\n",
            "         [ 1.1719, -1.1535, -0.8172,  ...,  0.6310,  0.1205,  1.0727],\n",
            "         [ 1.0796,  0.5387, -0.5124,  ...,  3.0793, -0.7899, -0.8292]],\n",
            "\n",
            "        [[-0.2218,  0.5649,  1.0136,  ...,  1.1260,  0.4969, -0.4946],\n",
            "         [-0.4204,  0.7502,  0.1324,  ..., -0.7546, -1.3105, -2.5873],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [-1.2443, -1.0001,  1.3434,  ...,  0.3107,  1.2247,  0.7603],\n",
            "         [-0.2122,  0.2130,  0.6530,  ...,  0.0757,  0.1124, -1.2027],\n",
            "         [-0.4027, -1.1385, -0.5885,  ...,  0.4040, -1.3216,  0.7628]],\n",
            "\n",
            "        [[-0.7334,  0.7376,  1.7544,  ..., -0.0256,  1.0649, -0.4616],\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932],\n",
            "         [ 1.1719, -1.1535, -0.8172,  ...,  0.6310,  0.1205,  1.0727],\n",
            "         ...,\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 1615,  3364,   739,  2092,   256,  7657,   438,  9776,   340,   262],\n",
            "        [19242,   339,   442, 17758,   465,  5986,  1165,    30,   314,  4398],\n",
            "        [  339,   338,   407,  2045,   553,   673,   531,    11,   351,   257],\n",
            "        [ 1021,   319,   884,   257,   705, 32796,  2637,  3244,   465,  6283],\n",
            "        [   11,   290,   339,  4808,  9776,    62,  1364,  2157,   438, 13893],\n",
            "        [  438,   392,   326, 11542,   373,  1813,   502,    13,   887,    11],\n",
            "        [27339,   284,   262, 21296,    13,  1375,  2227,   683, 29178,  3474],\n",
            "        [  898,  1650,  1010,    13,   198,   198,     1,  6423,   314,   373]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.0089,  0.8364, -0.3736,  ...,  0.4259,  2.1327,  0.3330],\n",
            "         [-1.7414, -0.7749, -0.9823,  ...,  1.7979, -1.8102, -0.1926],\n",
            "         [-1.2379, -1.0293,  0.7280,  ...,  0.0620, -1.6237, -0.0263],\n",
            "         ...,\n",
            "         [ 1.2210,  0.9798,  1.1341,  ..., -0.3086, -0.6145,  0.7419],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[ 1.7473,  0.3275,  1.1423,  ..., -0.9579,  0.0839, -1.7243],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [-0.5832, -0.7594, -0.6373,  ..., -1.1156,  0.3075,  0.5766],\n",
            "         ...,\n",
            "         [ 0.9895, -0.3105,  1.0758,  ...,  0.5757, -1.7812,  1.7524],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 0.6113,  0.7427,  1.1528,  ..., -0.0836, -1.3445,  0.3227]],\n",
            "\n",
            "        [[-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947],\n",
            "         [ 1.8880,  0.6421,  0.7259,  ...,  0.3924,  0.9928,  0.5289],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 1.0818, -0.0166, -0.1110,  ..., -0.8440, -0.8880,  0.6695],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         ...,\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-0.7191,  1.5499, -0.3703,  ..., -1.3717, -0.9244, -1.5860],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[-1.1036,  0.7373,  1.4951,  ..., -1.1710, -0.1850, -0.1686],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [ 0.9994,  1.4933,  0.1504,  ...,  0.8027, -0.4997, -0.7806],\n",
            "         [ 2.3992,  0.5390, -0.0692,  ..., -0.3825,  0.9197,  0.5638],\n",
            "         [ 0.3219,  1.5584,  0.5403,  ...,  0.9504, -0.5137, -1.0467]],\n",
            "\n",
            "        [[-1.2603,  0.2078,  0.6411,  ..., -0.3257,  0.6318, -0.9779],\n",
            "         [ 0.2826, -0.4646, -0.7355,  ...,  0.3864,  0.5140,  0.2913],\n",
            "         [-0.5750,  0.3596, -0.4075,  ..., -1.5981,  1.7641,  0.4230],\n",
            "         ...,\n",
            "         [ 0.4604, -0.1027, -0.0537,  ..., -0.9904, -0.7147,  0.0392],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 1.1599, -0.5407, -0.8304,  ...,  0.1135, -1.2435,  1.4415]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[19672,   484,   550,   262,  1295,   286, 15393,   438, 16706,   262],\n",
            "        [  262,  3716,  7106,  6637,   286,   262, 45172,   338,  5928,  3773],\n",
            "        [ 2250,    11,   290,   339,  3724,  6451,    11,   286,  2612,  4369],\n",
            "        [ 3888,  7263,   257,  4808,    73,   446,   259, 13235,    62,  1336],\n",
            "        [ 2763,  1043,   502,   503,   890,  2084,   553,   339,   531, 15376],\n",
            "        [ 2469,   265,  1572,   351,   257,   922,    12, 17047,  8167, 32545],\n",
            "        [   40,  2900,   736,   284,   616,   670,    11,   290,  1816,   319],\n",
            "        [ 7521,   597,   517,  1701,   314,  1965,    11,   991,  2045,   546]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.9469, -1.3766,  1.0046,  ...,  0.5227,  1.6040, -0.4891],\n",
            "         [ 0.4209, -0.2613, -0.9257,  ..., -1.0392, -0.7258,  0.0094],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         ...,\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-1.6974,  0.1453, -0.6478,  ..., -0.8103, -1.0758,  1.1848],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.5844,  0.2372,  0.9767,  ..., -1.2091, -0.5514,  0.6052],\n",
            "         [ 1.7014,  1.0642,  0.6274,  ...,  1.8360, -0.2661,  1.3913],\n",
            "         ...,\n",
            "         [ 0.4594, -0.5580, -0.7102,  ..., -0.8592,  0.1542, -0.4947],\n",
            "         [-0.5401,  0.2689,  0.1965,  ..., -0.8574,  0.8662,  0.7146],\n",
            "         [-1.2740, -0.5941,  2.3137,  ..., -2.1197,  0.7443,  0.0205]],\n",
            "\n",
            "        [[-0.6722, -2.2913,  1.3227,  ..., -0.4255,  0.6075,  0.8313],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.8074, -0.7364,  1.3253,  ...,  0.9710, -1.2545,  0.1034],\n",
            "         [-1.3986,  0.2255, -0.7350,  ...,  0.4102,  1.2656,  1.3706]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.7038,  0.3921, -0.6524,  ...,  0.3405, -0.4105, -1.0250],\n",
            "         [ 0.8009, -1.5570,  1.0438,  ..., -0.1147, -2.4772, -0.0108],\n",
            "         [-0.1166,  0.2356, -0.9064,  ...,  1.4931,  0.8769, -0.8940],\n",
            "         ...,\n",
            "         [-0.0328, -1.3092,  0.7142,  ..., -1.2354,  0.6776, -0.6899],\n",
            "         [-1.3656, -0.3711,  1.0401,  ..., -0.4499,  0.0138,  1.8886],\n",
            "         [-0.4124, -0.2777, -0.0028,  ...,  1.8240,  0.8640,  0.2715]],\n",
            "\n",
            "        [[ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [-0.5769,  0.2599, -0.6822,  ..., -0.6519,  0.0247,  0.1310],\n",
            "         [ 1.2641, -0.2539, -1.1079,  ..., -1.1639, -0.7542,  1.3690],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 0.3797,  0.4861,  1.1970,  ..., -2.1601,  1.4799,  1.4849],\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691]],\n",
            "\n",
            "        [[ 1.3837, -0.7146, -1.2462,  ...,  0.1798,  0.1274, -1.1049],\n",
            "         [ 0.2496,  0.3955,  0.0805,  ..., -0.6985, -0.3505, -0.0510],\n",
            "         [-0.8319, -1.0101,  1.3246,  ..., -0.5300,  1.5858,  0.1537],\n",
            "         ...,\n",
            "         [-0.6681,  1.2456,  0.8299,  ..., -1.7945,  1.5532,  0.7493],\n",
            "         [ 0.1264, -1.3830, -0.8750,  ...,  0.4769,  2.3809,  0.3756],\n",
            "         [ 0.1116, -0.2741,  0.2720,  ...,  0.2087, -1.9009,  1.2337]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  286, 14081,  2415,   284,   307, 13055,   366, 11576,   306,     1],\n",
            "        [  887,   314,  4137,  3589,   284,  1234,   340,   994,    26,   290],\n",
            "        [11564,   284,  1657,    13, 24975,   339,  2900,  3812,   502,    13],\n",
            "        [ 3830,   612, 12703,  4964,    11,   290,   319,   465, 11914,    11],\n",
            "        [  286, 24380,   329, 20728,   287,   257,  4286, 10273,   438, 29370],\n",
            "        [  465,  1021,   319,   616,  8163,   351,   257,  6487,    13,   366],\n",
            "        [ 1718,   262,  1657,   832, 41160,   286,  1468,  9932,   316,   666],\n",
            "        [  502,    11,   290,   284,  3285,   683,   910,    25,   705,  1026]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.7433, -0.2709, -0.3275,  ...,  1.3432,  0.1576,  0.3337],\n",
            "         [-0.5804,  0.1116, -0.1618,  ..., -1.3464,  0.7731, -1.3799],\n",
            "         ...,\n",
            "         [-1.3596,  1.5118, -1.2019,  ..., -2.0397, -1.7812, -1.1054],\n",
            "         [ 1.3713,  0.5671,  1.6299,  ...,  0.9140, -1.0583, -0.0210],\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122]],\n",
            "\n",
            "        [[-0.7191,  1.5499, -0.3703,  ..., -1.3717, -0.9244, -1.5860],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 1.1937,  0.5222, -1.5755,  ..., -1.6030,  0.6489, -0.8480],\n",
            "         ...,\n",
            "         [-1.4115,  1.5391, -0.6777,  ...,  0.0700, -0.0109,  0.6465],\n",
            "         [ 0.5921, -1.0570,  0.0323,  ...,  0.3138,  1.1976, -0.9763],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159]],\n",
            "\n",
            "        [[-0.0098, -0.6384,  0.2338,  ...,  0.0029, -0.0138,  0.4707],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [ 2.2125, -0.3721,  0.3907,  ...,  1.0500,  0.6031, -0.9406],\n",
            "         ...,\n",
            "         [ 0.5080, -1.3109,  1.1290,  ..., -0.7253,  0.0435, -2.0041],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [-0.3030,  0.3971,  0.4488,  ..., -0.0742, -0.2091,  0.3043],\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691],\n",
            "         ...,\n",
            "         [-0.3584, -1.4564, -1.1587,  ...,  1.1384,  2.0840,  0.3909],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-0.4672, -0.9148,  2.1816,  ...,  1.5576, -0.6511, -0.2273]],\n",
            "\n",
            "        [[-0.6728,  1.0539,  0.7958,  ..., -0.1083, -0.4771,  1.0437],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 2.2125, -0.3721,  0.3907,  ...,  1.0500,  0.6031, -0.9406],\n",
            "         ...,\n",
            "         [-1.3400, -0.9882, -0.5443,  ...,  1.3605, -0.0239,  0.6669],\n",
            "         [ 0.1320,  0.0255,  0.0419,  ..., -0.7917,  0.8306, -0.2174],\n",
            "         [-0.9211,  0.4273, -0.2033,  ..., -0.0967, -0.0726, -0.2251]],\n",
            "\n",
            "        [[ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [ 0.6064,  0.5206,  0.7622,  ..., -0.4967, -0.5741,  0.3031],\n",
            "         [ 0.3843,  0.3194, -0.1653,  ..., -0.8107, -1.4684,  0.8078]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  510,   616, 20348,    11,   290,  1816,   866,   290,  1297,  9074],\n",
            "        [  262,  3084,   290,   336,  8375,   503,  4291,   262,  4252, 18250],\n",
            "        [  284,   910,   644,   339,  1807,   326,  1110,   526,   198,   198],\n",
            "        [ 1701,   198,   198,  1544,  9373,  6364,    25,   366, 27034,    13],\n",
            "        [16337,  1497,    11,   290,   531,    25,   366,  1532,   345,  1302],\n",
            "        [  198,   198,  1544,  6204,  2045,   510,   379,   262, 17548,    11],\n",
            "        [  290,  7342,   502,    11,   262,  1517,   484,  1444,   616,   705],\n",
            "        [  262,  1109,   326,    11,   319,  1401,    77,  3929,  1528,    11]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         [-0.2648,  0.0619, -0.1806,  ...,  1.1104, -0.1095,  0.0154],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 0.2140,  0.1935,  1.0648,  ...,  2.1137,  3.4164,  0.3580],\n",
            "         [-1.7958, -0.2559, -0.0259,  ..., -0.3978,  0.0792, -0.6153]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-1.4900,  0.9736,  0.0299,  ...,  0.4243,  0.8197,  0.6663],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-1.0714,  0.9725, -0.7295,  ..., -0.2154, -0.5633,  1.8171],\n",
            "         [ 0.7847,  2.0323,  0.9131,  ..., -1.6691,  0.3853,  0.8539]],\n",
            "\n",
            "        [[-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [ 0.6074,  1.0642,  0.0900,  ...,  0.4162, -1.2428, -1.2814],\n",
            "         [-0.2886, -0.8704,  0.6625,  ..., -1.6532,  0.8268, -1.4911],\n",
            "         ...,\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-0.2523,  0.4677,  0.1485,  ..., -0.2896,  0.4759, -1.5621],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.9300, -0.5039,  1.0458,  ..., -1.6253,  0.6252,  2.1388],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [-0.6335, -3.1774, -0.9004,  ..., -1.1514, -0.2385,  0.1854],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         ...,\n",
            "         [ 0.6213,  0.0406,  1.0963,  ...,  0.5433, -0.5501, -0.9227],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         [ 0.6064,  0.5206,  0.7622,  ..., -0.4967, -0.5741,  0.3031]],\n",
            "\n",
            "        [[-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.5677, -0.3773, -0.8361,  ..., -0.2578,  1.7016,  0.1218],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         ...,\n",
            "         [ 1.6424, -1.3608,  2.3127,  ..., -0.5428, -2.8522,  1.8336],\n",
            "         [-0.7167, -0.3862,  0.5817,  ..., -0.1092,  0.3406,  1.4194],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  670,    11,   290,  1816,   319, 39136,   278,   290,   285,  4185],\n",
            "        [   40,   588,   284, 14996,   326,   520,  5493,  2241,   561,   423],\n",
            "        [ 1182,    11,   290, 47425,   278,   465,  5101, 11061,   340,    11],\n",
            "        [   11,   991, 16755,    13,   198,   198,     1,  5812,    11,  8759],\n",
            "        [   11,   262, 15910,   286, 16153,   312,   328,  3780,   416,   543],\n",
            "        [ 5963,    11,   290,   314,   550,   691,   284,   900,   510,   262],\n",
            "        [  673,   550,  8603,    11,   355,  4544,  9325,   701, 42397,    11],\n",
            "        [  465, 14475,    13,   198,   198,     1,  5779,    11,  1282,   981]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.1329, -0.2949,  1.4879,  ...,  0.8537, -0.2309, -0.9426],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         [ 0.4557, -2.0750, -0.0573,  ...,  1.4250, -0.0342,  1.1262],\n",
            "         [-0.1698,  0.1336, -2.3464,  ..., -0.4575, -0.3715, -0.5952]],\n",
            "\n",
            "        [[ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [-0.9736, -0.7071, -0.9007,  ...,  2.8945,  0.1100, -1.5532],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         ...,\n",
            "         [-1.4038, -1.0566, -0.1379,  ..., -1.7105, -1.0874, -0.1505],\n",
            "         [-2.2530,  0.7858, -1.5418,  ...,  0.3413, -0.3559,  0.4938],\n",
            "         [ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083]],\n",
            "\n",
            "        [[-1.6710, -0.1052, -0.1112,  ...,  0.0448,  0.3768, -0.0370],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [ 0.0289, -0.1392,  1.5403,  ..., -0.2919, -0.9387,  1.4589],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.0387,  0.3777,  1.0040,  ..., -0.8426, -1.5160,  0.1574],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-1.1610, -0.3399,  0.6493,  ..., -0.1103,  0.4803, -1.4159],\n",
            "         ...,\n",
            "         [-1.2038, -1.1570,  0.5143,  ..., -1.0287, -1.1155, -0.8511],\n",
            "         [ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307]],\n",
            "\n",
            "        [[ 0.1583,  0.0856, -1.6712,  ..., -1.3325, -0.4703, -0.9782],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-0.4232,  0.0967, -0.5213,  ...,  1.5514,  2.0364, -0.0426],\n",
            "         ...,\n",
            "         [ 0.7363, -0.5189, -0.6556,  ...,  0.3181,  0.5015,  0.0476],\n",
            "         [ 0.7024, -1.1160,  0.4916,  ..., -0.7087,  0.8593,  1.8732],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 0.5932, -0.5860,  0.7225,  ..., -0.9350,  1.3455, -0.1251],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 2.5432, -0.1697,  0.6637,  ..., -0.4082, -1.9256,  0.4849],\n",
            "         [ 0.3161, -0.0687,  1.6979,  ...,  1.8996,  0.0202, -0.2006]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  717, 14000,    11,   339,  2993,   655,   644,   262,   886,   561],\n",
            "        [   25,  9675,   284,   423,   616,  1021,   319,   884,   257,   705],\n",
            "        [ 1808,    25,   705,  8491,   345,  1654,   345,   760,   810,   345],\n",
            "        [ 9325,   701,     8,   373,  1719,   319,   683,    13,   198,   198],\n",
            "        [  373,   257, 17548,   286,   257, 50085,   438,   272,  1468, 10032],\n",
            "        [12239,    13,   198,   198,     1,    40,   588,   284, 14996,   326],\n",
            "        [  351,   262,  1459,   714,  1239,   423,  4499,   326, 18680,   510],\n",
            "        [  780,   339,  6572,   340,   526,   198,   198,     1, 49174,   276]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.6313,  0.3005,  1.7098,  ..., -0.4809,  0.4106,  0.9097],\n",
            "         [ 0.9360, -1.5745,  0.1299,  ...,  0.0998,  1.2441,  0.1171],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.4003, -1.0779,  0.9404,  ..., -0.5071,  1.7688,  1.1111],\n",
            "         [-2.2530,  0.7858, -1.5418,  ...,  0.3413, -0.3559,  0.4938]],\n",
            "\n",
            "        [[-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [ 1.0340, -0.3313,  1.3499,  ..., -0.5154, -0.1073, -0.5112],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         ...,\n",
            "         [ 0.2632,  0.7728,  0.9803,  ..., -1.3675, -0.2758,  1.1261],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [ 0.6064,  0.5206,  0.7622,  ..., -0.4967, -0.5741,  0.3031]],\n",
            "\n",
            "        [[ 0.3517,  0.1046,  0.6817,  ...,  1.0936, -1.5083, -0.0761],\n",
            "         [-0.1092, -1.0082, -0.8264,  ...,  0.6346, -1.5135, -0.7533],\n",
            "         [ 0.6064,  0.5206,  0.7622,  ..., -0.4967, -0.5741,  0.3031],\n",
            "         ...,\n",
            "         [-1.5400,  0.4149,  1.1748,  ...,  0.5854, -1.7530, -1.5975],\n",
            "         [-1.0453,  1.7011, -0.8623,  ...,  1.2479, -0.0131, -1.8740],\n",
            "         [ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.5861,  0.2201, -0.1110,  ..., -0.8595, -1.8356,  1.3523],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.8029, -0.4898,  1.1223,  ...,  0.0806, -0.4177,  0.7964],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895]],\n",
            "\n",
            "        [[-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.4941,  0.2584, -1.5210,  ...,  0.4730, -0.0790,  1.5319],\n",
            "         ...,\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         [-0.1978, -0.3288,  1.8765,  ...,  0.8230, -0.1723,  0.0339],\n",
            "         [ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628]],\n",
            "\n",
            "        [[-0.1613,  1.2849, -0.7412,  ...,  0.6751, -1.1402,  0.7706],\n",
            "         [-0.3545, -0.2300, -0.2078,  ..., -0.1557,  0.1112,  2.2748],\n",
            "         [ 0.6209,  0.8307,  0.1653,  ..., -1.7517, -0.0668, -1.5959],\n",
            "         ...,\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [ 0.3670, -1.7704,  0.0215,  ..., -0.4949, -0.9207,  0.0129],\n",
            "         [-0.4460,  0.8671,  0.3254,  ...,  0.6196,  0.2657, -0.7750]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  438,  3826,  3892,   284,   262,  2006, 20212, 19369, 14638,    13],\n",
            "        [  312,   328,  3780,   416,   543,    11,   351,   884,  2784,  9830],\n",
            "        [  273,  1807,   673,   750,    13,   887,   673,  3521,   470,  6842],\n",
            "        [  438,  1820, 18560,   438,   392,   326,   314,   423,   284,  1394],\n",
            "        [  286,  3703,    13,  9074,    13,   402,   271, 10899,    11, 17728],\n",
            "        [  286,   262, 33125,    12,   565,   593,   338, 25304,  4040,   284],\n",
            "        [  438,   392,   416,   502,  2474,   198,   198,  1544, 13818,   757],\n",
            "        [40123, 18113,   544,  9325,   701,    11,   379,   262,   938,   402]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-1.0706, -0.5278, -1.4224,  ..., -1.3784,  0.8513, -0.3452],\n",
            "         [-0.6530,  0.5243,  0.3125,  ...,  0.5007,  0.9330,  1.5722],\n",
            "         ...,\n",
            "         [-1.0680, -1.8742,  1.1907,  ..., -0.0348,  1.2813,  0.6507],\n",
            "         [ 2.0010,  0.0109, -0.0836,  ..., -0.9758,  1.3942,  0.5690],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[ 0.3723, -0.9264, -0.1156,  ..., -0.0254, -0.3349, -0.1218],\n",
            "         [-0.6307,  0.9134, -1.2656,  ..., -0.9989, -1.6028, -0.5046],\n",
            "         [ 0.3992, -1.9110, -0.5462,  ..., -0.6913, -0.7342,  0.3400],\n",
            "         ...,\n",
            "         [ 0.2632,  0.7728,  0.9803,  ..., -1.3675, -0.2758,  1.1261],\n",
            "         [-0.2546,  0.7596, -0.1010,  ..., -1.5709, -0.5525,  1.1286],\n",
            "         [-1.1887, -0.6557,  0.9274,  ..., -0.4982, -0.7102,  0.8247]],\n",
            "\n",
            "        [[-0.4619,  0.6085,  0.5810,  ..., -0.1674, -0.2398, -0.2442],\n",
            "         [ 0.6083, -0.8358,  0.8137,  ...,  1.3855, -0.2252, -2.8407],\n",
            "         [ 0.1583,  0.0856, -1.6712,  ..., -1.3325, -0.4703, -0.9782],\n",
            "         ...,\n",
            "         [-0.5430, -0.9748, -0.5825,  ..., -0.2468, -0.0488,  0.4508],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [ 0.4451, -0.5404,  0.5278,  ...,  0.1397,  0.7446,  0.7623]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.2254,  0.6082,  0.3873,  ...,  0.5001, -0.4799,  0.6621],\n",
            "         ...,\n",
            "         [ 1.0153,  1.7833, -0.3308,  ...,  0.3673, -0.0388, -0.1314],\n",
            "         [-0.6216, -0.5406, -0.5794,  ...,  0.9553, -0.8296, -1.4217],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 1.0818, -0.0166, -0.1110,  ..., -0.8440, -0.8880,  0.6695],\n",
            "         [ 0.5290,  1.2444, -1.8292,  ...,  0.2727, -1.6876,  0.5176],\n",
            "         ...,\n",
            "         [-0.2523,  0.4677,  0.1485,  ..., -0.2896,  0.4759, -1.5621],\n",
            "         [-0.2160,  0.2843, -1.2530,  ...,  1.5848, -1.1659, -0.9161],\n",
            "         [-0.3382, -0.5948,  0.2674,  ...,  2.3675, -0.6613, -0.2827]],\n",
            "\n",
            "        [[-0.2997,  0.0442,  0.3554,  ...,  0.5001,  1.5735,  0.6318],\n",
            "         [-0.6120, -0.2123,  1.5207,  ..., -0.6893, -1.1084,  0.6856],\n",
            "         [-0.1851,  0.2034,  1.7849,  ...,  0.8796, -0.6442,  1.4131],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.9960,  0.7669, -0.0186,  ...,  0.5013,  2.1483, -0.0287],\n",
            "         [ 0.1605,  0.5546, -1.5836,  ..., -0.6178,  0.3921,  0.3794]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  531,    13,   198,   198,  1026,   373,   257, 17548,   286,   257],\n",
            "        [ 1549,  1560,   502,   703,   340,  3022,   553,   314,   531,    13],\n",
            "        [  287,   790,  1627,    13,   317,   582,   508,   550,  1509,   388],\n",
            "        [ 8166,   438, 14363,  1986,   373,  1598,   290, 36519,    13,   314],\n",
            "        [  271, 10899,   338,  1280,   954, 36368,    13,   366,  1026,   338],\n",
            "        [ 3973,  9899, 14678, 40556,    12, 11487,    11,   618,    11,   319],\n",
            "        [28582,    13, 18612, 35394,    30,  8673,    13,  1002,   340,   547],\n",
            "        [  198,   464,  1109,  3181,  1363,   284,   502,   262,  4112,   957]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 1.1944,  1.4784, -0.9098,  ..., -0.9145, -0.3798,  2.2964],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [-0.9300, -0.5039,  1.0458,  ..., -1.6253,  0.6252,  2.1388],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310]],\n",
            "\n",
            "        [[ 0.7829,  0.2202,  2.9774,  ..., -0.6214,  0.2283, -0.2155],\n",
            "         [ 1.3104,  0.3089, -1.2618,  ..., -1.3819, -1.8186, -0.8563],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         ...,\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888],\n",
            "         [ 1.1944,  1.4784, -0.9098,  ..., -0.9145, -0.3798,  2.2964],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         [ 1.7244, -0.9115, -0.4953,  ...,  1.6060, -0.0101,  0.6287],\n",
            "         [ 1.4400, -0.9946, -1.4995,  ..., -1.9225,  0.6170,  1.7725],\n",
            "         ...,\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [-0.2269, -0.0938, -0.3420,  ...,  0.0062, -0.1993, -0.3487],\n",
            "         [ 0.1498, -1.1682, -1.1352,  ...,  0.8368,  1.0190, -0.8247]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0158, -1.4719,  0.9562,  ..., -1.9689, -0.8810, -1.5892],\n",
            "         [ 0.5619,  0.0749,  0.3019,  ..., -0.9806, -0.2475,  0.6883],\n",
            "         [-0.8784,  0.1369, -0.9499,  ...,  0.0232,  0.6859,  2.5054],\n",
            "         ...,\n",
            "         [ 0.5868,  1.3891, -1.6561,  ...,  0.7081,  1.3799, -0.5942],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.4583, -1.6412, -0.5188,  ...,  1.0188,  0.1627,  1.2691]],\n",
            "\n",
            "        [[-0.3842,  0.1598, -1.4104,  ..., -0.7476, -0.6639,  1.4299],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.3324,  0.3777, -0.6000,  ..., -0.3425, -0.2760, -2.1439],\n",
            "         ...,\n",
            "         [-0.8106, -1.6942,  2.4801,  ..., -1.4467, -0.5545, -1.2258],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [ 0.8212,  0.3809, -0.7229,  ..., -0.5552, -0.2895, -2.3285]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-0.9954, -0.2646,  1.0402,  ...,  0.0893,  0.9426,  2.1905],\n",
            "         [ 0.5677, -0.3773, -0.8361,  ..., -0.2578,  1.7016,  0.1218],\n",
            "         ...,\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.3695,  0.8507, -0.9958,  ...,  0.3426, -0.1512, -1.2583],\n",
            "         [-0.0216,  0.0928, -0.4223,  ..., -0.3118,  0.7898,  1.3667]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[32796,  2637,  3244,   465,  6283,  1204,    12, 46965,  9449,  2540],\n",
            "        [  312,   410, 12523,    13,   632,   373,  6616,   290,  7586,   290],\n",
            "        [   62,   339,   442, 17758, 12036,  1701,   314,  1965, 25891,    13],\n",
            "        [  198,     1,  1532,   314,   714,   423, 13055,   326,  1986,    11],\n",
            "        [  438,    40,   655,  9617,  7521,   656,   511,  6698,    13,   764],\n",
            "        [  351,   257,  6487,    13,   366, 10049,   262, 21296,   286,   340],\n",
            "        [  760,    13,   679,  1139,   484,   821,   407,  4197,   284,   423],\n",
            "        [ 1592,  2259,   739,   438, 14363,   898,  9408,   355,   281,  2134]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.3585e-01,  9.9408e-03,  8.7433e-01,  ..., -1.4885e+00,\n",
            "          -1.0246e+00, -1.5149e+00],\n",
            "         [-1.3907e+00,  9.7328e-02,  1.6298e+00,  ...,  5.2665e-01,\n",
            "           1.4896e+00, -1.2956e+00],\n",
            "         [ 2.0278e+00,  2.5485e-01, -1.4004e+00,  ..., -2.0151e-01,\n",
            "          -8.4211e-01, -3.4045e-01],\n",
            "         ...,\n",
            "         [-2.6315e-03,  2.6525e-01,  1.3921e+00,  ...,  5.3657e-01,\n",
            "          -1.9609e+00, -2.1821e+00],\n",
            "         [-4.4374e-01, -1.5452e+00, -1.9995e+00,  ..., -1.5349e-01,\n",
            "           4.2868e-01, -2.8131e-01],\n",
            "         [ 9.7251e-01, -6.5124e-01,  7.6889e-02,  ...,  1.8158e-01,\n",
            "          -7.0457e-02, -1.6534e-01]],\n",
            "\n",
            "        [[ 3.7227e-01, -9.2640e-01, -1.1557e-01,  ..., -2.5353e-02,\n",
            "          -3.3488e-01, -1.2184e-01],\n",
            "         [ 4.2885e-01, -7.2179e-01, -1.8211e-01,  ...,  1.6560e+00,\n",
            "           5.0371e-01, -1.0278e+00],\n",
            "         [-1.4972e+00, -1.0862e+00, -8.0470e-01,  ..., -8.0295e-01,\n",
            "           5.2591e-01, -1.2850e-01],\n",
            "         ...,\n",
            "         [-1.1610e+00, -3.3992e-01,  6.4933e-01,  ..., -1.1030e-01,\n",
            "           4.8025e-01, -1.4159e+00],\n",
            "         [ 2.7788e-01, -6.2066e-02, -9.6581e-01,  ..., -3.5778e-01,\n",
            "           7.6733e-01, -2.2927e-01],\n",
            "         [-1.1610e+00, -3.3992e-01,  6.4933e-01,  ..., -1.1030e-01,\n",
            "           4.8025e-01, -1.4159e+00]],\n",
            "\n",
            "        [[-8.4558e-01, -1.2353e+00, -3.8301e-01,  ...,  8.4102e-01,\n",
            "          -1.3609e+00, -3.3840e-01],\n",
            "         [-3.5449e-01, -2.3002e-01, -2.0778e-01,  ..., -1.5570e-01,\n",
            "           1.1122e-01,  2.2748e+00],\n",
            "         [-5.8324e-01, -7.5937e-01, -6.3726e-01,  ..., -1.1156e+00,\n",
            "           3.0746e-01,  5.7655e-01],\n",
            "         ...,\n",
            "         [ 5.3656e-01,  1.9892e+00,  4.7741e-01,  ...,  1.7064e-01,\n",
            "          -3.6089e-01, -4.0458e-02],\n",
            "         [ 6.4779e-01,  7.4449e-01,  4.3145e-01,  ..., -8.4149e-01,\n",
            "           1.0902e-02, -2.0669e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-3.2174e-01, -1.2322e+00, -2.6197e-01,  ..., -2.2384e+00,\n",
            "          -1.3085e+00,  1.6677e+00],\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         [-3.5842e-01, -1.4564e+00, -1.1587e+00,  ...,  1.1384e+00,\n",
            "           2.0840e+00,  3.9087e-01],\n",
            "         ...,\n",
            "         [-1.0792e+00,  1.6657e+00, -2.2147e-01,  ...,  1.5606e+00,\n",
            "          -7.4661e-01,  2.7218e-01],\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01]],\n",
            "\n",
            "        [[-1.5400e+00,  4.1493e-01,  1.1748e+00,  ...,  5.8538e-01,\n",
            "          -1.7530e+00, -1.5975e+00],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 4.4359e-01,  2.9453e-01,  1.0645e+00,  ..., -2.2958e-01,\n",
            "           2.7335e-01,  2.5117e-01],\n",
            "         ...,\n",
            "         [ 1.5385e-01, -1.4362e+00, -1.3575e+00,  ...,  5.5808e-02,\n",
            "           2.1980e+00,  1.6894e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [ 7.8450e-01,  1.3598e+00, -1.1044e+00,  ...,  2.9561e-02,\n",
            "          -3.5540e-02, -3.0833e-01]],\n",
            "\n",
            "        [[-1.3921e+00, -1.6150e-01, -5.3877e-01,  ...,  1.5891e+00,\n",
            "           1.3965e-01,  1.2098e+00],\n",
            "         [-2.3118e-01,  1.0024e+00,  1.6244e+00,  ...,  4.3272e-01,\n",
            "          -1.4229e+00,  2.0385e-01],\n",
            "         [-1.2379e+00, -1.0293e+00,  7.2796e-01,  ...,  6.1979e-02,\n",
            "          -1.6237e+00, -2.6296e-02],\n",
            "         ...,\n",
            "         [-6.8540e-01,  1.3182e+00,  6.5168e-03,  ..., -7.8027e-03,\n",
            "           6.2407e-01,  2.8329e+00],\n",
            "         [ 5.4922e-02, -2.4333e+00, -2.9900e-01,  ...,  2.0638e+00,\n",
            "           1.8694e-01,  3.9260e-01],\n",
            "         [ 1.6465e-02,  7.2629e-01,  4.3299e-01,  ...,  5.2463e-01,\n",
            "          -3.5290e-01, -1.2828e+00]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[43920,  3619,     0,   632,   550,  1464,   587,   465, 10030,   284],\n",
            "        [20136,   546,   616, 15185,  2900,   656,   257,  2726,  6227,   284],\n",
            "        [  553,  9074,    13,   402,   271, 10899,   531,   351, 27322,   540],\n",
            "        [  898, 49451,   553,   339,   531,    11,  3756,   502,   656,   257],\n",
            "        [  340,  1422,   470,  1011,   881,  2392,   284,  1645,    13,   764],\n",
            "        [ 3432,   262,  2938, 17547,   339,   531,    11,  9644,   503,   465],\n",
            "        [  582,   508,   550,  1509,   388,   351,   262,  1459,   714,  1239],\n",
            "        [  994,   345,   460,   655,  6687,   284,   766,   340,    13,   314]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.2196,  1.3847,  0.9810,  ..., -0.2736,  1.7097, -0.8752],\n",
            "         [-0.1420,  1.9369, -1.3475,  ...,  0.7970, -1.7525, -1.5364],\n",
            "         [ 0.5051,  0.2064,  0.9431,  ..., -1.2557,  0.4493, -0.3174],\n",
            "         ...,\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         [ 0.5753,  0.7275,  0.3220,  ...,  0.1220,  0.8378, -2.8034],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[-0.7830,  1.2393,  1.5449,  ...,  0.2355, -0.2432, -0.3384],\n",
            "         [ 0.1116, -0.2741,  0.2720,  ...,  0.2087, -1.9009,  1.2337],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         ...,\n",
            "         [-0.4575,  2.5131,  1.4198,  ...,  1.5596,  0.8023,  1.2324],\n",
            "         [-0.6646, -0.9889, -0.2501,  ..., -0.6666,  1.3032,  0.7239],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]],\n",
            "\n",
            "        [[ 1.3361,  0.6034,  0.8908,  ..., -0.9077,  0.3499, -0.5623],\n",
            "         [-1.7958, -0.2559, -0.0259,  ..., -0.3978,  0.0792, -0.6153],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         ...,\n",
            "         [-0.3217, -1.2322, -0.2620,  ..., -2.2384, -1.3085,  1.6677],\n",
            "         [-0.9556, -1.0173,  0.3942,  ...,  1.6643,  0.2401,  2.7218],\n",
            "         [-0.3352, -0.4004,  0.2277,  ..., -1.9903, -0.9639, -1.1604]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.8551, -0.2343, -0.9996,  ...,  1.7391, -0.1257,  0.7755],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 1.2619, -0.7851,  0.3486,  ..., -1.0604,  0.8337,  1.3079],\n",
            "         ...,\n",
            "         [-1.0168, -1.2880, -0.6921,  ...,  0.7600, -1.0538,  0.0933],\n",
            "         [-1.5821,  0.8331, -1.0998,  ...,  0.3167,  0.5193, -0.7538],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093]],\n",
            "\n",
            "        [[-1.4455, -2.2687,  1.4077,  ..., -0.8479,  0.7084,  0.5810],\n",
            "         [-0.5768,  1.4488,  0.2243,  ..., -0.1859, -0.6737,  1.0192],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         ...,\n",
            "         [-0.4941,  0.2584, -1.5210,  ...,  0.4730, -0.0790,  1.5319],\n",
            "         [ 1.0208,  0.4613, -0.1690,  ...,  1.0675, -1.1652,  0.2891],\n",
            "         [ 0.5474, -0.9886,  2.2438,  ...,  1.9493,  0.3414,  1.4793]],\n",
            "\n",
            "        [[-1.4115,  1.5391, -0.6777,  ...,  0.0700, -0.0109,  0.6465],\n",
            "         [ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222],\n",
            "         [-0.5026, -0.7407,  0.3110,  ...,  0.2714, -0.7383,  2.2537],\n",
            "         ...,\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [ 0.2986,  1.1781, -0.2166,  ...,  0.7523,  1.4686, -1.1888]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  832,   262, 12768, 21213,    11,   314,  3947,   284,  3285,   262],\n",
            "        [  314,   373,   618,   314,  1392,  9074,    13,   520,  5493,   338],\n",
            "        [ 2951,    25,   366,  1135,  2236,   407,   804,  2402,   663,   588],\n",
            "        [  306,  8564,   284,   790,  1296,   286,  8737,   526,   198,   198],\n",
            "        [   11,   772,   611,   339,  1549,   587,  6776,    13,   314, 11856],\n",
            "        [  373,   262,   530,  7090,   883,  2636,  2951,   714,   766,   832],\n",
            "        [  290, 45592,    12, 14792,  5986,   351,   257,  8839,   326,  7284],\n",
            "        [ 1070,   268,  2288,    13,  1867,  7425,   502,   783,   373,   326]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-2.0414e+00,  1.9721e-01,  8.4603e-01,  ...,  8.5928e-01,\n",
            "          -9.8686e-01, -9.8075e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 1.3511e+00, -4.5087e-01, -1.6048e-01,  ..., -9.3145e-01,\n",
            "          -1.9994e-01,  1.3914e+00],\n",
            "         ...,\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [-1.0632e+00,  3.4212e-01, -5.5314e-01,  ...,  6.7416e-01,\n",
            "           1.2355e+00, -8.7935e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01]],\n",
            "\n",
            "        [[ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         [ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [ 5.8679e-01,  1.3891e+00, -1.6561e+00,  ...,  7.0807e-01,\n",
            "           1.3799e+00, -5.9418e-01],\n",
            "         ...,\n",
            "         [-2.1421e-01, -1.3219e+00, -9.2078e-01,  ..., -7.0352e-01,\n",
            "          -8.7424e-01, -2.0800e+00],\n",
            "         [-1.2124e-01, -3.0303e+00,  1.8840e+00,  ...,  4.5246e-01,\n",
            "           1.8281e-01, -1.1669e+00],\n",
            "         [ 4.5941e-01, -5.5795e-01, -7.1025e-01,  ..., -8.5924e-01,\n",
            "           1.5418e-01, -4.9474e-01]],\n",
            "\n",
            "        [[ 1.4609e+00, -1.6441e+00,  6.3180e-01,  ...,  1.6115e+00,\n",
            "          -1.9263e+00, -7.9017e-01],\n",
            "         [-1.0923e-01, -1.0082e+00, -8.2644e-01,  ...,  6.3462e-01,\n",
            "          -1.5135e+00, -7.5331e-01],\n",
            "         [-4.6720e-01, -9.1476e-01,  2.1816e+00,  ...,  1.5576e+00,\n",
            "          -6.5105e-01, -2.2725e-01],\n",
            "         ...,\n",
            "         [-6.0122e-01,  6.0822e-01, -1.4998e+00,  ...,  1.1348e+00,\n",
            "          -7.4151e-01, -2.6126e-02],\n",
            "         [-9.7583e-01,  4.4514e-02, -2.1645e-01,  ...,  1.6064e-01,\n",
            "          -7.6521e-01, -1.8104e+00],\n",
            "         [-9.7364e-01, -7.0711e-01, -9.0073e-01,  ...,  2.8945e+00,\n",
            "           1.1000e-01, -1.5532e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 2.0277e-01, -3.2441e-01,  5.8122e-02,  ...,  1.2838e+00,\n",
            "           1.1483e+00,  1.3023e+00],\n",
            "         ...,\n",
            "         [ 1.0208e+00,  4.6131e-01, -1.6898e-01,  ...,  1.0675e+00,\n",
            "          -1.1652e+00,  2.8913e-01],\n",
            "         [-3.1282e-01, -2.5704e-01,  3.3363e-01,  ..., -4.5781e-01,\n",
            "          -1.1063e+00, -7.1982e-01],\n",
            "         [-2.0414e+00,  1.9721e-01,  8.4603e-01,  ...,  8.5928e-01,\n",
            "          -9.8686e-01, -9.8075e-01]],\n",
            "\n",
            "        [[-1.1610e+00, -3.3992e-01,  6.4933e-01,  ..., -1.1030e-01,\n",
            "           4.8025e-01, -1.4159e+00],\n",
            "         [ 3.5029e-01, -1.0320e+00,  5.5863e-01,  ...,  2.3441e-04,\n",
            "          -9.4058e-01, -1.0474e+00],\n",
            "         [-2.3836e-02,  7.2067e-01, -1.5676e+00,  ...,  2.5924e-01,\n",
            "           2.4894e+00,  2.3067e-01],\n",
            "         ...,\n",
            "         [ 1.1570e+00,  1.4354e+00, -3.2015e-01,  ..., -7.9002e-01,\n",
            "           1.8126e+00,  1.7084e-01],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         [ 4.8769e-01,  1.0519e-01, -1.2206e-01,  ...,  7.5057e-01,\n",
            "          -1.0250e-01,  2.3836e-01]],\n",
            "\n",
            "        [[ 1.7178e-01,  2.9278e-01, -1.3821e+00,  ...,  5.3837e-01,\n",
            "           7.7209e-02,  7.0363e-01],\n",
            "         [-1.2110e+00,  1.1620e+00, -1.6635e+00,  ...,  2.3573e-01,\n",
            "           6.4475e-01, -1.4111e+00],\n",
            "         [ 2.3893e-01, -4.9227e-01, -1.0673e+00,  ..., -6.0322e-01,\n",
            "           1.1958e+00,  2.3506e-01],\n",
            "         ...,\n",
            "         [ 4.2129e-02, -1.0840e+00, -1.4136e+00,  ..., -2.5189e-01,\n",
            "           4.2971e-01, -1.3407e+00],\n",
            "         [ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  257,  1049,  1517,    13,   383,  1306,  6000,  1517,   373,   284],\n",
            "        [   13,   198,   198,     1,  5574,  1660,    12, 49903,   438,   273],\n",
            "        [   25,   787,  3511,  6792,   438,   392,   994,   389,   262, 33204],\n",
            "        [ 3214,   319,   257,  1402,  4286,  2029,   262, 24818,   417,    12],\n",
            "        [ 2280,   284,   616,  2583,   408,    25,   366,    40,  1276,  1107],\n",
            "        [  286,  8737,   526,   198,   198, 43920,  3619,     0,   632,   550],\n",
            "        [  373,  4808,  1169,    62, 38378, 34537,   526,   198,   198,     1],\n",
            "        [  550,   925,   683,   438,   270,   373, 15830,   326,   484,   815]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         [-1.7606e+00,  1.9188e-01, -1.2019e+00,  ..., -8.6458e-01,\n",
            "           5.4483e-01,  6.0320e-01],\n",
            "         [ 5.3971e-02,  8.2846e-01, -6.1118e-01,  ..., -5.4833e-01,\n",
            "          -1.0730e+00,  2.0751e-01],\n",
            "         ...,\n",
            "         [ 5.3971e-02,  8.2846e-01, -6.1118e-01,  ..., -5.4833e-01,\n",
            "          -1.0730e+00,  2.0751e-01],\n",
            "         [ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01]],\n",
            "\n",
            "        [[ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         ...,\n",
            "         [ 5.6270e-01,  2.1819e-01,  1.4849e+00,  ...,  6.2696e-01,\n",
            "          -1.9812e+00,  5.7690e-01],\n",
            "         [-1.6872e+00,  3.5494e-01,  1.5316e+00,  ...,  1.4605e-01,\n",
            "           4.5568e-02,  3.7156e-02],\n",
            "         [-4.6192e-01,  6.0854e-01,  5.8098e-01,  ..., -1.6740e-01,\n",
            "          -2.3983e-01, -2.4423e-01]],\n",
            "\n",
            "        [[-1.0923e-01, -1.0082e+00, -8.2644e-01,  ...,  6.3462e-01,\n",
            "          -1.5135e+00, -7.5331e-01],\n",
            "         [-1.6788e+00,  8.6271e-01,  8.9119e-01,  ..., -4.6701e-01,\n",
            "          -2.8499e-03, -2.2191e-01],\n",
            "         [ 4.1381e-01, -9.4420e-01, -1.9763e+00,  ...,  9.8490e-01,\n",
            "          -1.7709e+00, -2.5865e-01],\n",
            "         ...,\n",
            "         [ 2.1906e-01, -5.0334e-01,  4.1974e-01,  ..., -1.5638e+00,\n",
            "          -4.7784e-01, -1.8545e+00],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 4.4466e-01,  2.2598e+00,  5.1824e-01,  ..., -1.0016e+00,\n",
            "           1.5440e+00,  2.7523e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-9.4208e-01,  3.9430e-01,  1.2472e+00,  ..., -5.4199e-01,\n",
            "          -3.7587e-01, -1.6346e-01],\n",
            "         [ 1.0058e+00,  5.5568e-01,  1.2799e+00,  ..., -8.0181e-01,\n",
            "           1.1466e+00, -2.0526e-01],\n",
            "         ...,\n",
            "         [ 5.0511e-01,  2.0639e-01,  9.4309e-01,  ..., -1.2557e+00,\n",
            "           4.4932e-01, -3.1742e-01],\n",
            "         [ 1.4850e+00,  9.7850e-01,  1.0932e+00,  ..., -3.4377e-01,\n",
            "           5.0353e-01, -7.5207e-01],\n",
            "         [ 1.1637e+00, -1.1183e+00, -1.0012e+00,  ...,  1.8436e-01,\n",
            "           5.0564e-01, -9.0855e-01]],\n",
            "\n",
            "        [[ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [-3.0595e+00, -2.3386e-01,  5.6158e-01,  ..., -7.1203e-01,\n",
            "          -4.9988e-02, -6.3656e-01],\n",
            "         [ 2.3421e-01,  1.2221e+00,  2.2005e-01,  ..., -1.5481e+00,\n",
            "           3.0688e-01,  6.6418e-01],\n",
            "         ...,\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [ 6.7616e-01,  1.0905e+00, -8.1296e-02,  ...,  9.5518e-01,\n",
            "          -1.8204e-01,  2.1222e-01]],\n",
            "\n",
            "        [[ 1.1637e+00, -1.1183e+00, -1.0012e+00,  ...,  1.8436e-01,\n",
            "           5.0564e-01, -9.0855e-01],\n",
            "         [-4.2135e-01,  1.4543e+00,  1.4310e+00,  ...,  1.1589e+00,\n",
            "          -1.1401e-02, -8.0676e-01],\n",
            "         [ 9.9937e-01,  1.4933e+00,  1.5044e-01,  ...,  8.0270e-01,\n",
            "          -4.9967e-01, -7.8062e-01],\n",
            "         ...,\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         [ 4.2091e-01, -2.6131e-01, -9.2567e-01,  ..., -1.0392e+00,\n",
            "          -7.2582e-01,  9.4441e-03],\n",
            "         [ 9.6979e-01, -2.9620e-01,  6.0475e-01,  ..., -4.1479e-01,\n",
            "          -4.4254e-01,  5.6734e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 1617,   261, 12917,   905,    11,  5025,   502,   878,   402,   271],\n",
            "        [16511,   286,   465, 11555,   303,  7821, 13209,    11,   262,  7888],\n",
            "        [  438,    83,   359,   706,    13,   764,   764,   764,  1375,  1908],\n",
            "        [ 7163,   262,  8631, 26210,  3425,  9417,   286,   262,  2119,    13],\n",
            "        [  278,   287,   257, 14263,   276,  5118,    11,   550,  6578,   257],\n",
            "        [  423,  4499,   326, 18680,   510,    12,  5532, 14000,    13,   764],\n",
            "        [ 4642,   286,   502,   438,    40,   550,   655,  8197,   606,    13],\n",
            "        [   13,   198,   198,     1,    40,   373,  9675,   379,   717,    11]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.8873,  2.8016,  1.0104,  ..., -1.2157,  0.9145,  0.2415],\n",
            "         [-0.5903, -0.5819, -0.1717,  ...,  0.5375,  1.5635, -0.8193],\n",
            "         [-0.2573,  0.1668,  0.4726,  ...,  0.4853,  1.5384, -0.7777],\n",
            "         ...,\n",
            "         [ 0.8793, -1.1962,  0.4589,  ..., -0.7711, -2.2812,  0.6270],\n",
            "         [ 0.1605,  0.5546, -1.5836,  ..., -0.6178,  0.3921,  0.3794],\n",
            "         [-0.5381,  0.2798,  0.4389,  ..., -1.5520,  1.2393, -0.2932]],\n",
            "\n",
            "        [[-0.5645,  1.7691, -0.6189,  ..., -0.3008,  1.0233, -0.8940],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.7176, -0.8397,  0.1213,  ...,  0.6356, -1.0264, -1.4093],\n",
            "         ...,\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [ 0.4099, -0.0687,  0.7716,  ...,  0.5918,  0.0616, -0.5572]],\n",
            "\n",
            "        [[-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-1.1763,  0.2549, -0.7100,  ..., -0.6795, -1.0877,  1.9333],\n",
            "         [-1.7341,  0.4921, -1.8344,  ...,  0.3779, -0.2384,  1.0013],\n",
            "         ...,\n",
            "         [-0.8599,  2.2641,  2.0736,  ...,  0.6570,  0.5910, -1.6616],\n",
            "         [ 1.4470, -0.0848, -0.7287,  ..., -1.9911,  2.6161,  0.5186],\n",
            "         [-0.2221,  1.3250, -0.1164,  ...,  0.6750,  2.2295,  0.6840]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.7845,  1.3598, -1.1044,  ...,  0.0296, -0.0355, -0.3083],\n",
            "         [-0.3559, -0.5035, -0.2793,  ..., -0.5695,  0.8471,  0.3691],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         ...,\n",
            "         [ 0.9360, -1.5745,  0.1299,  ...,  0.0998,  1.2441,  0.1171],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-0.8599,  2.2641,  2.0736,  ...,  0.6570,  0.5910, -1.6616]],\n",
            "\n",
            "        [[ 0.3502, -0.0257,  1.5899,  ..., -1.1617,  1.0165,  0.9952],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 0.8953, -0.1444,  0.9452,  ...,  0.2287, -0.0098, -0.5837],\n",
            "         ...,\n",
            "         [-0.7663, -0.2607,  0.4340,  ...,  0.2017, -0.5345, -0.6826],\n",
            "         [ 0.3645, -0.5846,  0.6519,  ..., -0.0050,  0.8798,  0.8682],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [-1.1569,  0.1217, -0.6140,  ...,  0.2029, -0.1312,  0.1417],\n",
            "         [-0.6313,  0.3005,  1.7098,  ..., -0.4809,  0.4106,  0.9097],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 9546,   546,   262, 15393,   852,  4808,  3810,    62,   438,  1219],\n",
            "        [  257, 14787,   618,   314,  4762,   287,  3589,   438,   392,   783],\n",
            "        [   13,   520,  5493,    13,  3226,  1781,   314,  1422,   470,  1560],\n",
            "        [  355,   996,   484,   547, 12548,   287,   281, 13079,   410, 12523],\n",
            "        [ 5563,    11,  9174,   530,   286,   262,  5385, 41186, 39614,  1386],\n",
            "        [  607,   284,   262, 18560,    13,   198,   198,     1,  5246,    13],\n",
            "        [ 5118,    11,   550,  6578,   257, 24518,   290,  7428,   262,  3394],\n",
            "        [   11,   523,   326,   612,   550,   587,   645, 15223,   670,   286]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-0.6089,  0.4034,  1.5381,  ...,  1.5925,  0.4516,  1.6142],\n",
            "         [ 0.1116, -0.2741,  0.2720,  ...,  0.2087, -1.9009,  1.2337],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [-0.8456, -1.2353, -0.3830,  ...,  0.8410, -1.3609, -0.3384],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [-1.0435,  1.0144, -0.3908,  ...,  0.7552, -0.9340,  0.4600]],\n",
            "\n",
            "        [[-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-1.6518,  0.8627, -0.2101,  ..., -0.3348, -0.9600, -1.0897],\n",
            "         [ 0.5868,  1.3891, -1.6561,  ...,  0.7081,  1.3799, -0.5942],\n",
            "         ...,\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 1.0818, -0.0166, -0.1110,  ..., -0.8440, -0.8880,  0.6695],\n",
            "         [ 0.0421, -1.0840, -1.4136,  ..., -0.2519,  0.4297, -1.3407]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-0.2142, -1.3219, -0.9208,  ..., -0.7035, -0.8742, -2.0800],\n",
            "         [-0.1212, -3.0303,  1.8840,  ...,  0.4525,  0.1828, -1.1669],\n",
            "         ...,\n",
            "         [-1.7231, -0.1417,  1.0724,  ...,  0.1451,  0.0061,  1.0362],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [ 1.3104,  0.3089, -1.2618,  ..., -1.3819, -1.8186, -0.8563]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.9156, -1.6805, -0.0275,  ..., -1.4683, -0.0037, -0.2294],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         ...,\n",
            "         [ 0.6762,  1.0905, -0.0813,  ...,  0.9552, -0.1820,  0.2122],\n",
            "         [-0.4518, -0.5185, -0.8591,  ...,  1.9137, -0.5566, -0.1338],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121]],\n",
            "\n",
            "        [[-0.2350, -0.3374,  0.0617,  ...,  1.0787,  0.6193,  0.0998],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         ...,\n",
            "         [-0.5926,  1.2011, -0.0172,  ..., -0.8628,  0.8629, -0.5397],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-1.0631,  0.5535, -1.6543,  ..., -0.0830,  0.9752, -0.5296]],\n",
            "\n",
            "        [[ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [ 0.5801, -1.7379, -0.3187,  ..., -0.7272, -1.4554,  0.0465],\n",
            "         [-0.9492,  0.0564, -0.4755,  ...,  0.3999,  0.9180,  0.6895],\n",
            "         ...,\n",
            "         [ 0.7933, -0.2798,  1.4400,  ..., -0.0970, -0.0628,  0.6026],\n",
            "         [-0.1329, -0.2949,  1.4879,  ...,  0.8537, -0.2309, -0.9426],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 2029,   262,  1459,   438,   261, 45697, 19369,    11,   355,   345],\n",
            "        [  286, 22353,    13,   843,   340,   373,   407,   691,   262,  9074],\n",
            "        [  821,  2406,   503,  8348,   198,   198,     1,  1532,   314,   714],\n",
            "        [41379,   293,   338,  1804,   340,   329,   502,     0,   383,   520],\n",
            "        [  764,   764,  3894,    11,  7521,   373,   262,   530,  7090,   883],\n",
            "        [  670,    13,   679,   550,   587,  2636,   691,  8208,    12, 14337],\n",
            "        [  965,  2860,  1359,   290,   965,  1397,    11,   326, 14516,   530],\n",
            "        [  287,   281, 13079,   410, 12523,   286, 22353,    13,   843,   340]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 4.3359e-01,  6.1584e-02,  1.6570e+00,  ..., -1.7117e+00,\n",
            "           3.0104e-02, -2.0060e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-4.9415e-01,  2.5842e-01, -1.5210e+00,  ...,  4.7304e-01,\n",
            "          -7.8970e-02,  1.5319e+00],\n",
            "         ...,\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [-6.8540e-01,  1.3182e+00,  6.5168e-03,  ..., -7.8027e-03,\n",
            "           6.2407e-01,  2.8329e+00],\n",
            "         [ 1.4866e+00,  4.5990e-02, -1.0712e+00,  ...,  1.1870e+00,\n",
            "          -1.5403e-01, -2.2184e-02]],\n",
            "\n",
            "        [[-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-1.7153e+00,  7.0747e-01, -2.3379e-01,  ...,  3.9937e-01,\n",
            "          -1.7167e+00, -9.3700e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         ...,\n",
            "         [-6.0351e-01,  7.1535e-01, -1.1398e+00,  ...,  4.0309e-01,\n",
            "          -6.0959e-01,  1.0566e+00],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-1.7958e+00, -2.5592e-01, -2.5860e-02,  ..., -3.9778e-01,\n",
            "           7.9161e-02, -6.1532e-01]],\n",
            "\n",
            "        [[ 1.0659e+00, -1.1044e+00, -1.0838e+00,  ..., -5.2003e-01,\n",
            "           2.0780e+00, -2.9673e-01],\n",
            "         [-9.8550e-01, -3.1409e-01,  7.1561e-01,  ..., -5.8300e-01,\n",
            "          -1.2365e+00, -4.0990e-01],\n",
            "         [-1.5821e+00,  8.3312e-01, -1.0998e+00,  ...,  3.1671e-01,\n",
            "           5.1927e-01, -7.5376e-01],\n",
            "         ...,\n",
            "         [-1.0880e+00,  5.3164e-01, -5.8157e-01,  ..., -1.9775e+00,\n",
            "          -5.9515e-01, -4.9557e-01],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         [ 1.0208e+00,  4.6131e-01, -1.6898e-01,  ...,  1.0675e+00,\n",
            "          -1.1652e+00,  2.8913e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.3293e-01, -2.9488e-01,  1.4879e+00,  ...,  8.5372e-01,\n",
            "          -2.3087e-01, -9.4256e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 4.4359e-01,  2.9453e-01,  1.0645e+00,  ..., -2.2958e-01,\n",
            "           2.7335e-01,  2.5117e-01],\n",
            "         ...,\n",
            "         [-2.7770e-01,  1.6516e+00, -5.8714e-01,  ...,  2.6537e-01,\n",
            "           5.6581e-01, -7.0945e-01],\n",
            "         [-2.3836e-02,  7.2067e-01, -1.5676e+00,  ...,  2.5924e-01,\n",
            "           2.4894e+00,  2.3067e-01],\n",
            "         [-9.4817e-01,  7.0679e-01,  6.6893e-01,  ..., -1.0863e+00,\n",
            "           9.9826e-01,  8.3489e-01]],\n",
            "\n",
            "        [[-1.0552e+00,  9.0797e-01,  8.6820e-01,  ..., -2.1974e-01,\n",
            "          -5.6268e-01, -1.0185e+00],\n",
            "         [-3.5786e-02, -1.1547e+00,  1.3728e+00,  ..., -1.3842e-01,\n",
            "          -1.0444e+00,  5.8856e-04],\n",
            "         [ 4.9391e-01, -1.8730e+00, -1.2626e+00,  ..., -6.9412e-02,\n",
            "          -5.6572e-01,  7.5738e-01],\n",
            "         ...,\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         [-1.2337e+00,  2.1474e+00, -1.3254e-01,  ..., -1.2091e+00,\n",
            "           1.4435e+00,  1.4200e+00],\n",
            "         [ 2.0277e-01, -3.2441e-01,  5.8122e-02,  ...,  1.2838e+00,\n",
            "           1.1483e+00,  1.3023e+00]],\n",
            "\n",
            "        [[ 1.1606e+00,  6.6746e-01,  9.5967e-01,  ...,  1.3476e+00,\n",
            "           1.1898e+00,  6.4805e-01],\n",
            "         [ 5.4922e-02, -2.4333e+00, -2.9900e-01,  ...,  2.0638e+00,\n",
            "           1.8694e-01,  3.9260e-01],\n",
            "         [ 1.3444e+00, -3.1124e-01, -2.6069e-01,  ..., -1.2905e+00,\n",
            "          -1.4726e+00,  9.8492e-01],\n",
            "         ...,\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 2.4228e-01,  7.8312e-01, -4.9941e-01,  ...,  1.7024e-01,\n",
            "           6.7668e-01,  9.5780e-01],\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  683,    11,   523,  1690,    11,  1615,  3364,   739,  2092,   256],\n",
            "        [10059,  9412,    26,   290,   355,   314,  2900,    11,   616,  4151],\n",
            "        [ 9074,    13,   402,   271, 10899,   338,  7062,   373,   523,  2429],\n",
            "        [  536,  5469,   338, 11914,    11, 33096,   663,  4808,  3808,    62],\n",
            "        [  607,    13,   198,   198,  5189,  1781,    11,   611,   673,   550],\n",
            "        [ 1144,   287,   262,  3024,    12,  4803,   286,   511,   512,  1741],\n",
            "        [  286, 18113,   544,   338, 10953,   314,  2936,  1498,   284,  1986],\n",
            "        [ 2652,   526,   198,   198,  5297,   438,    40,   714,   655,  6687]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 9.9937e-01,  1.4933e+00,  1.5044e-01,  ...,  8.0270e-01,\n",
            "          -4.9967e-01, -7.8062e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [ 5.8008e-01, -1.7379e+00, -3.1869e-01,  ..., -7.2724e-01,\n",
            "          -1.4554e+00,  4.6526e-02],\n",
            "         ...,\n",
            "         [-1.2379e+00, -1.0293e+00,  7.2796e-01,  ...,  6.1979e-02,\n",
            "          -1.6237e+00, -2.6296e-02],\n",
            "         [ 5.9130e-01,  4.2791e-01,  1.6824e-01,  ...,  4.9647e-01,\n",
            "           6.6784e-01, -6.7701e-01],\n",
            "         [ 1.2411e+00, -3.5829e-01, -1.7565e+00,  ..., -8.9436e-01,\n",
            "           6.7279e-03,  9.6438e-01]],\n",
            "\n",
            "        [[ 6.3809e-01,  5.8577e-01, -2.3713e+00,  ..., -7.4027e-01,\n",
            "           1.5922e-01,  4.8981e-01],\n",
            "         [ 8.7169e-01, -7.4422e-01,  8.9032e-01,  ...,  7.7858e-01,\n",
            "           7.5417e-02, -9.4455e-01],\n",
            "         [ 5.9210e-01, -1.0570e+00,  3.2271e-02,  ...,  3.1380e-01,\n",
            "           1.1976e+00, -9.7631e-01],\n",
            "         ...,\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [ 9.3177e-02, -1.4416e+00, -1.1102e+00,  ...,  3.1926e-01,\n",
            "           2.5096e+00,  1.2252e+00],\n",
            "         [-3.7372e-01, -4.4458e-01,  7.3665e-01,  ...,  5.3012e-01,\n",
            "           1.2015e-01,  6.5949e-01]],\n",
            "\n",
            "        [[-1.7958e+00, -2.5592e-01, -2.5860e-02,  ..., -3.9778e-01,\n",
            "           7.9161e-02, -6.1532e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 1.6052e-01,  5.5458e-01, -1.5836e+00,  ..., -6.1778e-01,\n",
            "           3.9215e-01,  3.7935e-01],\n",
            "         ...,\n",
            "         [ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [ 5.8008e-01, -1.7379e+00, -3.1869e-01,  ..., -7.2724e-01,\n",
            "          -1.4554e+00,  4.6526e-02],\n",
            "         [-7.2768e-01,  1.4503e+00,  1.5265e+00,  ..., -7.7197e-01,\n",
            "           4.4271e-01,  1.0377e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.3684e+00, -9.8638e-01,  2.5606e-02,  ...,  1.8331e+00,\n",
            "          -7.4961e-01,  2.4783e-04],\n",
            "         [ 1.1606e+00,  6.6746e-01,  9.5967e-01,  ...,  1.3476e+00,\n",
            "           1.1898e+00,  6.4805e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         ...,\n",
            "         [ 1.1834e+00,  9.0417e-01, -6.8985e-01,  ..., -1.1641e+00,\n",
            "           8.8850e-02, -9.2761e-01],\n",
            "         [ 8.9449e-01,  6.2438e-01,  1.0354e+00,  ...,  5.0265e-01,\n",
            "           1.0731e-01, -1.3138e+00],\n",
            "         [-2.1229e-01,  7.0272e-01,  7.5775e-01,  ...,  1.6682e+00,\n",
            "          -6.1477e-01,  8.1718e-01]],\n",
            "\n",
            "        [[-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-6.1199e-01, -2.1227e-01,  1.5207e+00,  ..., -6.8928e-01,\n",
            "          -1.1084e+00,  6.8562e-01],\n",
            "         [-1.8508e-01,  2.0343e-01,  1.7849e+00,  ...,  8.7963e-01,\n",
            "          -6.4424e-01,  1.4131e+00],\n",
            "         ...,\n",
            "         [-1.9772e+00,  3.9142e-02, -1.2965e-01,  ..., -3.8552e-01,\n",
            "           4.4250e-01,  3.3138e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [ 5.1539e-01, -4.1679e-01,  4.9709e-02,  ..., -8.7144e-01,\n",
            "          -9.8557e-01,  1.1729e+00]],\n",
            "\n",
            "        [[-2.7044e+00,  1.1892e+00,  1.0832e+00,  ...,  1.3416e+00,\n",
            "           2.9077e-01, -1.0619e-01],\n",
            "         [ 1.0058e+00,  5.5568e-01,  1.2799e+00,  ..., -8.0181e-01,\n",
            "           1.1466e+00, -2.0526e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         ...,\n",
            "         [ 1.0208e+00,  4.6131e-01, -1.6898e-01,  ...,  1.0675e+00,\n",
            "          -1.1652e+00,  2.8913e-01],\n",
            "         [-1.0407e-03, -1.2642e+00,  8.1672e-01,  ...,  2.3681e+00,\n",
            "          -8.9181e-01,  6.7308e-01],\n",
            "         [ 9.7402e-01, -1.7277e-01,  6.2254e-02,  ...,  3.5662e-01,\n",
            "          -1.2104e+00,  6.1857e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 1297,  9074,    13,   520,  5493,   523,   618,   673,  2540,   284],\n",
            "        [  340,  1701,   314,   373,   546,   284,  1061,   510,   428, 18437],\n",
            "        [  373,  3940,   416,   262,  1807,    25,   611,   339,  4808, 22474],\n",
            "        [  531,   314,  3521,   470,  7521,   683,    11,   326,   314,   373],\n",
            "        [  843,   379,   262,  2589,   314,   373,  4808,  1169,    62, 38378],\n",
            "        [  679,  1422,   470, 10505,   263,    11,   345,  1833,    11,  3595],\n",
            "        [   12,    64,    12,  1671,   330,    11,  4844,   286,   262,  1633],\n",
            "        [  607,   599,  6321,   287,   262, 17423,    12,  3823,    13,   198]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 2.1399e-01,  1.9347e-01,  1.0648e+00,  ...,  2.1137e+00,\n",
            "           3.4164e+00,  3.5804e-01],\n",
            "         [-1.7958e+00, -2.5592e-01, -2.5860e-02,  ..., -3.9778e-01,\n",
            "           7.9161e-02, -6.1532e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         ...,\n",
            "         [ 1.5830e-01,  8.5613e-02, -1.6712e+00,  ..., -1.3325e+00,\n",
            "          -4.7034e-01, -9.7824e-01],\n",
            "         [ 9.7251e-01, -6.5124e-01,  7.6889e-02,  ...,  1.8158e-01,\n",
            "          -7.0457e-02, -1.6534e-01],\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01]],\n",
            "\n",
            "        [[-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01],\n",
            "         [-7.2657e-01, -1.4021e+00, -8.5086e-01,  ...,  4.5411e-02,\n",
            "           8.8633e-01,  4.8628e-01],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         ...,\n",
            "         [ 2.8984e-01,  1.4311e+00, -6.8838e-01,  ...,  1.4353e+00,\n",
            "          -7.3147e-01, -4.6282e-01],\n",
            "         [ 3.3093e-01,  2.2000e+00, -6.9947e-01,  ...,  5.5905e-01,\n",
            "           2.4344e+00, -1.0442e+00],\n",
            "         [ 8.2708e-01,  5.0850e-01,  5.4756e-01,  ..., -7.5805e-01,\n",
            "          -1.0453e+00,  4.4544e-01]],\n",
            "\n",
            "        [[ 1.1599e+00, -5.4072e-01, -8.3042e-01,  ...,  1.1354e-01,\n",
            "          -1.2435e+00,  1.4415e+00],\n",
            "         [-1.2581e+00, -3.4162e-01,  1.7096e-01,  ...,  1.4971e+00,\n",
            "           5.7221e-01,  1.4267e+00],\n",
            "         [ 5.2904e-01,  1.2444e+00, -1.8292e+00,  ...,  2.7274e-01,\n",
            "          -1.6876e+00,  5.1756e-01],\n",
            "         ...,\n",
            "         [-3.5449e-01, -2.3002e-01, -2.0778e-01,  ..., -1.5570e-01,\n",
            "           1.1122e-01,  2.2748e+00],\n",
            "         [-3.0595e+00, -2.3386e-01,  5.6158e-01,  ..., -7.1203e-01,\n",
            "          -4.9988e-02, -6.3656e-01],\n",
            "         [-1.7352e+00,  5.1797e-01,  1.6177e+00,  ...,  1.3294e+00,\n",
            "          -2.1823e-01, -5.2259e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 4.4359e-01,  2.9453e-01,  1.0645e+00,  ..., -2.2958e-01,\n",
            "           2.7335e-01,  2.5117e-01],\n",
            "         [-1.7231e+00, -1.4167e-01,  1.0724e+00,  ...,  1.4514e-01,\n",
            "           6.0665e-03,  1.0362e+00],\n",
            "         [ 1.0791e-01, -8.7473e-01, -1.6640e+00,  ..., -1.4962e+00,\n",
            "          -1.4791e+00, -6.8406e-01],\n",
            "         ...,\n",
            "         [ 1.5134e-02,  7.9912e-01, -9.2780e-01,  ..., -2.1138e-01,\n",
            "          -1.5281e-01,  5.7233e-04],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [-1.8442e-01,  3.0398e-01, -1.2384e-01,  ...,  6.2062e-01,\n",
            "           1.9251e+00,  6.2403e-01]],\n",
            "\n",
            "        [[-2.3836e-02,  7.2067e-01, -1.5676e+00,  ...,  2.5924e-01,\n",
            "           2.4894e+00,  2.3067e-01],\n",
            "         [-1.6555e+00,  4.2936e-01, -5.3272e-01,  ..., -1.6245e+00,\n",
            "          -9.9364e-01, -8.0776e-01],\n",
            "         [-2.3836e-02,  7.2067e-01, -1.5676e+00,  ...,  2.5924e-01,\n",
            "           2.4894e+00,  2.3067e-01],\n",
            "         ...,\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 2.6136e-01, -1.5452e-01,  4.2274e-01,  ...,  1.5218e+00,\n",
            "           4.2063e-01, -1.0119e+00]],\n",
            "\n",
            "        [[-1.9156e+00, -1.6805e+00, -2.7495e-02,  ..., -1.4683e+00,\n",
            "          -3.7265e-03, -2.2936e-01],\n",
            "         [ 2.3795e-02, -5.7925e-01, -1.0028e+00,  ..., -1.4183e-01,\n",
            "           3.8149e-02, -1.1313e+00],\n",
            "         [-5.2681e-01, -1.0800e-01, -1.7016e+00,  ..., -9.4015e-01,\n",
            "           1.9736e+00, -3.1857e-01],\n",
            "         ...,\n",
            "         [ 7.2668e-01,  1.4957e-01, -3.4096e-01,  ...,  1.0477e+00,\n",
            "          -1.0172e+00, -1.0008e+00],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 9885,   345,   286,  2376, 26927,   616,   670,   526,   198,   198],\n",
            "        [  446,   259, 13235,    62,  1336,   286, 11398, 35560,  1000,   292],\n",
            "        [  757, 13984,   198,   198,  5779, 28112, 10197,   832,   262, 46475],\n",
            "        [  922,    12, 17047,  8167, 32545,    13,   198,   198,     1,  5812],\n",
            "        [31564,   286,   465,  3656,   338,  1263,  5236,  9343,   683,    11],\n",
            "        [  257,  1568,  1110,    11,   314,   550,   757,  1057,   625,   422],\n",
            "        [  568, 22665,    11,   523, 23332,    11,   523,   595, 18052,    11],\n",
            "        [  284,   607,    13,   314,  2391,   531,   314,  3521,   470,  7521]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.5794, -0.6057,  1.5766,  ..., -0.6383,  2.3214, -0.6584],\n",
            "         [ 1.4866,  0.0460, -1.0712,  ...,  1.1870, -0.1540, -0.0222],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         ...,\n",
            "         [ 1.0058,  0.5557,  1.2799,  ..., -0.8018,  1.1466, -0.2053],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471]],\n",
            "\n",
            "        [[ 1.1302, -0.3980, -0.7894,  ..., -0.1775, -0.0786,  2.4477],\n",
            "         [ 0.0425, -0.1864, -0.3348,  ..., -1.8449,  0.7245,  0.6462],\n",
            "         [ 0.5502,  1.6065, -0.1449,  ...,  2.1566, -0.0891,  2.3223],\n",
            "         ...,\n",
            "         [ 0.2771, -0.9826, -0.0123,  ..., -0.5920, -0.7897, -0.3766],\n",
            "         [ 0.2353,  1.4162, -1.9256,  ...,  0.3496, -0.9126,  0.0507],\n",
            "         [-0.2678, -0.0238,  1.0052,  ..., -0.9925,  0.6703,  0.5228]],\n",
            "\n",
            "        [[-0.3382, -0.5948,  0.2674,  ...,  2.3675, -0.6613, -0.2827],\n",
            "         [-1.1840,  1.1107,  0.5118,  ...,  2.0461, -0.3088, -1.1314],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [-2.0414,  0.1972,  0.8460,  ...,  0.8593, -0.9869, -0.9807],\n",
            "         [-0.0513,  0.6189, -1.7173,  ...,  0.4766,  0.3910,  0.8307],\n",
            "         [-0.3684, -0.3622,  0.8930,  ..., -0.7042,  0.3584,  1.0520]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-0.2522,  0.0103, -0.4378,  ..., -0.0788,  0.6742, -1.1329],\n",
            "         [ 1.3356, -0.9776, -1.3349,  ..., -0.7665,  0.0110, -0.9757],\n",
            "         ...,\n",
            "         [-0.1389, -0.8295,  0.6532,  ...,  0.9444,  1.0417,  0.2850],\n",
            "         [-0.2405, -0.1489,  0.4910,  ...,  0.4731, -1.2184,  2.2132],\n",
            "         [-0.1729,  0.6175,  2.3042,  ...,  1.0319, -0.2190, -0.3214]],\n",
            "\n",
            "        [[ 0.7415,  0.9423, -0.1055,  ...,  1.0361, -0.5117,  1.0873],\n",
            "         [ 1.6508, -0.4641, -1.3287,  ...,  0.3664,  0.9333,  1.4001],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         ...,\n",
            "         [ 0.5774,  1.3310, -1.3438,  ...,  0.1548,  0.5826, -1.5347],\n",
            "         [-0.4718,  0.2266,  0.1731,  ..., -1.3497,  0.3496,  0.5947],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712]],\n",
            "\n",
            "        [[-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [-1.9156, -1.6805, -0.0275,  ..., -1.4683, -0.0037, -0.2294],\n",
            "         [ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         ...,\n",
            "         [-0.5430, -0.9748, -0.5825,  ..., -0.2468, -0.0488,  0.4508],\n",
            "         [ 0.1079, -0.8747, -1.6640,  ..., -1.4962, -1.4791, -0.6841],\n",
            "         [ 1.3837, -0.7146, -1.2462,  ...,  0.1798,  0.1274, -1.1049]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[   40,  5710,   616,  3809, 43045,    13,   366,  2215,   673,  1908],\n",
            "        [  550,  1813,   510,   465, 12036,    13,  1550, 14580,    11,   340],\n",
            "        [  198,   198,  3347,  4376,   607, 26928,   351,   257,  9254,   286],\n",
            "        [   11,   287,   262, 13203,  5482,  1044,   276,  5739,    13,   383],\n",
            "        [  198,   198,     1,  3987,   470,   345,  1683, 45553,   903,   351],\n",
            "        [  286, 15393,   438, 16706,   262,  4318,  6103,   287,   257, 14005],\n",
            "        [  284,  2107,  1231,   326,   526,   198,   198,  5779,   438,   270],\n",
            "        [   13,   198,   198,     1, 26788,   338,   691, 12226,   318,   284]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 0.5736,  0.6788,  0.6810,  ...,  0.7741,  1.9809,  1.2333],\n",
            "         [ 1.0774,  1.3042, -1.4869,  ..., -0.9937, -0.8945,  0.6943],\n",
            "         [ 0.0932, -1.4416, -1.1102,  ...,  0.3193,  2.5096,  1.2252],\n",
            "         ...,\n",
            "         [ 0.1817, -0.8641,  0.2625,  ...,  0.1630,  0.1150,  0.8715],\n",
            "         [ 0.1583,  0.0856, -1.6712,  ..., -1.3325, -0.4703, -0.9782],\n",
            "         [-0.2221,  1.3250, -0.1164,  ...,  0.6750,  2.2295,  0.6840]],\n",
            "\n",
            "        [[ 1.1637, -1.1183, -1.0012,  ...,  0.1844,  0.5056, -0.9086],\n",
            "         [ 0.3681, -0.5106, -0.6107,  ...,  0.0823, -0.1694, -0.6275],\n",
            "         [ 0.2898,  1.4311, -0.6884,  ...,  1.4353, -0.7315, -0.4628],\n",
            "         ...,\n",
            "         [-0.9894, -1.3980, -1.0853,  ...,  2.1384, -1.6330,  1.1343],\n",
            "         [ 1.7881,  1.9280,  0.7520,  ..., -1.0498,  1.3583,  0.1712],\n",
            "         [-0.3808,  0.5145, -0.0948,  ..., -0.3431,  1.5654, -0.6311]],\n",
            "\n",
            "        [[-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [ 0.0811,  0.9551, -0.4938,  ..., -1.3557,  0.7913, -0.2509],\n",
            "         ...,\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-0.3629,  0.1616, -0.3700,  ...,  0.7865, -0.4560, -0.1154],\n",
            "         [-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.3971,  0.5285,  0.3505,  ...,  0.7033, -0.1221,  0.8168],\n",
            "         [ 1.8094,  1.4205,  0.2023,  ..., -0.2895,  0.9482,  1.3301],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         ...,\n",
            "         [ 1.1606,  0.6675,  0.9597,  ...,  1.3476,  1.1898,  0.6480],\n",
            "         [-1.8782,  0.7290,  0.7753,  ..., -0.0713,  0.1626, -0.8310],\n",
            "         [-0.2643, -0.9595,  1.1950,  ..., -0.7315,  1.1925, -0.6911]],\n",
            "\n",
            "        [[-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890],\n",
            "         [ 1.4645, -2.2736,  1.6307,  ..., -0.7426,  0.6736,  0.6262],\n",
            "         [ 0.1493, -1.4356,  2.2383,  ..., -1.5074,  0.4848, -0.4251],\n",
            "         ...,\n",
            "         [-1.8116, -0.7524,  1.2285,  ...,  0.4409,  0.4295,  0.7556],\n",
            "         [-1.6872,  0.3549,  1.5316,  ...,  0.1461,  0.0456,  0.0372],\n",
            "         [ 0.5821,  1.9366,  0.8448,  ..., -0.9704, -0.7925, -1.6757]],\n",
            "\n",
            "        [[ 2.5644, -0.0383, -0.2427,  ...,  1.1613, -0.2773,  1.5121],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         [-1.2484, -1.0462, -1.0309,  ..., -1.8435, -0.6416, -0.5471],\n",
            "         ...,\n",
            "         [ 1.2772, -1.5178, -0.5967,  ..., -0.5769, -2.0643, -0.7395],\n",
            "         [ 2.1120,  1.0673, -1.0083,  ...,  0.2292,  1.3644, -0.4726],\n",
            "         [-1.1024, -1.5599, -1.7564,  ..., -1.1066, -0.9497, -0.7890]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  284,   262,  2156,   287,   616,   749, 34372, 10038,   438, 34330],\n",
            "        [   11,   345,  1833,    11,  3595,   520,  5493,   438,   258,   655],\n",
            "        [  355,  1752,   530,   550,   890,   276,   284,   910,    25,   366],\n",
            "        [    1, 44140,   757,  1701,   339, 30050,   503,    13,   366,  2215],\n",
            "        [  373,  2636,   526,   198,   198,    40,  5710,   616,  3809, 43045],\n",
            "        [  262, 37090,   257,   845, 22665,   366,   672,   270,  2838,     1],\n",
            "        [ 3255,   465, 48422,   540,   450,    67,  3299,    13,   366,  5189],\n",
            "        [  326, 17548,   286,   262, 50085, 10938,   319,   262,  3355,  1474]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-2.4289e-01, -1.2897e+00,  5.4511e-01,  ..., -1.4117e+00,\n",
            "           3.4930e-01, -1.7464e+00],\n",
            "         ...,\n",
            "         [-1.3522e+00, -6.4909e-01, -1.0727e+00,  ...,  3.4495e-01,\n",
            "          -6.1179e-01,  2.2816e-01],\n",
            "         [-1.6872e+00,  3.5494e-01,  1.5316e+00,  ...,  1.4605e-01,\n",
            "           4.5568e-02,  3.7156e-02],\n",
            "         [ 1.0667e+00,  6.7298e-01,  6.0839e-01,  ..., -1.9575e+00,\n",
            "           2.0084e+00,  9.0728e-01]],\n",
            "\n",
            "        [[ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [ 1.4866e+00,  4.5990e-02, -1.0712e+00,  ...,  1.1870e+00,\n",
            "          -1.5403e-01, -2.2184e-02],\n",
            "         [ 1.5134e-02,  7.9912e-01, -9.2780e-01,  ..., -2.1138e-01,\n",
            "          -1.5281e-01,  5.7233e-04],\n",
            "         ...,\n",
            "         [-1.6872e+00,  3.5494e-01,  1.5316e+00,  ...,  1.4605e-01,\n",
            "           4.5568e-02,  3.7156e-02],\n",
            "         [ 9.8226e-01, -1.1883e+00, -1.0222e+00,  ..., -1.7382e+00,\n",
            "           5.8911e-01,  1.4738e-01],\n",
            "         [-1.0407e-03, -1.2642e+00,  8.1672e-01,  ...,  2.3681e+00,\n",
            "          -8.9181e-01,  6.7308e-01]],\n",
            "\n",
            "        [[-6.8540e-01,  1.3182e+00,  6.5168e-03,  ..., -7.8027e-03,\n",
            "           6.2407e-01,  2.8329e+00],\n",
            "         [ 1.0754e+00, -6.2966e-01, -6.2673e-02,  ..., -9.1191e-01,\n",
            "           1.3890e+00,  1.3794e+00],\n",
            "         [ 2.0277e-01, -3.2441e-01,  5.8122e-02,  ...,  1.2838e+00,\n",
            "           1.1483e+00,  1.3023e+00],\n",
            "         ...,\n",
            "         [ 6.0738e-01,  1.0642e+00,  8.9991e-02,  ...,  4.1625e-01,\n",
            "          -1.2428e+00, -1.2814e+00],\n",
            "         [-1.0923e-01, -1.0082e+00, -8.2644e-01,  ...,  6.3462e-01,\n",
            "          -1.5135e+00, -7.5331e-01],\n",
            "         [-4.6720e-01, -9.1476e-01,  2.1816e+00,  ...,  1.5576e+00,\n",
            "          -6.5105e-01, -2.2725e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-6.8373e-01,  9.4807e-01, -4.8198e-01,  ...,  9.7149e-01,\n",
            "          -1.9657e+00,  1.2249e+00],\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         ...,\n",
            "         [ 5.8209e-01,  1.9366e+00,  8.4485e-01,  ..., -9.7044e-01,\n",
            "          -7.9248e-01, -1.6757e+00],\n",
            "         [ 7.8871e-01, -4.7310e-01, -8.3980e-04,  ..., -1.4997e+00,\n",
            "          -8.0209e-02,  2.1473e-01],\n",
            "         [ 6.7616e-01,  1.0905e+00, -8.1296e-02,  ...,  9.5518e-01,\n",
            "          -1.8204e-01,  2.1222e-01]],\n",
            "\n",
            "        [[ 1.6155e+00, -3.1214e-01,  3.4918e-01,  ...,  2.4602e-02,\n",
            "          -1.5078e-01, -1.6929e-01],\n",
            "         [ 7.1757e-01, -8.3968e-01,  1.2131e-01,  ...,  6.3562e-01,\n",
            "          -1.0264e+00, -1.4093e+00],\n",
            "         [ 7.9554e-02, -6.9892e-01,  6.1649e-01,  ..., -2.8540e-01,\n",
            "          -1.3751e-01, -1.4957e+00],\n",
            "         ...,\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [-4.6720e-01, -9.1476e-01,  2.1816e+00,  ...,  1.5576e+00,\n",
            "          -6.5105e-01, -2.2725e-01],\n",
            "         [-8.7458e-01, -8.4733e-01, -1.0667e+00,  ...,  1.4908e+00,\n",
            "           1.2031e+00,  1.2830e+00]],\n",
            "\n",
            "        [[-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01],\n",
            "         [-9.2997e-01, -5.0392e-01,  1.0458e+00,  ..., -1.6253e+00,\n",
            "           6.2516e-01,  2.1388e+00],\n",
            "         [-1.3971e+00,  5.2853e-01,  3.5046e-01,  ...,  7.0330e-01,\n",
            "          -1.2214e-01,  8.1677e-01],\n",
            "         ...,\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-1.1602e+00,  3.1333e-01, -1.2542e+00,  ...,  1.0247e+00,\n",
            "           1.6588e-02, -2.7117e-01],\n",
            "         [-9.4686e-02,  1.8411e+00, -1.5012e+00,  ..., -8.8356e-01,\n",
            "           6.1886e-01, -1.6787e+00]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[ 2157,   502,    11, 12704,   257,  1310,  2952,    13,   198,   198],\n",
            "        [ 8216,    13,   314,   550,  1775,   683,    11,   523,  1690,    11],\n",
            "        [  262, 45172,   338,  5928,  3773,    13,   843,  8797,   616,  4240],\n",
            "        [ 1813,   340,   284,   502,    11,   611,   339,  1549,   587,  1498],\n",
            "        [ 1444,   510,   477,   402,   271, 10899,   338,  1613,     0,   198],\n",
            "        [  338,  3625,    11,   290,   314, 14028,   611,   257,   256, 11912],\n",
            "        [  438,   292,   345,   910,    13,  8920,  4808,  5562,    62,   465],\n",
            "        [  314,  1043,   607,   523,    13,  1114,  3619,    11,   477,   465]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[ 3.4149e-01, -4.6010e-02,  1.3161e-03,  ...,  9.7844e-01,\n",
            "           4.1616e-01, -1.2199e+00],\n",
            "         [ 8.9528e-01, -1.4435e-01,  9.4515e-01,  ...,  2.2872e-01,\n",
            "          -9.7809e-03, -5.8368e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         ...,\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01]],\n",
            "\n",
            "        [[-4.8908e-01,  1.0140e+00,  2.5975e-01,  ..., -8.7537e-01,\n",
            "          -1.7198e+00, -7.5520e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         [ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         ...,\n",
            "         [ 5.8008e-01, -1.7379e+00, -3.1869e-01,  ..., -7.2724e-01,\n",
            "          -1.4554e+00,  4.6526e-02],\n",
            "         [-7.4457e-01,  1.2020e+00,  5.7999e-01,  ...,  9.5648e-01,\n",
            "           1.3591e+00,  3.8625e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01]],\n",
            "\n",
            "        [[-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [-2.3546e+00,  2.2436e+00, -1.1919e+00,  ..., -3.8142e-01,\n",
            "          -1.6474e+00,  5.7668e-01],\n",
            "         [ 4.5941e-01, -5.5795e-01, -7.1025e-01,  ..., -8.5924e-01,\n",
            "           1.5418e-01, -4.9474e-01],\n",
            "         ...,\n",
            "         [ 7.3406e-01,  8.9138e-01,  8.7605e-01,  ..., -3.2414e-01,\n",
            "           6.8583e-01, -1.9104e+00],\n",
            "         [ 9.3177e-02, -1.4416e+00, -1.1102e+00,  ...,  3.1926e-01,\n",
            "           2.5096e+00,  1.2252e+00],\n",
            "         [ 1.8252e+00, -1.0332e+00, -1.2493e+00,  ...,  5.5296e-01,\n",
            "          -6.1457e-01, -1.7345e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 4.5941e-01, -5.5795e-01, -7.1025e-01,  ..., -8.5924e-01,\n",
            "           1.5418e-01, -4.9474e-01],\n",
            "         [-1.1473e+00, -2.0415e-01, -8.5276e-01,  ...,  1.2359e+00,\n",
            "           1.0477e-01,  6.1669e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         ...,\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         [ 1.2411e+00, -3.5829e-01, -1.7565e+00,  ..., -8.9436e-01,\n",
            "           6.7279e-03,  9.6438e-01],\n",
            "         [-2.5128e-01,  1.0183e+00,  3.6844e-01,  ..., -7.0948e-01,\n",
            "          -1.0096e+00,  1.1753e+00]],\n",
            "\n",
            "        [[-1.6872e+00,  3.5494e-01,  1.5316e+00,  ...,  1.4605e-01,\n",
            "           4.5568e-02,  3.7156e-02],\n",
            "         [-2.6781e-01, -2.3841e-02,  1.0052e+00,  ..., -9.9253e-01,\n",
            "           6.7035e-01,  5.2284e-01],\n",
            "         [ 1.4866e+00,  4.5990e-02, -1.0712e+00,  ...,  1.1870e+00,\n",
            "          -1.5403e-01, -2.2184e-02],\n",
            "         ...,\n",
            "         [ 4.4494e-01, -2.2295e+00,  3.6817e-01,  ...,  4.1714e-01,\n",
            "          -2.6349e-01, -7.9117e-01],\n",
            "         [-8.4558e-01, -1.2353e+00, -3.8301e-01,  ...,  8.4102e-01,\n",
            "          -1.3609e+00, -3.3840e-01],\n",
            "         [ 7.1757e-01, -8.3968e-01,  1.2131e-01,  ...,  6.3562e-01,\n",
            "          -1.0264e+00, -1.4093e+00]],\n",
            "\n",
            "        [[ 2.9863e-01,  1.1781e+00, -2.1661e-01,  ...,  7.5234e-01,\n",
            "           1.4686e+00, -1.1888e+00],\n",
            "         [ 1.4307e+00,  9.2382e-01,  7.7364e-01,  ..., -8.8724e-01,\n",
            "          -1.6588e-01,  1.9158e+00],\n",
            "         [-1.9156e+00, -1.6805e+00, -2.7495e-02,  ..., -1.4683e+00,\n",
            "          -3.7265e-03, -2.2936e-01],\n",
            "         ...,\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01],\n",
            "         [-1.8818e+00, -1.4698e-01,  1.4267e+00,  ...,  1.2142e+00,\n",
            "          -4.6867e-01,  1.1407e+00],\n",
            "         [ 7.1757e-01, -8.3968e-01,  1.2131e-01,  ...,  6.3562e-01,\n",
            "          -1.0264e+00, -1.4093e+00]]], grad_fn=<EmbeddingBackward0>)\n",
            "Batch of Input Indices:\n",
            " tensor([[  198,   198,     1,  1639,  1683,  2993,    30,   887,   345,   655],\n",
            "        [ 1375,  4762,   287,   683,    11, 26996,   798,   287,   683,   438],\n",
            "        [  466,   340,    13,   383, 18098,   373,  3940,   416,   262,  1807],\n",
            "        [  271, 10899,  4120,   284,   423,   595,    67,  1328,   340,   438],\n",
            "        [26928,   351,   257,  9254,   286,   922,    12, 17047,  8167,  5975],\n",
            "        [   62,   991, 12036,   438, 20777, 41379,   293,   338,  1804,   340],\n",
            "        [   26,   475,   340,   561,   423,   587,  1327,   284,  5879,   326],\n",
            "        [10303,   257, 17972,    13,   632,  1138,    11,   287,  1790,    11]])\n",
            "Batch of Embeddings:\n",
            " tensor([[[-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [-1.2484e+00, -1.0462e+00, -1.0309e+00,  ..., -1.8435e+00,\n",
            "          -6.4164e-01, -5.4710e-01],\n",
            "         [ 6.7616e-01,  1.0905e+00, -8.1296e-02,  ...,  9.5518e-01,\n",
            "          -1.8204e-01,  2.1222e-01],\n",
            "         ...,\n",
            "         [-7.1909e-01,  1.5499e+00, -3.7033e-01,  ..., -1.3717e+00,\n",
            "          -9.2435e-01, -1.5860e+00],\n",
            "         [ 1.4866e+00,  4.5990e-02, -1.0712e+00,  ...,  1.1870e+00,\n",
            "          -1.5403e-01, -2.2184e-02],\n",
            "         [-1.0407e-03, -1.2642e+00,  8.1672e-01,  ...,  2.3681e+00,\n",
            "          -8.9181e-01,  6.7308e-01]],\n",
            "\n",
            "        [[ 1.4470e+00, -8.4776e-02, -7.2872e-01,  ..., -1.9911e+00,\n",
            "           2.6161e+00,  5.1856e-01],\n",
            "         [ 6.3551e-02, -1.3460e+00,  8.5021e-01,  ...,  1.8437e+00,\n",
            "          -9.7283e-01, -1.2313e+00],\n",
            "         [ 1.1606e+00,  6.6746e-01,  9.5967e-01,  ...,  1.3476e+00,\n",
            "           1.1898e+00,  6.4805e-01],\n",
            "         ...,\n",
            "         [ 1.1606e+00,  6.6746e-01,  9.5967e-01,  ...,  1.3476e+00,\n",
            "           1.1898e+00,  6.4805e-01],\n",
            "         [ 9.9937e-01,  1.4933e+00,  1.5044e-01,  ...,  8.0270e-01,\n",
            "          -4.9967e-01, -7.8062e-01],\n",
            "         [-1.6872e+00,  3.5494e-01,  1.5316e+00,  ...,  1.4605e-01,\n",
            "           4.5568e-02,  3.7156e-02]],\n",
            "\n",
            "        [[-8.4796e-01,  9.1270e-01, -8.7696e-01,  ...,  2.4126e+00,\n",
            "           5.7679e-01, -9.3367e-01],\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01],\n",
            "         [ 2.5644e+00, -3.8294e-02, -2.4266e-01,  ...,  1.1613e+00,\n",
            "          -2.7732e-01,  1.5121e+00],\n",
            "         ...,\n",
            "         [ 5.2904e-01,  1.2444e+00, -1.8292e+00,  ...,  2.7274e-01,\n",
            "          -1.6876e+00,  5.1756e-01],\n",
            "         [-5.1296e-02,  6.1887e-01, -1.7173e+00,  ...,  4.7659e-01,\n",
            "           3.9100e-01,  8.3075e-01],\n",
            "         [ 6.0825e-01, -8.3576e-01,  8.1374e-01,  ...,  1.3855e+00,\n",
            "          -2.2521e-01, -2.8407e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-8.4558e-01, -1.2353e+00, -3.8301e-01,  ...,  8.4102e-01,\n",
            "          -1.3609e+00, -3.3840e-01],\n",
            "         [-6.6806e-01,  1.2456e+00,  8.2994e-01,  ..., -1.7945e+00,\n",
            "           1.5532e+00,  7.4931e-01],\n",
            "         [-2.1223e-01,  2.1300e-01,  6.5300e-01,  ...,  7.5739e-02,\n",
            "           1.1243e-01, -1.2027e+00],\n",
            "         ...,\n",
            "         [ 4.5941e-01, -5.5795e-01, -7.1025e-01,  ..., -8.5924e-01,\n",
            "           1.5418e-01, -4.9474e-01],\n",
            "         [-3.6431e+00, -7.1430e-01,  1.2849e+00,  ..., -8.8991e-01,\n",
            "          -5.9020e-01,  1.9006e+00],\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01]],\n",
            "\n",
            "        [[ 5.9210e-01, -1.0570e+00,  3.2271e-02,  ...,  3.1380e-01,\n",
            "           1.1976e+00, -9.7631e-01],\n",
            "         [-2.8399e-01, -2.2967e+00,  9.1001e-01,  ..., -6.1041e-01,\n",
            "          -6.8508e-01, -1.6910e-01],\n",
            "         [-3.8076e-01,  5.1452e-01, -9.4756e-02,  ..., -3.4308e-01,\n",
            "           1.5654e+00, -6.3113e-01],\n",
            "         ...,\n",
            "         [-1.1024e+00, -1.5599e+00, -1.7564e+00,  ..., -1.1066e+00,\n",
            "          -9.4972e-01, -7.8900e-01],\n",
            "         [-4.8161e-01, -2.1394e+00,  1.4863e+00,  ..., -8.7180e-01,\n",
            "           1.6651e+00, -6.3250e-01],\n",
            "         [-9.4924e-01,  5.6373e-02, -4.7546e-01,  ...,  3.9988e-01,\n",
            "           9.1804e-01,  6.8954e-01]],\n",
            "\n",
            "        [[-2.8551e-01, -1.4693e-01, -2.0395e-01,  ...,  1.1408e-01,\n",
            "          -2.2132e-02, -2.4660e-02],\n",
            "         [-1.8782e+00,  7.2901e-01,  7.7530e-01,  ..., -7.1252e-02,\n",
            "           1.6261e-01, -8.3101e-01],\n",
            "         [-3.9639e-01, -3.0968e+00,  5.4255e-01,  ..., -1.0285e-01,\n",
            "           1.1723e-01,  1.7079e+00],\n",
            "         ...,\n",
            "         [ 1.1606e+00,  6.6746e-01,  9.5967e-01,  ...,  1.3476e+00,\n",
            "           1.1898e+00,  6.4805e-01],\n",
            "         [ 1.0542e+00,  1.4665e+00, -7.9418e-01,  ..., -5.1115e-01,\n",
            "          -4.7723e-01, -2.7823e-01],\n",
            "         [ 1.7881e+00,  1.9280e+00,  7.5197e-01,  ..., -1.0498e+00,\n",
            "           1.3583e+00,  1.7120e-01]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rHiYFfbcSzpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}